{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# WWLayerIterator\n",
    "\n",
    "This Notebook explains how to use the internal WeightWatcher Layer Iterators\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T23:51:16.544327Z",
     "start_time": "2019-03-05T23:51:16.531457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress the powerlaw package warnings\n",
    "# \"powerlaw.py:700: RuntimeWarning: divide by zero encountered in true_divide\"\n",
    "# \"powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\"\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-31T15:29:26-07:00\n",
      "\n",
      "CPython 3.7.4\n",
      "IPython 7.17.0\n",
      "\n",
      "compiler   : Clang 4.0.1 (tags/RELEASE_401/final)\n",
      "system     : Darwin\n",
      "release    : 17.7.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 12\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T00:16:43.249725Z",
     "start_time": "2019-03-06T00:16:43.240611Z"
    }
   },
   "source": [
    "### Import WeightWatcher\n",
    "\n",
    "set custom Logging at WARN Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.9'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARN)\n",
    "\n",
    "import weightwatcher as ww\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "ww.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  How to create a WWLayerIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:weightwatcher:\n",
      "\n",
      "python      version 3.7.4 (default, Aug 13 2019, 15:17:50) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.19.1\n",
      "tensforflow version 2.1.0\n",
      "keras       version 2.2.4-tf\n",
      "INFO:weightwatcher:params {'glorot_fix': False, 'normalize': False, 'conv2d_norm': True, 'randomize': True, 'savefig': False, 'rescale': True, 'deltaEs': False, 'intra': False, 'channels': None, 'conv2d_fft': False, 'ww2x': False}\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg19_bn(pretrained=True)\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "ww_layer_iterator = watcher.make_layer_iterator(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Iterator lets you loop over WWLayer instances\n",
    "\n",
    "- The WWLayer instance (object) is a wrapper to the underlying framework layers\n",
    "\n",
    "- The intent is to only access the WWLayer instance and not the underlying framework methods\n",
    "\n",
    "- This lets weightwatcher apply different functions / transformations on each layer individually\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WWLayer 2  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 5  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 9  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 12  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 16  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 19  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 22  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 25  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 29  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 32  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 35  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 38  None PYTORCH CONV2D  skipped False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WWLayer 42  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 45  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 48  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 51  None PYTORCH CONV2D  skipped False\n",
      "WWLayer 57  None PYTORCH DENSE  skipped False\n",
      "WWLayer 60  None PYTORCH DENSE  skipped False\n",
      "WWLayer 63  None PYTORCH DENSE  skipped False\n"
     ]
    }
   ],
   "source": [
    "for ww_layer in ww_layer_iterator:\n",
    "    print(ww_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The .__dict__ method lets you inspect what is actually in the iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'glorot_fix': False,\n",
       "  'normalize': False,\n",
       "  'conv2d_norm': True,\n",
       "  'randomize': True,\n",
       "  'savefig': False,\n",
       "  'rescale': True,\n",
       "  'deltaEs': False,\n",
       "  'intra': False,\n",
       "  'channels': None,\n",
       "  'conv2d_fft': False,\n",
       "  'ww2x': False},\n",
       " 'k': 0,\n",
       " 'model': VGG(\n",
       "   (features): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "     (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (5): ReLU(inplace=True)\n",
       "     (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (9): ReLU(inplace=True)\n",
       "     (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (12): ReLU(inplace=True)\n",
       "     (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (16): ReLU(inplace=True)\n",
       "     (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (19): ReLU(inplace=True)\n",
       "     (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (22): ReLU(inplace=True)\n",
       "     (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (25): ReLU(inplace=True)\n",
       "     (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (29): ReLU(inplace=True)\n",
       "     (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (32): ReLU(inplace=True)\n",
       "     (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (35): ReLU(inplace=True)\n",
       "     (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (38): ReLU(inplace=True)\n",
       "     (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (42): ReLU(inplace=True)\n",
       "     (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (45): ReLU(inplace=True)\n",
       "     (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (48): ReLU(inplace=True)\n",
       "     (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (51): ReLU(inplace=True)\n",
       "     (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "   (classifier): Sequential(\n",
       "     (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Dropout(p=0.5, inplace=False)\n",
       "     (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "     (4): ReLU(inplace=True)\n",
       "     (5): Dropout(p=0.5, inplace=False)\n",
       "     (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'framework': <FRAMEWORK.PYTORCH: 2>,\n",
       " 'channels': <CHANNELS.LAST: 4>,\n",
       " 'model_iter': <generator object ModelIterator.model_iter_.<locals>.layer_iter_ at 0x1665981d0>,\n",
       " 'layer_iter': <generator object WWLayerIterator.ww_layer_iter_ at 0x166598250>,\n",
       " 'filter_ids': [],\n",
       " 'filter_types': [],\n",
       " 'filter_names': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The WWLayerIterator constructor method takes\n",
    "\n",
    "- layers=[LAYER_ID, ...] to specify filters, as in the watcher.analyze(..,) and watcher.describe(...) methods\n",
    "\n",
    "- other parameters, like ww2x and channels, are specified in the parameters dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:weightwatcher:params {'glorot_fix': False, 'normalize': False, 'conv2d_norm': True, 'randomize': True, 'savefig': False, 'rescale': True, 'deltaEs': False, 'intra': False, 'channels': None, 'conv2d_fft': False, 'ww2x': False}\n",
      "DEBUG:weightwatcher:FRAMEWORKS: KERAS = 4  PYTORCH = 2 ONNX = 8 UNKNOWN = 1 \n",
      "DEBUG:weightwatcher:FIRST = 2  LAST = 4 UNKNOWN = 1 \n",
      "DEBUG:weightwatcher:MODEL ITERATOR, framework = 2, channels = 4 \n",
      "INFO:weightwatcher:Filtering layer by id 60\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger('weightwatcher') \n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "layers = [60]\n",
    "DEFAULT_PARAMS = {'glorot_fix': False, 'normalize':False, 'conv2d_norm':True, 'randomize': True, 'savefig':False, \n",
    "                  'rescale':True , 'deltaEs':False, 'intra':False, 'channels':None, 'conv2d_fft':False, \n",
    "                  'ww2x':False}\n",
    "\n",
    "params = DEFAULT_PARAMS\n",
    "ww_layer_iterator = watcher.make_layer_iterator(model=model, layers=layers, params=params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now only 1 layer is processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:weightwatcher:skipping layer 0 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 0 None is skipped\n",
      "INFO:weightwatcher:skipping layer 1 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 1 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 64x3 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=64 M=3 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 2 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 64 max evals None\n",
      "DEBUG:weightwatcher:Layer 2 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 3 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 3 None is skipped\n",
      "INFO:weightwatcher:skipping layer 4 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 4 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 64x64 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=64 M=64 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 5 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 64 max evals None\n",
      "DEBUG:weightwatcher:Layer 5 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 6 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 6 None is skipped\n",
      "INFO:weightwatcher:skipping layer 7 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 7 None is skipped\n",
      "INFO:weightwatcher:skipping layer 8 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 8 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 128x64 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=128 M=64 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 9 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 128 max evals None\n",
      "DEBUG:weightwatcher:Layer 9 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 10 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 10 None is skipped\n",
      "INFO:weightwatcher:skipping layer 11 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 11 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 128x128 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=128 M=128 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 12 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 128 max evals None\n",
      "DEBUG:weightwatcher:Layer 12 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 13 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 13 None is skipped\n",
      "INFO:weightwatcher:skipping layer 14 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 14 None is skipped\n",
      "INFO:weightwatcher:skipping layer 15 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 15 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 256x128 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=128 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 16 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "DEBUG:weightwatcher:Layer 16 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 17 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 17 None is skipped\n",
      "INFO:weightwatcher:skipping layer 18 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 18 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 256x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=256 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 19 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "DEBUG:weightwatcher:Layer 19 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 20 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 20 None is skipped\n",
      "INFO:weightwatcher:skipping layer 21 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 21 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 256x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=256 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 22 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "DEBUG:weightwatcher:Layer 22 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 23 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 23 None is skipped\n",
      "INFO:weightwatcher:skipping layer 24 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 24 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 256x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=256 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 25 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "DEBUG:weightwatcher:Layer 25 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 26 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 26 None is skipped\n",
      "INFO:weightwatcher:skipping layer 27 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 27 None is skipped\n",
      "INFO:weightwatcher:skipping layer 28 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 28 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=256 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 29 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:Layer 29 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 30 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 30 None is skipped\n",
      "INFO:weightwatcher:skipping layer 31 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 31 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 32 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:Layer 32 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 33 None by id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 33 None is skipped\n",
      "INFO:weightwatcher:skipping layer 34 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 34 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 35 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:Layer 35 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 36 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 36 None is skipped\n",
      "INFO:weightwatcher:skipping layer 37 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 37 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 38 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:Layer 38 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 39 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 39 None is skipped\n",
      "INFO:weightwatcher:skipping layer 40 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 40 None is skipped\n",
      "INFO:weightwatcher:skipping layer 41 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 41 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 42 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:Layer 42 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 43 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 43 None is skipped\n",
      "INFO:weightwatcher:skipping layer 44 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 44 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 45 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:Layer 45 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 46 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 46 None is skipped\n",
      "INFO:weightwatcher:skipping layer 47 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 47 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 48 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:Layer 48 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 49 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 49 None is skipped\n",
      "INFO:weightwatcher:skipping layer 50 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 50 None is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "INFO:weightwatcher:skipping layer 51 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:Layer 51 None is skipped\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "INFO:weightwatcher:skipping layer 52 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 52 None is skipped\n",
      "INFO:weightwatcher:skipping layer 53 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 53 None is skipped\n",
      "INFO:weightwatcher:skipping layer 54 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 54 None is skipped\n",
      "INFO:weightwatcher:skipping layer 55 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 55 None is skipped\n",
      "INFO:weightwatcher:skipping layer 56 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 56 None is skipped\n",
      "INFO:weightwatcher:skipping layer 57 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 25088 max evals None\n",
      "DEBUG:weightwatcher:Layer 57 None is skipped\n",
      "INFO:weightwatcher:skipping layer 58 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 58 None is skipped\n",
      "INFO:weightwatcher:skipping layer 59 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 59 None is skipped\n",
      "INFO:weightwatcher:keeping layer 60 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals None\n",
      "INFO:weightwatcher:skipping layer 61 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 61 None is skipped\n",
      "INFO:weightwatcher:skipping layer 62 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:Layer 62 None is skipped\n",
      "INFO:weightwatcher:skipping layer 63 None by id\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals None\n",
      "DEBUG:weightwatcher:Layer 63 None is skipped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WWLayer 60  None PYTORCH DENSE  skipped False\n"
     ]
    }
   ],
   "source": [
    "for ww_layer in ww_layer_iterator:\n",
    "    print(ww_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WWLayer  Instances\n",
    "\n",
    "When a WWLayer instance is created, the weight matrices for the layer are extracted from the underlying framework tensor (i.e. layer.weights and layer.biases) and placed into WMats\n",
    "\n",
    "- WMats = [W,W,W,...] contains 1 or more W matrices, of the same shape NxM, N > M\n",
    "- evals: the *combined* evals for each layer\n",
    "- rf = 1 or (k)x(k)  the size of the 'receptive field'\n",
    "\n",
    "\n",
    "\n",
    "- layer_type =  an internal enum:    known layer types so far include:\n",
    "\n",
    "<pre>\n",
    "LAYER_TYPE.DENSE | LAYER_TYPE.CONV1D | LAYER_TYPE.CONV2D | LAYER_TYPE.FLATTENED |  LAYER_TYPE.EMBEDDING | LAYER_TYPE.NORM\n",
    "</pre>\n",
    "\n",
    "- channel_str:  string for channel type :  \"FIRST\" | \"LAST\" | \"UNKNOWN\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WeightWatcher Apply Methods\n",
    "\n",
    "#### The various apply_xxx() methods use basic metaprogramming to set additional instance variables\n",
    "\n",
    "\n",
    "- apply_filters()\n",
    "- apply_normalize_Wmats()\n",
    "- apply_esd()\n",
    "- apply_random_esd()\n",
    "- apply_plot_esd()\n",
    "- apply_fit_powerlaw()\n",
    "- apply_norm_metrics()\n",
    "- apply_plot_deltaEs()\n",
    "- apply_mp_fit()\n",
    "- apply_svdsmoothing()\n",
    "\n",
    "\n",
    "i.e the apply_esd() method runs SVD on all the WMats, then combines them into a single ESD\n",
    "\n",
    "<code>\n",
    "#\n",
    "    def apply_esd(self, ww_layer, params=AULT_PARAMS):\n",
    "            \"\"\"run full SVD on layer weight matrices, compute ESD on combined eigenvalues, combine all...\"\"\"\n",
    "#\n",
    "...\n",
    "#\n",
    "    ww_layer.evals = evals\n",
    "    ww_layer.add_column(\"has_esd\", True)\n",
    "    ww_layer.add_column(\"num_evals\", len(evals))\n",
    "    ww_layer.add_column(\"sv_max\", sv_max)\n",
    "    ww_layer.add_column(\"rank_loss\", rank_loss)\n",
    "    ww_layer.add_column(\"lambda_max\", np.max(evals))    \n",
    "#      \n",
    "    return ww_layer\n",
    "</code>       \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are different Iterators for different ways of walking the Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weightwatcher.weightwatcher.WWLayerIterator"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ww_layer_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weightwatcher.weightwatcher import WWLayerIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weightwatcher.constants import LAYER_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WWStackedLayerIterator(WWLayerIterator):\n",
    "    \"\"\"Iterator variant that sticaks all weight matrics into a single WWLayer\"\"\"\n",
    "    from copy import deepcopy\n",
    "\n",
    "    def ww_stacked_iter_(self):\n",
    "        from copy import deepcopy\n",
    "        \n",
    "        # find the maximum dimensions so we can pad the matrices\n",
    "        ww_stacked_layer = None\n",
    "        for ww_layer in self.ww_layer_iter_():\n",
    "            \n",
    "            # Here, Ijust lazizy copy an older layer\n",
    "            # really, we should creat the WWLayer using the init() constructor\n",
    "            if ww_stacked_layer is None:\n",
    "                ww_stacked_layer =  deepcopy(ww_layer)\n",
    "                ww_stacked_layer.the_type =  LAYER_TYPE.COMBINED\n",
    "                ww_stacked_layer.layer_id = 0  \n",
    "                ww_stacked_layer.name = \"Example Stacked Layer\"\n",
    "            Wmats.extend(ww_layer.Wmats)\n",
    "            \n",
    "        # Note: Here the matrices should be padded so that they are all the same width\n",
    "        #  ww_stacked_layer.Wmats = pad(Wmats)\n",
    "        # \n",
    "        ww_stacked_layer.Wmats = Wmats\n",
    "        \n",
    "        # Then, the layer shape has to be set\n",
    "        # Just setting dummy variable here\n",
    "        ww_stacked_layer.N = 1000\n",
    "        ww_stacked_layer.M = 100\n",
    "        ww_stacked_layer.rf = 1\n",
    "        #...\n",
    "    \n",
    "        \n",
    "        yield ww_stacked_layer\n",
    "                \n",
    "    def make_layer_iter_(self):\n",
    "        return self.ww_stacked_iter_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weightwatcher:FRAMEWORKS: KERAS = 4  PYTORCH = 2 ONNX = 8 UNKNOWN = 1 \n",
      "DEBUG:weightwatcher:FIRST = 2  LAST = 4 UNKNOWN = 1 \n",
      "DEBUG:weightwatcher:MODEL ITERATOR, framework = 2, channels = 4 \n"
     ]
    }
   ],
   "source": [
    "layer_iter = WWStackedLayerIterator(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 0 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 1 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 64x3 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=64 M=3 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 64 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 3 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 4 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 64x64 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=64 M=64 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 64 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 6 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 7 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 8 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 128x64 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=128 M=64 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 128 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 10 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 11 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 128x128 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=128 M=128 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 128 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 13 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 14 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 15 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 256x128 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=128 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 17 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 18 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 256x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=256 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 20 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 21 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 256x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=256 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 23 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 24 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 256x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=256 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 26 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 27 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 28 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=256 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 30 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 31 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 33 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 34 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 36 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 37 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 39 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weightwatcher:layer not supported: Layer 40 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 41 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 43 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 44 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 46 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 47 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 49 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 50 None has no weights\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:Channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels = 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "WARNING:weightwatcher:pytorch layer: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  type LAYER_TYPE.UNKNOWN not found \n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 52 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 53 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 54 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 55 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 56 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 25088 max evals None\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 58 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 59 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals None\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 61 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 0 max evals None\n",
      "DEBUG:weightwatcher:layer not supported: Layer 62 None has no weights\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WWLayer 0  Example Stacked Layer PYTORCH COMBINED  skipped False\n"
     ]
    }
   ],
   "source": [
    "for layer in layer_iter:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice:  The Layer Matrices have not been padded or reshaped yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 3)\n",
      "(64, 3)\n",
      "(64, 3)\n",
      "(64, 3)\n",
      "(64, 3)\n",
      "(64, 3)\n",
      "(64, 3)\n",
      "(64, 3)\n",
      "(64, 3)\n",
      "(64, 64)\n",
      "(64, 64)\n",
      "(64, 64)\n",
      "(64, 64)\n",
      "(64, 64)\n",
      "(64, 64)\n",
      "(64, 64)\n",
      "(64, 64)\n",
      "(64, 64)\n",
      "(128, 64)\n",
      "(128, 64)\n",
      "(128, 64)\n",
      "(128, 64)\n",
      "(128, 64)\n",
      "(128, 64)\n",
      "(128, 64)\n",
      "(128, 64)\n",
      "(128, 64)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(128, 128)\n",
      "(256, 128)\n",
      "(256, 128)\n",
      "(256, 128)\n",
      "(256, 128)\n",
      "(256, 128)\n",
      "(256, 128)\n",
      "(256, 128)\n",
      "(256, 128)\n",
      "(256, 128)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(512, 256)\n",
      "(512, 256)\n",
      "(512, 256)\n",
      "(512, 256)\n",
      "(512, 256)\n",
      "(512, 256)\n",
      "(512, 256)\n",
      "(512, 256)\n",
      "(512, 256)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(4096, 25088)\n",
      "(4096, 4096)\n",
      "(1000, 4096)\n"
     ]
    }
   ],
   "source": [
    "for W in layer.Wmats:\n",
    "    print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
