### Example Notebooks

Most notebooks can be run directly in Google Colab or locally using Jupyter
<hr>

[WeightWatcher.ipynb](WeightWatcher.ipynb):\
Basic functionality

<hr>

#### Addtional Examples
[WeightWatcher-Example](https://github.com/CalculatedContent/WeightWatcher-Examples)


<hr>

#### Aopplications for LLMs / Transformer Models

[WW-BERT-BlogExample.ipynb](WW-BERT-BlogExample.ipynb):\
Compares BERT, RoBERT, and XLNet using the layer Alphas $\alpha$'s

[WW-LegalNER.ipynb](WW-LegalNER.ipynb):\
Comparing 2 different LLMs for Legal NER

 
[WW-GPT.ipynb](WW-GPT.ipynb):\
Compares GPT and GPT2, which are the same models trained with different amounts of data.

[WW_Sentence_Transformers.ipynb](WW_Sentence_Transformers.ipynb):\
Selecting the best Sentence Transformer, out of 100 different HuggingFace models

<hr>

#### From the SETOL (WeightWatcher theory paper):\
[WW_MLP3_BatchSizes.ipynb](WW_MLP3_BatchSizes.ipynb):\
Example using a very simple, 3-layer MLP (MLP3), but only training 1 layer

[LSA.ipynb](LSA.ipynb):\
Applying weightwatcher to a very simple example using Latent Semantic Analysis (LSA)


<hr>

#### New Rand_Distance metric

[WW-VGG-RandDistance.ipynb](WW-VGG-RandDistance.ipynb):\
Rand Distance metric applied to VGG series

<hr>

#### New SVDSharpness and SVDSmoothing Tranaforms

[WW-SVDSharpness-VGG11.ipynb](WW-SVDSharpness-VGG11.ipynb):\
Used to remove Correlation Traps

[WW-SVDSmoothing.ipynb](WW-SVDSmoothing.ipynb):\
[WW-SVDSmoothing-VGG16.ipynb](WW-SVDSmoothing-VGG16.ipynb):\
[WW-SVDSmoothing-VGG16-Keras.ipynb](WW-SVDSmoothing-VGG16-Keras.ipynb):\
Create lower-rank approximation for each layer

<hr>

#### Results from the [WeightWatcher Nature paper](https://www.nature.com/articles/s41467-021-24025-8).


[WW-VGG.ipynb](WW-VGG.ipynb):\
Compares the VGG test accuracies vs AlphaHat $\hat{\alpha}$. \
Also includes Correlation Flow plots

[WW-ResNet.ipynb](WW-ResNet.ipynb):\
[WW-DenseNet.ipynb](WW-DenseNet.ipynb):\
ResNet and DenseNet examples of Correlation Flow 

[WW-Full-PyTorchCV.ipynb](WW-Full-PyTorchCV.ipynb):\
Full computation of all CV models

(and see GPT example above)

<hr>

#### Advanced Usage 

[WW-LayerIterator.ipynb](WW-LayerIterator.ipynb):\
[WW-LayerIteratorB.ipynb](WW-LayerIteratorN.ipynb):\
Layer iterator

[WW-ONNX.ipynb](WW-ONNX.ipynb):\
Prototype ONNX support


<hr>




