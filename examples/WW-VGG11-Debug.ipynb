{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/CalculatedContent/WeightWatcher/blob/master/examples/WW-VGG-RandDistance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Debug Refactoring  VGG11 Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T23:51:16.544327Z",
     "start_time": "2019-03-05T23:51:16.531457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress the powerlaw package warnings\n",
    "# \"powerlaw.py:700: RuntimeWarning: divide by zero encountered in true_divide\"\n",
    "# \"powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\"\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T00:16:43.249725Z",
     "start_time": "2019-03-06T00:16:43.240611Z"
    }
   },
   "source": [
    "### Import WeightWatcher\n",
    "\n",
    "set custom Logging at WARN Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install weightwatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch is available but CUDA is not. Defaulting to scipy for SVD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.6.4.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import weightwatcher as ww\n",
    "import torchvision.models as models\n",
    "\n",
    "logger = logging.getLogger(ww.__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "ww.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:weightwatcher:\n",
      "\n",
      "python      version 3.9.13 (main, Aug 25 2022, 18:29:29) \n",
      "[Clang 12.0.0 ]\n",
      "numpy       version 1.22.3\n",
      "torch version 1.12.1\n",
      "INFO:weightwatcher:\n",
      "\n",
      "python      version 3.9.13 (main, Aug 25 2022, 18:29:29) \n",
      "[Clang 12.0.0 ]\n",
      "numpy       version 1.22.3\n",
      "torch version 1.12.1\n"
     ]
    }
   ],
   "source": [
    "modelname = 'VGG11'\n",
    "model = models.vgg11(pretrained=True)\n",
    "watcher = ww.WeightWatcher(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:weightwatcher:\n",
      "\n",
      "python      version 3.9.13 (main, Aug 25 2022, 18:29:29) \n",
      "[Clang 12.0.0 ]\n",
      "numpy       version 1.22.3\n",
      "torch version 1.12.1\n",
      "INFO:weightwatcher:\n",
      "\n",
      "python      version 3.9.13 (main, Aug 25 2022, 18:29:29) \n",
      "[Clang 12.0.0 ]\n",
      "numpy       version 1.22.3\n",
      "torch version 1.12.1\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg11(weights='VGG11_Weights.IMAGENET1K_V1').state_dict()\n",
    "watcher = ww.WeightWatcher(model=model, log_level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDK why the ints are floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:weightwatcher:params {'glorot_fix': False, 'normalize': False, 'conv2d_norm': True, 'randomize': True, 'savedir': 'ww-img', 'savefig': 'ww-img', 'rescale': True, 'plot': False, 'deltaEs': False, 'intra': False, 'channels': None, 'conv2d_fft': False, 'ww2x': False, 'vectors': True, 'smooth': None, 'stacked': False, 'svd_method': 'accurate', 'fix_fingers': None, 'fit': 'power_law', 'sparsify': True, 'detX': True, 'mp_fit': False, 'min_evals': 0, 'max_evals': None, 'max_N': 10, 'tolerance': 1e-06, 'layer_ids_start': 0, 'add_biases': False, 'glorot_fit': False, 'layers': []}\n",
      "INFO:weightwatcher:Saving all images to ww-img\n",
      "INFO:weightwatcher:params {'glorot_fix': False, 'normalize': False, 'conv2d_norm': True, 'randomize': True, 'savedir': 'ww-img', 'savefig': 'ww-img', 'rescale': True, 'plot': False, 'deltaEs': False, 'intra': False, 'channels': None, 'conv2d_fft': False, 'ww2x': False, 'vectors': True, 'smooth': None, 'stacked': False, 'svd_method': 'accurate', 'fix_fingers': None, 'fit': 'power_law', 'sparsify': True, 'detX': True, 'mp_fit': False, 'min_evals': 0, 'max_evals': None, 'max_N': 10, 'tolerance': 1e-06, 'layer_ids_start': 0, 'add_biases': False, 'glorot_fit': False, 'layers': []}\n",
      "INFO:weightwatcher:Saving all images to ww-img\n",
      "INFO:weightwatcher:torch version 1.12.1\n",
      "INFO:weightwatcher:framework from model = 16\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 64x3 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=64 M=3 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 64 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 1 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (64, 3, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 128x64 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=128 M=64 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 128 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 2 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (128, 64, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 256x128 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=128 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 3 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (256, 128, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 256x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=256 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 4 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (256, 256, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=256 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 5 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (512, 256, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 6 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (512, 512, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 7 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (512, 512, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 8 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (512, 512, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:layer_supported  N 25088 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 9 4  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (4096, 25088)  max size None\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 10 4  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (4096, 4096)  max size None\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 11 4  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (1000, 4096)  max size None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_id</th>\n",
       "      <th>name</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>Q</th>\n",
       "      <th>layer_type</th>\n",
       "      <th>longname</th>\n",
       "      <th>num_evals</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>features.0</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>LAYER_TYPE.CONV2D</td>\n",
       "      <td>features.0</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>features.3</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>LAYER_TYPE.CONV2D</td>\n",
       "      <td>features.3</td>\n",
       "      <td>576</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>features.6</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>LAYER_TYPE.CONV2D</td>\n",
       "      <td>features.6</td>\n",
       "      <td>1152</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>features.8</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>LAYER_TYPE.CONV2D</td>\n",
       "      <td>features.8</td>\n",
       "      <td>2304</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>features.11</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>LAYER_TYPE.CONV2D</td>\n",
       "      <td>features.11</td>\n",
       "      <td>2304</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>features.13</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>LAYER_TYPE.CONV2D</td>\n",
       "      <td>features.13</td>\n",
       "      <td>4608</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>features.16</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>LAYER_TYPE.CONV2D</td>\n",
       "      <td>features.16</td>\n",
       "      <td>4608</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>features.18</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>LAYER_TYPE.CONV2D</td>\n",
       "      <td>features.18</td>\n",
       "      <td>4608</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>classifier.0</td>\n",
       "      <td>4096</td>\n",
       "      <td>25088</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>LAYER_TYPE.DENSE</td>\n",
       "      <td>classifier.0</td>\n",
       "      <td>4096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>classifier.3</td>\n",
       "      <td>4096</td>\n",
       "      <td>4096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>LAYER_TYPE.DENSE</td>\n",
       "      <td>classifier.3</td>\n",
       "      <td>4096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>classifier.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>4096</td>\n",
       "      <td>4.096000</td>\n",
       "      <td>LAYER_TYPE.DENSE</td>\n",
       "      <td>classifier.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    layer_id          name     M      N          Q         layer_type  \\\n",
       "0          1    features.0     3     64  21.333333  LAYER_TYPE.CONV2D   \n",
       "1          2    features.3    64    128   2.000000  LAYER_TYPE.CONV2D   \n",
       "2          3    features.6   128    256   2.000000  LAYER_TYPE.CONV2D   \n",
       "3          4    features.8   256    256   1.000000  LAYER_TYPE.CONV2D   \n",
       "4          5   features.11   256    512   2.000000  LAYER_TYPE.CONV2D   \n",
       "5          6   features.13   512    512   1.000000  LAYER_TYPE.CONV2D   \n",
       "6          7   features.16   512    512   1.000000  LAYER_TYPE.CONV2D   \n",
       "7          8   features.18   512    512   1.000000  LAYER_TYPE.CONV2D   \n",
       "8          9  classifier.0  4096  25088   6.125000   LAYER_TYPE.DENSE   \n",
       "9         10  classifier.3  4096   4096   1.000000   LAYER_TYPE.DENSE   \n",
       "10        11  classifier.6  1000   4096   4.096000   LAYER_TYPE.DENSE   \n",
       "\n",
       "        longname  num_evals  rf  \n",
       "0     features.0         27   9  \n",
       "1     features.3        576   9  \n",
       "2     features.6       1152   9  \n",
       "3     features.8       2304   9  \n",
       "4    features.11       2304   9  \n",
       "5    features.13       4608   9  \n",
       "6    features.16       4608   9  \n",
       "7    features.18       4608   9  \n",
       "8   classifier.0       4096   1  \n",
       "9   classifier.3       4096   1  \n",
       "10  classifier.6       1000   1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details =  watcher.describe(model=model)\n",
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2_layer = details.layer_id.to_numpy()[-2]\n",
    "fc2_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:weightwatcher:params {'glorot_fix': False, 'normalize': False, 'conv2d_norm': True, 'randomize': True, 'savedir': 'ww-img', 'savefig': 'ww-img', 'rescale': True, 'plot': False, 'deltaEs': False, 'intra': False, 'channels': None, 'conv2d_fft': False, 'ww2x': False, 'vectors': True, 'smooth': None, 'stacked': False, 'svd_method': 'accurate', 'fix_fingers': None, 'fit': 'power_law', 'sparsify': True, 'detX': True, 'mp_fit': False, 'min_evals': 0, 'max_evals': None, 'max_N': 10, 'tolerance': 1e-06, 'layer_ids_start': 0, 'add_biases': False, 'glorot_fit': False, 'layers': []}\n",
      "INFO:weightwatcher:Saving all images to ww-img\n",
      "INFO:weightwatcher:params {'glorot_fix': False, 'normalize': False, 'conv2d_norm': True, 'randomize': True, 'savedir': 'ww-img', 'savefig': 'ww-img', 'rescale': True, 'plot': False, 'deltaEs': False, 'intra': False, 'channels': None, 'conv2d_fft': False, 'ww2x': False, 'vectors': True, 'smooth': None, 'stacked': False, 'svd_method': 'accurate', 'fix_fingers': None, 'fit': 'power_law', 'sparsify': True, 'detX': True, 'mp_fit': False, 'min_evals': 0, 'max_evals': None, 'max_N': 10, 'tolerance': 1e-06, 'layer_ids_start': 0, 'add_biases': False, 'glorot_fit': False, 'layers': []}\n",
      "INFO:weightwatcher:Saving all images to ww-img\n",
      "INFO:weightwatcher:torch version 1.12.1\n",
      "INFO:weightwatcher:framework from model = 16\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 64x3 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=64 M=3 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 64 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 1 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (64, 3, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 128x64 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=128 M=64 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 128 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 2 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (128, 64, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 256x128 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=128 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 3 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (256, 128, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 256x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=256 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 4 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (256, 256, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=256 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 5 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (512, 256, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 6 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (512, 512, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 7 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (512, 512, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 8 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (512, 512, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:layer_supported  N 25088 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 9 4  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (4096, 25088)  max size None\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 10 4  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (4096, 4096)  max size None\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 11 4  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (1000, 4096)  max size None\n",
      "INFO:weightwatcher:torch version 1.12.1\n",
      "INFO:weightwatcher:framework from model = 16\n",
      "INFO:weightwatcher:Filtering layer by id 10\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 64x3 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=64 M=3 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 1 features.0 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 64 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 1 features.0 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 128x64 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=128 M=64 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 2 features.3 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 128 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 2 features.3 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 256x128 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=128 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 3 features.6 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 3 features.6 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 256x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=256 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 4 features.8 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 4 features.8 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=256 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 5 features.11 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 5 features.11 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 6 features.13 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 6 features.13 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 7 features.16 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 7 features.16 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 8 features.18 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 8 features.18 is skipped\n",
      "DEBUG:weightwatcher:skipping layer 9 classifier.0 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 25088 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 9 classifier.0 is skipped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weightwatcher:keeping layer 10 classifier.3 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals 10000\n",
      "INFO:weightwatcher:Getting ESD for layer 10 ; ww_layer id = 10\n",
      "DEBUG:weightwatcher:apply ESD  on Layer 10 classifier.3 \n",
      "DEBUG:weightwatcher:running SVD on Layer 10 classifier.3 \n",
      "DEBUG:weightwatcher:params {'glorot_fix': False, 'normalize': False, 'conv2d_norm': True, 'randomize': True, 'savedir': 'ww-img', 'savefig': True, 'rescale': True, 'plot': False, 'deltaEs': False, 'intra': False, 'channels': None, 'conv2d_fft': False, 'ww2x': False, 'vectors': True, 'smooth': None, 'stacked': False, 'svd_method': 'accurate', 'fix_fingers': None, 'fit': 'power_law', 'sparsify': True, 'detX': True, 'mp_fit': False, 'min_evals': 50, 'max_evals': 10000, 'max_N': 10, 'tolerance': 1e-06, 'layer_ids_start': 0, 'add_biases': False} \n",
      "DEBUG:weightwatcher:Running accurate SVD:  W.shape=(4096, 4096)  n_comp = 4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTER 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weightwatcher:Found 4096 eiganvalues for 10 classifier.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esd_b4 = watcher.get_ESD(layer=fc2_layer)\n",
    "len(esd_b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:weightwatcher: Smoothing method svd\n",
      "INFO:weightwatcher:params {'glorot_fix': False, 'normalize': False, 'conv2d_norm': True, 'randomize': True, 'savedir': 'ww-img', 'savefig': True, 'rescale': True, 'plot': False, 'deltaEs': False, 'intra': False, 'channels': None, 'conv2d_fft': False, 'ww2x': False, 'vectors': True, 'smooth': 'svd', 'stacked': False, 'svd_method': 'accurate', 'fix_fingers': None, 'fit': 'PL', 'sparsify': True, 'detX': True, 'mp_fit': False, 'min_evals': 50, 'max_evals': 10000, 'max_N': 10, 'tolerance': 1e-06, 'layer_ids_start': 0, 'add_biases': False, 'layers': [10]}\n",
      "INFO:weightwatcher:Saving all images to ww-img\n",
      "INFO:weightwatcher:params {'glorot_fix': False, 'normalize': False, 'conv2d_norm': True, 'randomize': True, 'savedir': 'ww-img', 'savefig': True, 'rescale': True, 'plot': False, 'deltaEs': False, 'intra': False, 'channels': None, 'conv2d_fft': False, 'ww2x': False, 'vectors': True, 'smooth': 'svd', 'stacked': False, 'svd_method': 'accurate', 'fix_fingers': None, 'fit': 'power_law', 'sparsify': True, 'detX': True, 'mp_fit': False, 'min_evals': 50, 'max_evals': 10000, 'max_N': 10, 'tolerance': 1e-06, 'layer_ids_start': 0, 'add_biases': False, 'layers': [10]}\n",
      "INFO:weightwatcher:Saving all images to ww-img\n",
      "INFO:weightwatcher:torch version 1.12.1\n",
      "INFO:weightwatcher:framework from model = 16\n",
      "INFO:weightwatcher:Filtering layer by id 10\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 64x3 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=64 M=3 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 1 features.0 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 64 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 1 features.0 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 128x64 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=128 M=64 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 2 features.3 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 128 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 2 features.3 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 256x128 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=128 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 3 features.6 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 3 features.6 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 256x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=256 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 4 features.8 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 4 features.8 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=256 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 5 features.11 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 5 features.11 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 6 features.13 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 6 features.13 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 7 features.16 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 7 features.16 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 8 features.18 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 8 features.18 is skipped\n",
      "DEBUG:weightwatcher:skipping layer 9 classifier.0 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 25088 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 9 classifier.0 is skipped\n",
      "DEBUG:weightwatcher:keeping layer 10 classifier.3 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals 10000\n",
      "INFO:weightwatcher:LAYER: 10 4  : <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "INFO:weightwatcher:apply truncated SVD on Layer 10 classifier.3, with nsmooth=819,  keeping ncomp=819 out of 4096. of the singular vectors\n",
      "INFO:weightwatcher:LAYER TYPE  4 out of 4 8 64 \n",
      "DEBUG:weightwatcher:Keeping top 819 singular values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTER 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weightwatcher:smoothed W (4096, 4096) -> (4096, 4096) n_comp=819\n",
      "DEBUG:weightwatcher:skipping layer 11 classifier.6 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 11 classifier.6 is skipped\n",
      "INFO:weightwatcher:Returning smoothed model\n"
     ]
    }
   ],
   "source": [
    "watcher.SVDSmoothing(layers=[fc2_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:weightwatcher:params {'glorot_fix': False, 'normalize': False, 'conv2d_norm': True, 'randomize': True, 'savedir': 'ww-img', 'savefig': 'ww-img', 'rescale': True, 'plot': False, 'deltaEs': False, 'intra': False, 'channels': None, 'conv2d_fft': False, 'ww2x': False, 'vectors': True, 'smooth': None, 'stacked': False, 'svd_method': 'accurate', 'fix_fingers': None, 'fit': 'power_law', 'sparsify': True, 'detX': True, 'mp_fit': False, 'min_evals': 0, 'max_evals': None, 'max_N': 10, 'tolerance': 1e-06, 'layer_ids_start': 0, 'add_biases': False, 'glorot_fit': False, 'layers': []}\n",
      "INFO:weightwatcher:Saving all images to ww-img\n",
      "INFO:weightwatcher:params {'glorot_fix': False, 'normalize': False, 'conv2d_norm': True, 'randomize': True, 'savedir': 'ww-img', 'savefig': 'ww-img', 'rescale': True, 'plot': False, 'deltaEs': False, 'intra': False, 'channels': None, 'conv2d_fft': False, 'ww2x': False, 'vectors': True, 'smooth': None, 'stacked': False, 'svd_method': 'accurate', 'fix_fingers': None, 'fit': 'power_law', 'sparsify': True, 'detX': True, 'mp_fit': False, 'min_evals': 0, 'max_evals': None, 'max_N': 10, 'tolerance': 1e-06, 'layer_ids_start': 0, 'add_biases': False, 'glorot_fit': False, 'layers': []}\n",
      "INFO:weightwatcher:Saving all images to ww-img\n",
      "INFO:weightwatcher:torch version 1.12.1\n",
      "INFO:weightwatcher:framework from model = 16\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 64x3 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=64 M=3 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 64 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 1 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (64, 3, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 128x64 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=128 M=64 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 128 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 2 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (128, 64, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 256x128 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=128 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 3 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (256, 128, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 256x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=256 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 4 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (256, 256, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=256 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 5 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (512, 256, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 6 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (512, 512, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 7 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (512, 512, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 8 16  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (512, 512, 3, 3)  max size None\n",
      "DEBUG:weightwatcher:layer_supported  N 25088 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 9 4  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (4096, 25088)  max size None\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 10 4  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (4096, 4096)  max size None\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals None\n",
      "DEBUG:weightwatcher:LAYER TYPE: 11 4  layer type <class 'weightwatcher.weightwatcher.PyStateDictLayer'>\n",
      "DEBUG:weightwatcher:weights shape : (1000, 4096)  max size None\n",
      "INFO:weightwatcher:torch version 1.12.1\n",
      "INFO:weightwatcher:framework from model = 16\n",
      "INFO:weightwatcher:Filtering layer by id 10\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 64x3 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=64 M=3 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 1 features.0 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 64 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 1 features.0 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 128x64 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=128 M=64 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 2 features.3 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 128 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 2 features.3 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 256x128 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=128 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 3 features.6 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 3 features.6 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 256x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=256 M=256 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 4 features.8 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 256 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 4 features.8 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x256 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=256 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 5 features.11 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 5 features.11 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 6 features.13 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 6 features.13 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 7 features.16 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 7 features.16 is skipped\n",
      "DEBUG:weightwatcher:conv2D_Wmats\n",
      "DEBUG:weightwatcher:channels Last tensor shape: 512x512 (NxM), 3x3 (i,j)\n",
      "DEBUG:weightwatcher:get_conv2D_Wmats N=512 M=512 rf= 9 channels= 4\n",
      "DEBUG:weightwatcher:skipping layer 8 features.18 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 512 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 8 features.18 is skipped\n",
      "DEBUG:weightwatcher:skipping layer 9 classifier.0 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 25088 max evals 10000\n",
      "DEBUG:weightwatcher:Layer 9 classifier.0 is skipped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weightwatcher:keeping layer 10 classifier.3 by id\n",
      "DEBUG:weightwatcher:layer_supported  N 4096 max evals 10000\n",
      "INFO:weightwatcher:Getting ESD for layer 10 ; ww_layer id = 10\n",
      "DEBUG:weightwatcher:apply ESD  on Layer 10 classifier.3 \n",
      "DEBUG:weightwatcher:running SVD on Layer 10 classifier.3 \n",
      "DEBUG:weightwatcher:params {'glorot_fix': False, 'normalize': False, 'conv2d_norm': True, 'randomize': True, 'savedir': 'ww-img', 'savefig': True, 'rescale': True, 'plot': False, 'deltaEs': False, 'intra': False, 'channels': None, 'conv2d_fft': False, 'ww2x': False, 'vectors': True, 'smooth': None, 'stacked': False, 'svd_method': 'accurate', 'fix_fingers': None, 'fit': 'power_law', 'sparsify': True, 'detX': True, 'mp_fit': False, 'min_evals': 50, 'max_evals': 10000, 'max_N': 10, 'tolerance': 1e-06, 'layer_ids_start': 0, 'add_biases': False} \n",
      "DEBUG:weightwatcher:Running accurate SVD:  W.shape=(4096, 4096)  n_comp = 4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTER 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weightwatcher:Found 4096 eiganvalues for 10 classifier.3\n"
     ]
    }
   ],
   "source": [
    "esd_aftr = watcher.get_ESD(layer=fc2_layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(esd_b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 819)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(esd_b4[esd_b4>10**-10]), len(esd_aftr[esd_aftr>10**-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log10(esd_b4), bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.567443007721141e-10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(esd_b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
