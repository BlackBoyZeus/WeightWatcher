{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/CalculatedContent/WeightWatcher/blob/master/examples/WeightWatcher-VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# WeightWatcher - VGG\n",
    "\n",
    "https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "VGG is one of the first, large scale modern architectures based on the classic convolutional model of LeCun, resembling a larger scale version of LeNet5.  While there are earlier models (AlexNet, etc), VGG is usefukl because:\n",
    "\n",
    "-  There are several variants, with 11, 13, 16, and 19 layers, and with and wthout Batch Normalization\n",
    "-  It is widely available in pyTorch and other frameworks\n",
    "-  There are versions trained on all of ImageNet, ImageNet-1K (a smaller data set), etc.\n",
    "-  Although large,  is still used in Transfer Learning.\n",
    "\n",
    "The general VGG series architecture consists of \n",
    "\n",
    "-  Several sets of Conv2D+ReLU layers (followed by Max Pooling), with feature maps increasing in size\n",
    "-  3 final Fully Connected (Dense/Linear) layers\n",
    "\n",
    "Below we show the VGG16 architecture, consisting of 16 layers.\n",
    "\n",
    "The VGG series are considered very large models, with an enormous number of parameters comparexd to later models like ResNet and DenseNet series.  Most notably, compared to later models,\n",
    "\n",
    "-  VGG models contain large, FC layers at the end\n",
    "-  VGG does not contain residual connections\n",
    "\n",
    "(note: Figures may not display in Google Colab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!touch VGG16.1.png VGG16.2.png CV-models.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='VGG16.1.png',width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='VGG16.2.png',width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is noted that the VGGNet model (16?) has ov er 2X the number of parameters as one of the largest ResNet models, with far less top5 accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='CV-models.png',width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of results\n",
    "\n",
    "\n",
    "We first compute the Average Alpha $\\langle\\alpha\\rangle$ for all models, and compare to the Test Accuracy accross the models.  In contrast to expectations, and other models like ResNet, on average, $\\langle\\alpha\\rangle$ is increasing with Test Accuracy instead of decreasing.  In fact, $\\langle\\alpha\\rangle$ is strongly *negatively correlated* with reported Test Accuracy.  \n",
    "\n",
    "#### Why is this ?\n",
    "\n",
    "If we look at $\\alpha$ vs Layer Id, we see that  $\\alpha$ is increasing with Layer Id. That is, as information flows thorugh the network, the layers are less and less correlated.  THis suggests (to me) that the VGG networks are fairly bad at funneling information through the network.\n",
    "\n",
    "Instead, we need to use the Weighted Alpha metric $\\hat{\\alpha}$ , which is positively correlated with the Test Accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T23:51:16.544327Z",
     "start_time": "2019-03-05T23:51:16.531457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress the powerlaw package warnings\n",
    "# \"powerlaw.py:700: RuntimeWarning: divide by zero encountered in true_divide\"\n",
    "# \"powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\"\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install weightwatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T00:16:43.249725Z",
     "start_time": "2019-03-06T00:16:43.240611Z"
    }
   },
   "source": [
    "### Import WeightWatcher\n",
    "\n",
    "set custom Logging at WARN Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import weightwatcher as ww\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(ww.__name__)\n",
    "logger.setLevel(logging.INFO) \n",
    "\n",
    "\n",
    "ww.__version__,  torchvision.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all models now\n",
    "\n",
    "Pick colors from https://matplotlib.org/3.1.0/gallery/color/named_colors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_name = 'VGG'\n",
    "all_names = [ 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn']\n",
    "colors =    ['indigo', 'blue',    'purple',  'cyan',   'darkgreen','goldenrod','darkorange','red']\n",
    "\n",
    "\n",
    "all_models = []\n",
    "all_models.append(models.vgg11(weights=\"IMAGENET1K_V1\"))\n",
    "all_models.append(models.vgg11_bn(weights=\"IMAGENET1K_V1\"))\n",
    "\n",
    "all_models.append(models.vgg13(weights=\"IMAGENET1K_V1\"))\n",
    "all_models.append(models.vgg13_bn(weights=\"IMAGENET1K_V1\"))\n",
    "\n",
    "all_models.append(models.vgg16(weights=\"IMAGENET1K_V1\"))\n",
    "all_models.append(models.vgg16_bn(weights=\"IMAGENET1K_V1\"))\n",
    "\n",
    "all_models.append(models.vgg19(weights=\"IMAGENET1K_V1\"))\n",
    "all_models.append(models.vgg19_bn(weights=\"IMAGENET1K_V1\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reported accuracies from pytorch website\n",
    "\n",
    "https://pytorch.org/docs/stable/torchvision/models.html\n",
    "\n",
    "<pre>\n",
    "<table class=\"docutils align-default\">\n",
    "<colgroup>\n",
    "<col style=\"width: 55%\" />\n",
    "<col style=\"width: 22%\" />\n",
    "<col style=\"width: 22%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<thead>\n",
    "<tr class=\"row-odd\"><th class=\"head\"><p>Network</p></th>\n",
    "<th class=\"head\"><p>Top-1 error</p></th>\n",
    "<th class=\"head\"><p>Top-5 error</p></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "\n",
    "<tr class=\"row-odd\"><td><p>VGG-11</p></td>\n",
    "<td><p>30.98</p></td>\n",
    "<td><p>11.37</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>VGG-13</p></td>\n",
    "<td><p>30.07</p></td>\n",
    "<td><p>10.75</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>VGG-16</p></td>\n",
    "<td><p>28.41</p></td>\n",
    "<td><p>9.62</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>VGG-19</p></td>\n",
    "<td><p>27.62</p></td>\n",
    "<td><p>9.12</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>VGG-11 with batch normalization</p></td>\n",
    "<td><p>29.62</p></td>\n",
    "<td><p>10.19</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>VGG-13 with batch normalization</p></td>\n",
    "<td><p>28.45</p></td>\n",
    "<td><p>9.63</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>VGG-16 with batch normalization</p></td>\n",
    "<td><p>26.63</p></td>\n",
    "<td><p>8.50</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>VGG-19 with batch normalization</p></td>\n",
    "<td><p>25.76</p></td>\n",
    "<td><p>8.15</p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top1_errors= {\n",
    "    \n",
    "    \"vgg11\": 30.98,\n",
    "    \"vgg11_bn\": 29.62,\n",
    "    \"vgg13\": 30.07,\n",
    "    \"vgg13_bn\": 28.45,\n",
    "    \"vgg16\": 28.41,\n",
    "    \"vgg16_bn\": 26.63,\n",
    "    \"vgg19\": 27.62,\n",
    "    \"vgg19_bn\": 25.76,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top5_errors= {\n",
    "    \n",
    "    \"vgg11\": 11.37,\n",
    "    \"vgg11_bn\": 10.19,\n",
    "    \"vgg13\": 10.75,\n",
    "    \"vgg13_bn\": 9.63,\n",
    "    \"vgg16\": 9.62,\n",
    "    \"vgg16_bn\": 8.50,\n",
    "    \"vgg19\": 9.12,\n",
    "    \"vgg19_bn\": 8.15,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run WeightWatcher, collect summary and details (as dataframes) for all models\n",
    "\n",
    " The following metrics are analyzed below\n",
    " \n",
    "- 'log_norm'\n",
    "- 'alpha'\n",
    "- 'alpha_weighted'\n",
    "\n",
    "Other metrics are available by default in the summary statistics\n",
    "\n",
    "    'log_alpha_norm', 'log_spectral_norm', 'stable_rank', 'mp_softrank'\n",
    "    \n",
    "For new metrics, the summary can be computed directly from the details dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "all_summaries, all_details = [], []\n",
    "for im, name in enumerate(tqdm(all_names)):\n",
    "    print(im, name)\n",
    "    watcher = ww.WeightWatcher(model=all_models[im]) \n",
    "    details = watcher.analyze(ww2x=True, mp_fit=True, randomize=False, vectors=False, min_evals=50)\n",
    "    all_details.append(details)\n",
    "    all_summaries.append(watcher.get_summary(details))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The summary contains the following metrics (currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "from pylab import rcParams\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (7,7),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_accuracy(metric, xlabel, title, series_name, \\\n",
    "                       all_names, all_summaries, top_errors, save=False):\n",
    "    \"\"\"Create plot of Metric vs Reported Test Accuracy, and run Linear Regression\"\"\"\n",
    "    \n",
    "    num = len(all_names)\n",
    "    xs, ys = np.empty(num), np.empty(num)\n",
    "    for im, modelname in enumerate(all_names):    \n",
    "\n",
    "        summary = all_summaries[im]\n",
    "        x = summary[metric]\n",
    "        xs[im] = x\n",
    "\n",
    "        error = top_errors[modelname]\n",
    "        y = 100.0-error\n",
    "        ys[im] = y\n",
    "\n",
    "        label = modelname\n",
    "        plt.scatter(x, y, label=label)\n",
    "\n",
    "\n",
    "    xs = xs.reshape(-1,1)\n",
    "    ys = ys.reshape(-1,1)\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(xs, ys)\n",
    "    y_pred = regr.predict(xs)\n",
    "    plt.plot(xs, y_pred, color='red', linewidth=1)\n",
    "\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(ys, y_pred))\n",
    "    r2 = metrics.r2_score(ys, y_pred)\n",
    "\n",
    "    tau, p_value = stats.kendalltau(xs, ys)\n",
    "    title2 = \" RMSE: {:0.2} K-tau {:0.2}\".format(rmse, r2, tau)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(\"Test Accuracy vs \"+title+\"\\n\"+xlabel+title2)\n",
    "    plt.ylabel(r\"Test Accuracy\")\n",
    "    plt.xlabel(xlabel);\n",
    "    \n",
    "    if save:\n",
    "        figname = \"img/{}_{}_accs.png\".format(series_name, metric)\n",
    "        print(\"saving {}\".format(figname))\n",
    "        plt.savefig(figname)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots of Test Accuracy vs WeightWatcher metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = \"log_norm\"\n",
    "xlabel = r\"$\\langle\\log\\Vert W\\Vert_{F}\\rangle$\"\n",
    "title = \"Avg. log Frobenius Norm \"\n",
    "plot_test_accuracy(metric, xlabel, title, series_name, all_names, all_summaries, top1_errors, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"alpha\"\n",
    "xlabel = r\"$\\langle\\alpha\\rangle$\"\n",
    "title = \"Avg. Alpha  \"\n",
    "plot_test_accuracy(metric, xlabel, title, series_name, all_names, all_summaries, top1_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"alpha_weighted\"\n",
    "xlabel = r\"$\\hat{\\alpha}$\"\n",
    "plot_test_accuracy(metric, xlabel, title, series_name,  all_names, all_summaries, top1_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Flow\n",
    "\n",
    "VGG is an odd architecture in the that Alpha $\\alpha$ metric gets worse with increasing depth\n",
    "\n",
    "This suggests that the Correlation Flow is so poor that we can not use the layer-averaged Alpha $\\alpha$ metric as a total model metric,\n",
    "\n",
    "Notice that the Flow of ALpha-Hat $(\\hat{\\alpha})$ is more aligned between models of very different depths (VGG11 vs VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_flow(metric, ylabel, title, series_name,\n",
    "    all_names, all_details, colors, log=False, valid_ids = [], save=False):\n",
    "    \n",
    "    transparency = 1.0\n",
    "      \n",
    "    if len(valid_ids) == 0:\n",
    "        valid_ids = range(len(all_details)-1)\n",
    "        idname='all'\n",
    "    else:\n",
    "        idname='fnl'\n",
    "        \n",
    "        \n",
    "    for im, details in enumerate(all_details):\n",
    "        if im in valid_ids:\n",
    "            \n",
    "            details = all_details[im]\n",
    "            name = all_names[im]\n",
    "            x = details.index.to_numpy()\n",
    "            y = details[metric].to_numpy()\n",
    "            if log:\n",
    "                y = np.log10(np.array(y+0.000001, dtype=np.float))\n",
    "\n",
    "            plt.scatter(x,y, label=name, color=colors[im])\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(\"Depth vs \"+title+\" \"+ylabel)\n",
    "    plt.xlabel(\"Layer id\")\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    if save:\n",
    "        figname = \"img/{}_{}_{}_depth.png\".format(series_name, idname, metric)\n",
    "        print(\"saving {}\".format(figname))\n",
    "        plt.savefig(figname)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"alpha\"\n",
    "xlabel = r\"Alpha $\\alpha$\"\n",
    "title = 'VGG'\n",
    "plot_correlation_flow(metric, xlabel, title, series_name, all_names, all_details, colors, log=False, valid_ids = [0, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"alpha_weighted\"\n",
    "xlabel = r\"Alpha-Hat $(\\hat{\\alpha})$\"\n",
    "title = 'VGG'\n",
    "plot_correlation_flow(metric, xlabel, title, series_name, all_names, all_details, colors, log=False, valid_ids = [0, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
