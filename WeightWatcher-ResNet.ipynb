{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeightWatcher ResNet\n",
    "\n",
    "https://calculationconsulting.com\n",
    "\n",
    "\n",
    "### Analysis of pyTorch ResNet Models\n",
    "\n",
    "ResNet, with the same number of layers,  is a much smaller model than VGG, with 20X less parameters.\n",
    "\n",
    "We will see the power law exponents $\\alpha$ approach 2 (or less) and do not vary much between layers until the very end, where the power law model breaks down and we have bulk+spikes.  Compare this to VGG, where $\\alpha$ immediately increases with layer depth\n",
    "\n",
    "Moreover, the average exponent $\\langle\\alpha\\langle$ decreaes with test error, whereas for the VGG series, only the weighted alpha $\\hat{\\alpha}$  decreases with test error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='CV-models.png',width=800, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='resnet18.png',width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of VGG and ResNet\n",
    "\n",
    "https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035\n",
    "\n",
    "### Key Idea:  Residual Connections\n",
    "\n",
    "Improves gradient / information flow through the network\n",
    "\n",
    "Because of this, there are much deeper ResNet variants.  In fact, some researchers have trained ResNet variants with 1001 layers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "In contrast to the VGG series, the ResNet Average Alpha $\\langle\\alpha\\rangle$ is positively correlated with the Test Error:  smaller average alpha corresponds to better generalization.  Moreover, the layer $\\alpha$ are fairly constant, and near $2.0$, for at least $3/4$ of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T23:51:16.544327Z",
     "start_time": "2019-03-05T23:51:16.531457Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Suppress the powerlaw package warnings\n",
    "# \"powerlaw.py:700: RuntimeWarning: divide by zero encountered in true_divide\"\n",
    "# \"powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\"\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T22:51:12.554859Z",
     "start_time": "2018-10-01T22:51:12.518859Z"
    }
   },
   "source": [
    "### Import WeightWatcher\n",
    "\n",
    "set custom Logging at WARN Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T00:16:41.769719Z",
     "start_time": "2019-03-06T00:16:38.803181Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARN)\n",
    "\n",
    "import weightwatcher as ww\n",
    "import torchvision.models as models\n",
    "\n",
    "ww.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all models now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "series_name = 'ResNet'\n",
    "all_names = [ 'resnet18', 'resnet34', 'resnet50', 'resnet101','resnet152']\n",
    "\n",
    "colors = ['blue', 'green', 'teal', 'orange', 'red']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T00:16:43.249725Z",
     "start_time": "2019-03-06T00:16:43.240611Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_models = []\n",
    "all_models.append(models.resnet18(pretrained=True))\n",
    "all_models.append(models.resnet34(pretrained=True))\n",
    "all_models.append(models.resnet50(pretrained=True))\n",
    "all_models.append(models.resnet101(pretrained=True))\n",
    "all_models.append(models.resnet152(pretrained=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reported accuracies from pytorch website\n",
    "\n",
    "https://pytorch.org/docs/stable/torchvision/models.html\n",
    "\n",
    "<pre>\n",
    "<table class=\"docutils align-default\">\n",
    "<colgroup>\n",
    "<col style=\"width: 55%\" />\n",
    "<col style=\"width: 22%\" />\n",
    "<col style=\"width: 22%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<thead>\n",
    "<tr class=\"row-odd\"><th class=\"head\"><p>Network</p></th>\n",
    "<th class=\"head\"><p>Top-1 error</p></th>\n",
    "<th class=\"head\"><p>Top-5 error</p></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "\n",
    "<tr class=\"row-odd\"><td><p>ResNet-18</p></td>\n",
    "<td><p>30.24</p></td>\n",
    "<td><p>10.92</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>ResNet-34</p></td>\n",
    "<td><p>26.70</p></td>\n",
    "<td><p>8.58</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>ResNet-50</p></td>\n",
    "<td><p>23.85</p></td>\n",
    "<td><p>7.13</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>ResNet-101</p></td>\n",
    "<td><p>22.63</p></td>\n",
    "<td><p>6.44</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>ResNet-152</p></td>\n",
    "<td><p>21.69</p></td>\n",
    "<td><p>5.94</p></td>\n",
    "</tr>\n",
    "\n",
    "</tbody>\n",
    "</table>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_errors= {\n",
    "    \n",
    "    \"resnet18\": 30.24,\n",
    "    \"resnet34\": 26.70,\n",
    "    \"resnet50\": 23.85,\n",
    "    \"resnet101\": 22.63,\n",
    "    \"resnet152\": 21.69 \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_errors= {\n",
    "    \n",
    "    \"resnet18\": 10.92,\n",
    "    \"resnet34\": 8.58,\n",
    "    \"resnet50\": 7.13,\n",
    "    \"resnet101\": 6.44,\n",
    "    \"resnet152\": 5.94    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run WeightWatcher, collect summary and details (as dataframes) for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_details = []\n",
    "all_summaries = []\n",
    "for im, name in enumerate(all_names):\n",
    "    watcher = ww.WeightWatcher(model=all_models[im], logger=logger)\n",
    "    results = watcher.analyze(alphas=True, softranks=True, spectralnorms=True, mp_fit=True)\n",
    "\n",
    "    summary =  watcher.get_summary()\n",
    "    all_summaries.append(summary)\n",
    "    details  = watcher.get_details(results=results)\n",
    "    details.drop(columns=['slice', 'slice_count'], inplace=True)\n",
    "    details.dropna(inplace=True)\n",
    "    details['NxM'] = pd.to_numeric(details.N * details.M)\n",
    "\n",
    "    all_details.append(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "def plot_test_accuracy(metric, xlabel, title):\n",
    "    \"\"\"Create plot of Metric vs Reported Test Accuracy, and run Linear Regression\"\"\"\n",
    "    num = len(all_names)\n",
    "    xs, ys = np.empty(num), np.empty(num)\n",
    "    for im, modelname in enumerate(all_names):    \n",
    "\n",
    "        summary = all_summaries[im]\n",
    "        x = summary[metric]\n",
    "        xs[im] = x\n",
    "\n",
    "        error = top1_errors[modelname]\n",
    "        y = 100.0-error\n",
    "        ys[im] = y\n",
    "\n",
    "        label = modelname\n",
    "        plt.scatter(x, y, label=label)\n",
    "\n",
    "\n",
    "    xs = xs.reshape(-1,1)\n",
    "    ys = ys.reshape(-1,1)\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(xs, ys)\n",
    "    y_pred = regr.predict(xs)\n",
    "    plt.plot(xs, y_pred, color='red', linewidth=1)\n",
    "\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(ys, y_pred))\n",
    "    r2 = metrics.r2_score(ys, y_pred)\n",
    "    title2 = \"RMSE: {0:.2}   R2: {0:.2}\".format(rmse, r2)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(r\"Test Accuracy vs \"+title+\"\\n\"+title2)\n",
    "    plt.ylabel(r\"Test Accuracy\")\n",
    "    plt.xlabel(xlabel);\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_histogram(metric, xlabel, title, log=False, valid_ids = []):\n",
    "    transparency = 1.0\n",
    "    \n",
    "    if len(valid_ids) == 0:\n",
    "        valid_ids = range(len(all_details)-1)\n",
    "        \n",
    "    for im, details in enumerate(all_details):\n",
    "        if im in valid_ids:\n",
    "            vals = details[metric].to_numpy()\n",
    "            if log:\n",
    "                vals = np.log10(np.array(vals+0.000001, dtype=np.float))\n",
    "\n",
    "            plt.hist(vals, bins=100, label=all_names[im], alpha=transparency, color=colors[im], density=True)\n",
    "            transparency -= 0.15\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_depth(metric, ylabel, title, log=False, valid_ids = []):\n",
    "    transparency = 1.0\n",
    "    \n",
    "    if len(valid_ids) == 0:\n",
    "        valid_ids = range(len(all_details)-1)\n",
    "        \n",
    "    for im, details in enumerate(all_details):\n",
    "        if im in valid_ids:\n",
    "            \n",
    "            details = all_details[im]\n",
    "            name = all_names[im]\n",
    "            x = details.index.to_numpy()\n",
    "            y = details[metric].to_numpy()\n",
    "            if log:\n",
    "                y = np.log10(np.array(y+0.000001, dtype=np.float))\n",
    "\n",
    "            plt.scatter(x,y, label=name, color=colors[im])\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Layer id\")\n",
    "    plt.ylabel(xlabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics vs Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric = \"lognorm\"\n",
    "xlabel = r\"$\\langle\\log\\Vert W\\Vert\\rangle_{F}$\"\n",
    "title = \"Average Log Frobenius Norm \"+xlabel\n",
    "plot_test_accuracy(metric, xlabel, title)\n",
    "\n",
    "\n",
    "metric = \"alpha\"\n",
    "xlabel = r\"$\\langle\\alpha\\rangle$\"\n",
    "title = \"Average  Alpha  \"+xlabel\n",
    "plot_test_accuracy(metric, xlabel, title)\n",
    "\n",
    "metric = \"alpha_weighted\"\n",
    "xlabel = r\"$\\hat{\\alpha}$\"\n",
    "title = \"Average Weighted Alpha  \"+xlabel\n",
    "plot_test_accuracy(metric, xlabel, title)\n",
    "\n",
    "metric = \"spectralnorm\"\n",
    "xlabel = r\"$\\langle\\log\\;\\Vert\\mathbf{W}\\Vert_{2}\\rangle$\"\n",
    "title = \"Average Log Spectral Norm  \"+xlabel\n",
    "plot_test_accuracy(metric, xlabel, title)\n",
    "\n",
    "metric = \"softranklog\"\n",
    "xlabel = r\"$\\langle\\log\\;\\mathcal{R}_{s}\\rangle$\"\n",
    "title = \"Average Log Stable Rank \"+xlabel\n",
    "plot_test_accuracy(metric, xlabel, title)\n",
    "\n",
    "metric = \"softrank_mp\"\n",
    "xlabel = r\"$\\langle\\log\\;\\mathcal{R}_{mp}\\rangle$\"\n",
    "title = \"Average Log MP Soft Rank \"+xlabel\n",
    "plot_test_accuracy(metric, xlabel, title)\n",
    "\n",
    "metric = \"logpnorm\"\n",
    "xlabel = r\"$\\langle\\log\\;\\Vert\\mathbf{W}\\Vert^{2\\alpha}_{2\\alpha}\\rangle$\"\n",
    "title = \"Average Log pNorm \"+xlabel\n",
    "plot_test_accuracy(metric, xlabel, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of metrics for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_n_last_ids = [0, len(all_details)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"lognorm\"\n",
    "xlabel = r\"Log Frobenius Norm $\\langle\\log\\Vert\\mathbf{W}\\Vert\\rangle_{F}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title)\n",
    "plot_metrics_histogram(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"alpha\"\n",
    "xlabel = r\"Alpha $\\alpha$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title)\n",
    "plot_metrics_histogram(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"alpha_weighted\"\n",
    "xlabel = r\"Weighted Alpha $\\hat{\\alpha}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title)\n",
    "plot_metrics_histogram(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"softranklog\"\n",
    "xlabel = r\"Log Stable Rank $\\log\\;\\mathcal{R}_{s}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title)\n",
    "plot_metrics_histogram(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"spectralnorm\"\n",
    "xlabel = r\"Log Spectral Norm $\\log\\;\\Vert\\mathbf{W}\\Vert_{2}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title, log=True)\n",
    "plot_metrics_histogram(metric, xlabel, title, log=True, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"softrank_mp\"\n",
    "xlabel = r\"Log MP Soft Rank $\\log\\;\\mathcal{R}_{mp}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title)\n",
    "plot_metrics_histogram(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "metric = \"logpnorm\"\n",
    "xlabel = r\"Log p-Norm $\\log\\;\\Vert\\mathbf{W}\\Vert^{2\\alpha}_{2\\alpha}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_histogram(metric, xlabel, title)\n",
    "plot_metrics_histogram(metric, xlabel, title, valid_ids = first_n_last_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics as a function of depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"lognorm\"\n",
    "xlabel = r\"Log Frobenius Norm $\\langle\\log\\;\\Vert\\mathbf{W}\\Vert\\rangle_{F}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title)\n",
    "plot_metrics_depth(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"alpha\"\n",
    "xlabel = r\"Alpha $\\alpha$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title)\n",
    "plot_metrics_depth(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"alpha_weighted\"\n",
    "xlabel = r\"Weighted Alpha $\\hat{\\alpha}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title)\n",
    "plot_metrics_depth(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "\n",
    "metric = \"softranklog\"\n",
    "xlabel = r\"Log Stable Rank $\\log\\;\\mathcal{R}_{s}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title)\n",
    "plot_metrics_depth(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"spectralnorm\"\n",
    "xlabel = r\"Log Spectral Norm $\\log\\;\\Vert\\mathbf{W}\\Vert_{2}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title, log=True)\n",
    "plot_metrics_depth(metric, xlabel, title, log=True, valid_ids = first_n_last_ids)\n",
    "\n",
    "\n",
    "metric = \"softrank_mp\"\n",
    "xlabel = r\"Log MP Soft Rank $\\log\\;\\mathcal{R}_{mp}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title)\n",
    "plot_metrics_depth(metric, xlabel, title, valid_ids = first_n_last_ids)\n",
    "\n",
    "metric = \"logpnorm\"\n",
    "xlabel = r\"Log p-Norm $\\log\\;\\Vert\\mathbf{W}\\Vert^{2\\alpha}_{2\\alpha}$\"\n",
    "title = series_name+\" \"+xlabel\n",
    "plot_metrics_depth(metric, xlabel, title)\n",
    "plot_metrics_depth(metric, xlabel, title, valid_ids = first_n_last_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
