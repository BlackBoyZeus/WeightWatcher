{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeightWatcher\n",
    "\n",
    "https://calculationconsulting.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T00:40:06.579614Z",
     "start_time": "2018-11-27T00:40:06.567687Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Suppress the powerlaw package warnings\n",
    "# \"powerlaw.py:700: RuntimeWarning: divide by zero encountered in true_divide\"\n",
    "# \"powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\"\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Quick start example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import your model (Keras or PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T00:40:37.845451Z",
     "start_time": "2018-11-27T00:40:06.590432Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.applications import vgg16\n",
    "\n",
    "kmodel = vgg16.VGG16\n",
    "model = kmodel(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Run WeightWatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T00:40:44.494614Z",
     "start_time": "2018-11-27T00:40:37.852493Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:40:38,601 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 16:40:38,603 INFO Analyzing model 'vgg16' with 23 layers\n",
      "2018-11-26 16:40:39,230 INFO Layer 1: <keras.engine.input_layer.InputLayer object at 0x105271ba8>\n",
      "2018-11-26 16:40:39,232 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 16:40:39,238 INFO Layer 2: <keras.layers.convolutional.Conv2D object at 0xb31554780>\n",
      "2018-11-26 16:40:39,288 INFO Keras tensor shape detected: 3x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:40:39,291 INFO Layer 2: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:40:40,782 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:40:40,786 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:40:40,789 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:40:40,796 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:40:40,799 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:40:40,802 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:40:40,807 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:40:40,813 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:40:40,815 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:40:40,818 INFO Layer 3: <keras.layers.convolutional.Conv2D object at 0xb3155e588>\n",
      "2018-11-26 16:40:40,866 INFO Keras tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:40:40,868 INFO Layer 3: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:40:40,875 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:40:40,879 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.3978934586048126\n",
      "2018-11-26 16:40:40,883 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:40:40,889 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.45358702540397644\n",
      "2018-11-26 16:40:40,892 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:40:40,896 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.40578144788742065\n",
      "2018-11-26 16:40:40,898 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:40:40,901 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.45428669452667236\n",
      "2018-11-26 16:40:40,907 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:40:40,911 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.49695152044296265\n",
      "2018-11-26 16:40:40,915 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:40:40,918 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.45737624168395996\n",
      "2018-11-26 16:40:40,932 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:40:40,935 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.4044671952724457\n",
      "2018-11-26 16:40:40,941 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:40:40,948 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.4511153995990753\n",
      "2018-11-26 16:40:40,958 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:40:40,964 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.3889707922935486\n",
      "2018-11-26 16:40:40,969 INFO Layer 4: <keras.layers.pooling.MaxPooling2D object at 0xb3158d780>\n",
      "2018-11-26 16:40:40,972 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 16:40:40,976 INFO Layer 5: <keras.layers.convolutional.Conv2D object at 0xb3158d5f8>\n",
      "2018-11-26 16:40:41,033 INFO Keras tensor shape detected: 64x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:40:41,040 INFO Layer 5: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:40:41,044 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:40:41,058 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.44109997153282166\n",
      "2018-11-26 16:40:41,060 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:40:41,066 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.4613628089427948\n",
      "2018-11-26 16:40:41,077 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:40:41,083 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.4370166063308716\n",
      "2018-11-26 16:40:41,089 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:40:41,099 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.4667660593986511\n",
      "2018-11-26 16:40:41,104 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:40:41,106 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.5201410055160522\n",
      "2018-11-26 16:40:41,116 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:40:41,120 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.46935534477233887\n",
      "2018-11-26 16:40:41,123 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:40:41,126 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.4464665651321411\n",
      "2018-11-26 16:40:41,130 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:40:41,138 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.48161619901657104\n",
      "2018-11-26 16:40:41,141 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:40:41,144 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.4471622705459595\n",
      "2018-11-26 16:40:41,147 INFO Layer 6: <keras.layers.convolutional.Conv2D object at 0xb315d3080>\n",
      "2018-11-26 16:40:41,204 INFO Keras tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:40:41,207 INFO Layer 6: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:40:41,210 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:40:41,218 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.45507872104644775\n",
      "2018-11-26 16:40:41,223 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:40:41,228 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.4839082956314087\n",
      "2018-11-26 16:40:41,231 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:40:41,238 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.4593982994556427\n",
      "2018-11-26 16:40:41,241 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:40:41,247 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.48676982522010803\n",
      "2018-11-26 16:40:41,251 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:40:41,255 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.5329121351242065\n",
      "2018-11-26 16:40:41,263 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:40:41,265 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.486453115940094\n",
      "2018-11-26 16:40:41,271 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:40:41,274 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.4555995762348175\n",
      "2018-11-26 16:40:41,281 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:40:41,284 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.4885979890823364\n",
      "2018-11-26 16:40:41,288 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:40:41,301 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.44975680112838745\n",
      "2018-11-26 16:40:41,306 INFO Layer 7: <keras.layers.pooling.MaxPooling2D object at 0xb315f3518>\n",
      "2018-11-26 16:40:41,310 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 16:40:41,312 INFO Layer 8: <keras.layers.convolutional.Conv2D object at 0xb315f3390>\n",
      "2018-11-26 16:40:41,367 INFO Keras tensor shape detected: 128x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:40:41,373 INFO Layer 8: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:40:41,379 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:40:41,382 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.4331028163433075\n",
      "2018-11-26 16:40:41,385 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:40:41,389 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.501900315284729\n",
      "2018-11-26 16:40:41,397 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:40:41,401 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.435834139585495\n",
      "2018-11-26 16:40:41,404 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:40:41,409 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.5173439979553223\n",
      "2018-11-26 16:40:41,412 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:40:41,419 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.630874752998352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:40:41,424 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:40:41,427 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.5137887597084045\n",
      "2018-11-26 16:40:41,439 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:40:41,443 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.4312974512577057\n",
      "2018-11-26 16:40:41,446 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:40:41,450 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.4997106194496155\n",
      "2018-11-26 16:40:41,459 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:40:41,463 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.42677345871925354\n",
      "2018-11-26 16:40:41,465 INFO Layer 9: <keras.layers.convolutional.Conv2D object at 0xb31619cc0>\n",
      "2018-11-26 16:40:41,523 INFO Keras tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:40:41,525 INFO Layer 9: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:40:41,529 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,532 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4611811339855194\n",
      "2018-11-26 16:40:41,536 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,540 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.5103280544281006\n",
      "2018-11-26 16:40:41,543 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,546 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.46348103880882263\n",
      "2018-11-26 16:40:41,550 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,554 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5043201446533203\n",
      "2018-11-26 16:40:41,556 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,564 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.5939016342163086\n",
      "2018-11-26 16:40:41,569 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,573 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.5075631737709045\n",
      "2018-11-26 16:40:41,579 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,584 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.45727992057800293\n",
      "2018-11-26 16:40:41,588 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,594 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.5017167329788208\n",
      "2018-11-26 16:40:41,597 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,600 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4612100124359131\n",
      "2018-11-26 16:40:41,604 INFO Layer 10: <keras.layers.convolutional.Conv2D object at 0xb316342e8>\n",
      "2018-11-26 16:40:41,659 INFO Keras tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:40:41,664 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:40:41,668 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,674 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4767092168331146\n",
      "2018-11-26 16:40:41,679 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,685 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.5228332281112671\n",
      "2018-11-26 16:40:41,688 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,693 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.48029711842536926\n",
      "2018-11-26 16:40:41,699 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,705 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5129597187042236\n",
      "2018-11-26 16:40:41,709 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,712 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.590246319770813\n",
      "2018-11-26 16:40:41,720 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,724 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.52484530210495\n",
      "2018-11-26 16:40:41,727 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,731 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.4757029116153717\n",
      "2018-11-26 16:40:41,738 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,741 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.5153258442878723\n",
      "2018-11-26 16:40:41,744 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:40:41,747 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4783080518245697\n",
      "2018-11-26 16:40:41,750 INFO Layer 11: <keras.layers.pooling.MaxPooling2D object at 0xb31673518>\n",
      "2018-11-26 16:40:41,752 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 16:40:41,755 INFO Layer 12: <keras.layers.convolutional.Conv2D object at 0xb31673390>\n",
      "2018-11-26 16:40:41,805 INFO Keras tensor shape detected: 256x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:40:41,808 INFO Layer 12: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:40:41,810 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:40:41,814 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.533117413520813\n",
      "2018-11-26 16:40:41,817 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:40:41,822 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.5677251815795898\n",
      "2018-11-26 16:40:41,825 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:40:41,828 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.5357765555381775\n",
      "2018-11-26 16:40:41,831 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:40:41,841 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.5680774450302124\n",
      "2018-11-26 16:40:41,845 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:40:41,848 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.6403180360794067\n",
      "2018-11-26 16:40:41,851 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:40:41,855 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.5651501417160034\n",
      "2018-11-26 16:40:41,858 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:40:41,861 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.5288751721382141\n",
      "2018-11-26 16:40:41,864 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:40:41,866 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.5627536177635193\n",
      "2018-11-26 16:40:41,869 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:40:41,873 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.5263329744338989\n",
      "2018-11-26 16:40:41,876 INFO Layer 13: <keras.layers.convolutional.Conv2D object at 0xb31694cc0>\n",
      "2018-11-26 16:40:41,964 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:40:41,967 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:40:41,970 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:41,978 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.5816661715507507\n",
      "2018-11-26 16:40:41,981 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:41,986 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.5994589924812317\n",
      "2018-11-26 16:40:41,990 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:41,994 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.5804641246795654\n",
      "2018-11-26 16:40:41,998 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,006 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.5878161787986755\n",
      "2018-11-26 16:40:42,009 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,012 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.6349806785583496\n",
      "2018-11-26 16:40:42,015 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,020 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.5888810753822327\n",
      "2018-11-26 16:40:42,028 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,032 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.5777970552444458\n",
      "2018-11-26 16:40:42,036 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,039 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.5947223901748657\n",
      "2018-11-26 16:40:42,042 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,046 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.5786637663841248\n",
      "2018-11-26 16:40:42,048 INFO Layer 14: <keras.layers.convolutional.Conv2D object at 0xb316b32e8>\n",
      "2018-11-26 16:40:42,129 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:40:42,134 INFO Layer 14: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:40:42,139 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,143 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.598810613155365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:40:42,147 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,152 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.6240571737289429\n",
      "2018-11-26 16:40:42,156 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,159 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.6002294421195984\n",
      "2018-11-26 16:40:42,163 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,166 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.6069265604019165\n",
      "2018-11-26 16:40:42,171 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,174 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.6537207961082458\n",
      "2018-11-26 16:40:42,177 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,182 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.6051104664802551\n",
      "2018-11-26 16:40:42,186 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,190 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.596659243106842\n",
      "2018-11-26 16:40:42,192 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,197 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.6204671859741211\n",
      "2018-11-26 16:40:42,200 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,204 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.5969995856285095\n",
      "2018-11-26 16:40:42,207 INFO Layer 15: <keras.layers.pooling.MaxPooling2D object at 0xb316f2518>\n",
      "2018-11-26 16:40:42,209 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 16:40:42,212 INFO Layer 16: <keras.layers.convolutional.Conv2D object at 0xb316f2390>\n",
      "2018-11-26 16:40:42,271 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:40:42,273 INFO Layer 16: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:40:42,278 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,281 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.6414387226104736\n",
      "2018-11-26 16:40:42,285 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,289 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.658482551574707\n",
      "2018-11-26 16:40:42,292 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,296 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.6415495276451111\n",
      "2018-11-26 16:40:42,301 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,305 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.6379082798957825\n",
      "2018-11-26 16:40:42,308 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,311 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.6930620670318604\n",
      "2018-11-26 16:40:42,314 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,317 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.6355615258216858\n",
      "2018-11-26 16:40:42,320 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,323 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.6379796266555786\n",
      "2018-11-26 16:40:42,326 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,329 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.6546915769577026\n",
      "2018-11-26 16:40:42,333 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,337 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.6379215717315674\n",
      "2018-11-26 16:40:42,342 INFO Layer 17: <keras.layers.convolutional.Conv2D object at 0xb31716cc0>\n",
      "2018-11-26 16:40:42,403 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:40:42,406 INFO Layer 17: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:40:42,410 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,413 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.6483020782470703\n",
      "2018-11-26 16:40:42,416 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,420 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.6716188788414001\n",
      "2018-11-26 16:40:42,426 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,430 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.6487486958503723\n",
      "2018-11-26 16:40:42,435 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,439 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.6313163042068481\n",
      "2018-11-26 16:40:42,441 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,453 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.690161406993866\n",
      "2018-11-26 16:40:42,458 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,463 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.6324495077133179\n",
      "2018-11-26 16:40:42,469 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,473 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.6435777544975281\n",
      "2018-11-26 16:40:42,476 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,483 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.6643065214157104\n",
      "2018-11-26 16:40:42,491 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,496 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.6426410675048828\n",
      "2018-11-26 16:40:42,499 INFO Layer 18: <keras.layers.convolutional.Conv2D object at 0xb317322e8>\n",
      "2018-11-26 16:40:42,554 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:40:42,559 INFO Layer 18: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:40:42,562 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,565 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.6312968730926514\n",
      "2018-11-26 16:40:42,569 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,574 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.6557008028030396\n",
      "2018-11-26 16:40:42,585 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,589 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.6303039193153381\n",
      "2018-11-26 16:40:42,595 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,599 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.6299318671226501\n",
      "2018-11-26 16:40:42,602 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,607 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.6738649010658264\n",
      "2018-11-26 16:40:42,612 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,616 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.6266793012619019\n",
      "2018-11-26 16:40:42,620 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,625 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.6302400231361389\n",
      "2018-11-26 16:40:42,628 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,632 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.6563602089881897\n",
      "2018-11-26 16:40:42,635 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:40:42,639 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.6300156712532043\n",
      "2018-11-26 16:40:42,648 INFO Layer 19: <keras.layers.pooling.MaxPooling2D object at 0xb31774518>\n",
      "2018-11-26 16:40:42,650 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 16:40:42,653 INFO Layer 20: <keras.layers.core.Flatten object at 0xb31774390>\n",
      "2018-11-26 16:40:42,656 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 16:40:42,658 INFO Layer 21: <keras.layers.core.Dense object at 0xb31794320>\n",
      "2018-11-26 16:40:43,841 INFO Layer 21: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:40:43,845 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 16:40:43,885 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.3697518110275269\n",
      "2018-11-26 16:40:43,887 INFO Layer 22: <keras.layers.core.Dense object at 0xb317afb70>\n",
      "2018-11-26 16:40:44,210 INFO Layer 22: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:40:44,213 INFO     Weight matrix 1/1 (4096,4096): Analyzing ...\n",
      "2018-11-26 16:40:44,228 INFO     Weight matrix 1/1 (4096,4096): Lognorm: 1.2557973861694336\n",
      "2018-11-26 16:40:44,230 INFO Layer 23: <keras.layers.core.Dense object at 0xb317d4470>\n",
      "2018-11-26 16:40:44,340 INFO Layer 23: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:40:44,343 INFO     Weight matrix 1/1 (1000,4096): Analyzing ...\n",
      "2018-11-26 16:40:44,352 INFO     Weight matrix 1/1 (1000,4096): Lognorm: 1.224208950996399\n",
      "2018-11-26 16:40:44,357 INFO ### Printing results ###\n",
      "2018-11-26 16:40:44,361 DEBUG Layer 2: Lognorm compound: 0.43449219730165267\n",
      "2018-11-26 16:40:44,366 DEBUG Layer 4: Lognorm compound: 0.46344298124313354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:40:44,370 DEBUG Layer 5: Lognorm compound: 0.4776083065403832\n",
      "2018-11-26 16:40:44,374 DEBUG Layer 7: Lognorm compound: 0.487847367922465\n",
      "2018-11-26 16:40:44,377 DEBUG Layer 8: Lognorm compound: 0.49566464953952366\n",
      "2018-11-26 16:40:44,380 DEBUG Layer 9: Lognorm compound: 0.5085808568530612\n",
      "2018-11-26 16:40:44,383 DEBUG Layer 11: Lognorm compound: 0.5586807264222039\n",
      "2018-11-26 16:40:44,391 DEBUG Layer 12: Lognorm compound: 0.5916056036949158\n",
      "2018-11-26 16:40:44,396 DEBUG Layer 13: Lognorm compound: 0.6114423407448663\n",
      "2018-11-26 16:40:44,402 DEBUG Layer 15: Lognorm compound: 0.6487328277693855\n",
      "2018-11-26 16:40:44,406 DEBUG Layer 16: Lognorm compound: 0.6525691350301107\n",
      "2018-11-26 16:40:44,409 DEBUG Layer 17: Lognorm compound: 0.6404881742265489\n",
      "2018-11-26 16:40:44,413 DEBUG Layer 20: Lognorm: 1.3697518110275269\n",
      "2018-11-26 16:40:44,416 DEBUG Layer 21: Lognorm: 1.2557973861694336\n",
      "2018-11-26 16:40:44,419 DEBUG Layer 22: Lognorm: 1.224208950996399\n",
      "2018-11-26 16:40:44,423 INFO LogNorm: min: 0.3889707922935486, max: 1.3697518110275269, avg: 0.5674788951873779\n",
      "2018-11-26 16:40:44,427 INFO LogNorm compound: min: 0.43449219730165267, max: 1.3697518110275269, avg: 0.6947275543654406\n"
     ]
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "results = watcher.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T00:40:44.620865Z",
     "start_time": "2018-11-27T00:40:44.508679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'id': 0,\n",
       "  'type': <keras.engine.input_layer.InputLayer at 0x105271ba8>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 1: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  0: {'N': 64,\n",
       "   'M': 3,\n",
       "   'Q': 21.333333333333332,\n",
       "   'summary': 'Weight matrix 1/9 (3,64): Skipping: too small (<50)'},\n",
       "  1: {'N': 64,\n",
       "   'M': 3,\n",
       "   'Q': 21.333333333333332,\n",
       "   'summary': 'Weight matrix 2/9 (3,64): Skipping: too small (<50)'},\n",
       "  2: {'N': 64,\n",
       "   'M': 3,\n",
       "   'Q': 21.333333333333332,\n",
       "   'summary': 'Weight matrix 3/9 (3,64): Skipping: too small (<50)'},\n",
       "  3: {'N': 64,\n",
       "   'M': 3,\n",
       "   'Q': 21.333333333333332,\n",
       "   'summary': 'Weight matrix 4/9 (3,64): Skipping: too small (<50)'},\n",
       "  4: {'N': 64,\n",
       "   'M': 3,\n",
       "   'Q': 21.333333333333332,\n",
       "   'summary': 'Weight matrix 5/9 (3,64): Skipping: too small (<50)'},\n",
       "  5: {'N': 64,\n",
       "   'M': 3,\n",
       "   'Q': 21.333333333333332,\n",
       "   'summary': 'Weight matrix 6/9 (3,64): Skipping: too small (<50)'},\n",
       "  6: {'N': 64,\n",
       "   'M': 3,\n",
       "   'Q': 21.333333333333332,\n",
       "   'summary': 'Weight matrix 7/9 (3,64): Skipping: too small (<50)'},\n",
       "  7: {'N': 64,\n",
       "   'M': 3,\n",
       "   'Q': 21.333333333333332,\n",
       "   'summary': 'Weight matrix 8/9 (3,64): Skipping: too small (<50)'},\n",
       "  8: {'N': 64,\n",
       "   'M': 3,\n",
       "   'Q': 21.333333333333332,\n",
       "   'summary': 'Weight matrix 9/9 (3,64): Skipping: too small (<50)'}},\n",
       " 2: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  0: {'N': 64,\n",
       "   'M': 64,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.39789346,\n",
       "   'summary': 'Weight matrix 1/9 (64,64): Lognorm: 0.3978934586048126'},\n",
       "  1: {'N': 64,\n",
       "   'M': 64,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.45358703,\n",
       "   'summary': 'Weight matrix 2/9 (64,64): Lognorm: 0.45358702540397644'},\n",
       "  2: {'N': 64,\n",
       "   'M': 64,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.40578145,\n",
       "   'summary': 'Weight matrix 3/9 (64,64): Lognorm: 0.40578144788742065'},\n",
       "  3: {'N': 64,\n",
       "   'M': 64,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.4542867,\n",
       "   'summary': 'Weight matrix 4/9 (64,64): Lognorm: 0.45428669452667236'},\n",
       "  4: {'N': 64,\n",
       "   'M': 64,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.49695152,\n",
       "   'summary': 'Weight matrix 5/9 (64,64): Lognorm: 0.49695152044296265'},\n",
       "  5: {'N': 64,\n",
       "   'M': 64,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.45737624,\n",
       "   'summary': 'Weight matrix 6/9 (64,64): Lognorm: 0.45737624168395996'},\n",
       "  6: {'N': 64,\n",
       "   'M': 64,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.4044672,\n",
       "   'summary': 'Weight matrix 7/9 (64,64): Lognorm: 0.4044671952724457'},\n",
       "  7: {'N': 64,\n",
       "   'M': 64,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.4511154,\n",
       "   'summary': 'Weight matrix 8/9 (64,64): Lognorm: 0.4511153995990753'},\n",
       "  8: {'N': 64,\n",
       "   'M': 64,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.3889708,\n",
       "   'summary': 'Weight matrix 9/9 (64,64): Lognorm: 0.3889707922935486'}},\n",
       " 3: {'id': 3,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb3158d780>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 4: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  0: {'N': 128,\n",
       "   'M': 64,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.44109997,\n",
       "   'summary': 'Weight matrix 1/9 (64,128): Lognorm: 0.44109997153282166'},\n",
       "  1: {'N': 128,\n",
       "   'M': 64,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.4613628,\n",
       "   'summary': 'Weight matrix 2/9 (64,128): Lognorm: 0.4613628089427948'},\n",
       "  2: {'N': 128,\n",
       "   'M': 64,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.4370166,\n",
       "   'summary': 'Weight matrix 3/9 (64,128): Lognorm: 0.4370166063308716'},\n",
       "  3: {'N': 128,\n",
       "   'M': 64,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.46676606,\n",
       "   'summary': 'Weight matrix 4/9 (64,128): Lognorm: 0.4667660593986511'},\n",
       "  4: {'N': 128,\n",
       "   'M': 64,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.520141,\n",
       "   'summary': 'Weight matrix 5/9 (64,128): Lognorm: 0.5201410055160522'},\n",
       "  5: {'N': 128,\n",
       "   'M': 64,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.46935534,\n",
       "   'summary': 'Weight matrix 6/9 (64,128): Lognorm: 0.46935534477233887'},\n",
       "  6: {'N': 128,\n",
       "   'M': 64,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.44646657,\n",
       "   'summary': 'Weight matrix 7/9 (64,128): Lognorm: 0.4464665651321411'},\n",
       "  7: {'N': 128,\n",
       "   'M': 64,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.4816162,\n",
       "   'summary': 'Weight matrix 8/9 (64,128): Lognorm: 0.48161619901657104'},\n",
       "  8: {'N': 128,\n",
       "   'M': 64,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.44716227,\n",
       "   'summary': 'Weight matrix 9/9 (64,128): Lognorm: 0.4471622705459595'}},\n",
       " 5: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  0: {'N': 128,\n",
       "   'M': 128,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.45507872,\n",
       "   'summary': 'Weight matrix 1/9 (128,128): Lognorm: 0.45507872104644775'},\n",
       "  1: {'N': 128,\n",
       "   'M': 128,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.4839083,\n",
       "   'summary': 'Weight matrix 2/9 (128,128): Lognorm: 0.4839082956314087'},\n",
       "  2: {'N': 128,\n",
       "   'M': 128,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.4593983,\n",
       "   'summary': 'Weight matrix 3/9 (128,128): Lognorm: 0.4593982994556427'},\n",
       "  3: {'N': 128,\n",
       "   'M': 128,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.48676983,\n",
       "   'summary': 'Weight matrix 4/9 (128,128): Lognorm: 0.48676982522010803'},\n",
       "  4: {'N': 128,\n",
       "   'M': 128,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.53291214,\n",
       "   'summary': 'Weight matrix 5/9 (128,128): Lognorm: 0.5329121351242065'},\n",
       "  5: {'N': 128,\n",
       "   'M': 128,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.48645312,\n",
       "   'summary': 'Weight matrix 6/9 (128,128): Lognorm: 0.486453115940094'},\n",
       "  6: {'N': 128,\n",
       "   'M': 128,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.45559958,\n",
       "   'summary': 'Weight matrix 7/9 (128,128): Lognorm: 0.4555995762348175'},\n",
       "  7: {'N': 128,\n",
       "   'M': 128,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.488598,\n",
       "   'summary': 'Weight matrix 8/9 (128,128): Lognorm: 0.4885979890823364'},\n",
       "  8: {'N': 128,\n",
       "   'M': 128,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.4497568,\n",
       "   'summary': 'Weight matrix 9/9 (128,128): Lognorm: 0.44975680112838745'}},\n",
       " 6: {'id': 6,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb315f3518>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 7: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  0: {'N': 256,\n",
       "   'M': 128,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.43310282,\n",
       "   'summary': 'Weight matrix 1/9 (128,256): Lognorm: 0.4331028163433075'},\n",
       "  1: {'N': 256,\n",
       "   'M': 128,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.5019003,\n",
       "   'summary': 'Weight matrix 2/9 (128,256): Lognorm: 0.501900315284729'},\n",
       "  2: {'N': 256,\n",
       "   'M': 128,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.43583414,\n",
       "   'summary': 'Weight matrix 3/9 (128,256): Lognorm: 0.435834139585495'},\n",
       "  3: {'N': 256,\n",
       "   'M': 128,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.517344,\n",
       "   'summary': 'Weight matrix 4/9 (128,256): Lognorm: 0.5173439979553223'},\n",
       "  4: {'N': 256,\n",
       "   'M': 128,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.63087475,\n",
       "   'summary': 'Weight matrix 5/9 (128,256): Lognorm: 0.630874752998352'},\n",
       "  5: {'N': 256,\n",
       "   'M': 128,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.51378876,\n",
       "   'summary': 'Weight matrix 6/9 (128,256): Lognorm: 0.5137887597084045'},\n",
       "  6: {'N': 256,\n",
       "   'M': 128,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.43129745,\n",
       "   'summary': 'Weight matrix 7/9 (128,256): Lognorm: 0.4312974512577057'},\n",
       "  7: {'N': 256,\n",
       "   'M': 128,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.49971062,\n",
       "   'summary': 'Weight matrix 8/9 (128,256): Lognorm: 0.4997106194496155'},\n",
       "  8: {'N': 256,\n",
       "   'M': 128,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.42677346,\n",
       "   'summary': 'Weight matrix 9/9 (128,256): Lognorm: 0.42677345871925354'}},\n",
       " 8: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  0: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.46118113,\n",
       "   'summary': 'Weight matrix 1/9 (256,256): Lognorm: 0.4611811339855194'},\n",
       "  1: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.51032805,\n",
       "   'summary': 'Weight matrix 2/9 (256,256): Lognorm: 0.5103280544281006'},\n",
       "  2: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.46348104,\n",
       "   'summary': 'Weight matrix 3/9 (256,256): Lognorm: 0.46348103880882263'},\n",
       "  3: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.50432014,\n",
       "   'summary': 'Weight matrix 4/9 (256,256): Lognorm: 0.5043201446533203'},\n",
       "  4: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.59390163,\n",
       "   'summary': 'Weight matrix 5/9 (256,256): Lognorm: 0.5939016342163086'},\n",
       "  5: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.5075632,\n",
       "   'summary': 'Weight matrix 6/9 (256,256): Lognorm: 0.5075631737709045'},\n",
       "  6: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.45727992,\n",
       "   'summary': 'Weight matrix 7/9 (256,256): Lognorm: 0.45727992057800293'},\n",
       "  7: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.50171673,\n",
       "   'summary': 'Weight matrix 8/9 (256,256): Lognorm: 0.5017167329788208'},\n",
       "  8: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.46121,\n",
       "   'summary': 'Weight matrix 9/9 (256,256): Lognorm: 0.4612100124359131'}},\n",
       " 9: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  0: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.47670922,\n",
       "   'summary': 'Weight matrix 1/9 (256,256): Lognorm: 0.4767092168331146'},\n",
       "  1: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.5228332,\n",
       "   'summary': 'Weight matrix 2/9 (256,256): Lognorm: 0.5228332281112671'},\n",
       "  2: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.48029712,\n",
       "   'summary': 'Weight matrix 3/9 (256,256): Lognorm: 0.48029711842536926'},\n",
       "  3: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.5129597,\n",
       "   'summary': 'Weight matrix 4/9 (256,256): Lognorm: 0.5129597187042236'},\n",
       "  4: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.5902463,\n",
       "   'summary': 'Weight matrix 5/9 (256,256): Lognorm: 0.590246319770813'},\n",
       "  5: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.5248453,\n",
       "   'summary': 'Weight matrix 6/9 (256,256): Lognorm: 0.52484530210495'},\n",
       "  6: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.4757029,\n",
       "   'summary': 'Weight matrix 7/9 (256,256): Lognorm: 0.4757029116153717'},\n",
       "  7: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.51532584,\n",
       "   'summary': 'Weight matrix 8/9 (256,256): Lognorm: 0.5153258442878723'},\n",
       "  8: {'N': 256,\n",
       "   'M': 256,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.47830805,\n",
       "   'summary': 'Weight matrix 9/9 (256,256): Lognorm: 0.4783080518245697'}},\n",
       " 10: {'id': 10,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb31673518>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 11: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  0: {'N': 512,\n",
       "   'M': 256,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.5331174,\n",
       "   'summary': 'Weight matrix 1/9 (256,512): Lognorm: 0.533117413520813'},\n",
       "  1: {'N': 512,\n",
       "   'M': 256,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.5677252,\n",
       "   'summary': 'Weight matrix 2/9 (256,512): Lognorm: 0.5677251815795898'},\n",
       "  2: {'N': 512,\n",
       "   'M': 256,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.53577656,\n",
       "   'summary': 'Weight matrix 3/9 (256,512): Lognorm: 0.5357765555381775'},\n",
       "  3: {'N': 512,\n",
       "   'M': 256,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.56807745,\n",
       "   'summary': 'Weight matrix 4/9 (256,512): Lognorm: 0.5680774450302124'},\n",
       "  4: {'N': 512,\n",
       "   'M': 256,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.64031804,\n",
       "   'summary': 'Weight matrix 5/9 (256,512): Lognorm: 0.6403180360794067'},\n",
       "  5: {'N': 512,\n",
       "   'M': 256,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.56515014,\n",
       "   'summary': 'Weight matrix 6/9 (256,512): Lognorm: 0.5651501417160034'},\n",
       "  6: {'N': 512,\n",
       "   'M': 256,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.5288752,\n",
       "   'summary': 'Weight matrix 7/9 (256,512): Lognorm: 0.5288751721382141'},\n",
       "  7: {'N': 512,\n",
       "   'M': 256,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.5627536,\n",
       "   'summary': 'Weight matrix 8/9 (256,512): Lognorm: 0.5627536177635193'},\n",
       "  8: {'N': 512,\n",
       "   'M': 256,\n",
       "   'Q': 2.0,\n",
       "   'lognorm': 0.526333,\n",
       "   'summary': 'Weight matrix 9/9 (256,512): Lognorm: 0.5263329744338989'}},\n",
       " 12: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  0: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.5816662,\n",
       "   'summary': 'Weight matrix 1/9 (512,512): Lognorm: 0.5816661715507507'},\n",
       "  1: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.599459,\n",
       "   'summary': 'Weight matrix 2/9 (512,512): Lognorm: 0.5994589924812317'},\n",
       "  2: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.5804641,\n",
       "   'summary': 'Weight matrix 3/9 (512,512): Lognorm: 0.5804641246795654'},\n",
       "  3: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.5878162,\n",
       "   'summary': 'Weight matrix 4/9 (512,512): Lognorm: 0.5878161787986755'},\n",
       "  4: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6349807,\n",
       "   'summary': 'Weight matrix 5/9 (512,512): Lognorm: 0.6349806785583496'},\n",
       "  5: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.5888811,\n",
       "   'summary': 'Weight matrix 6/9 (512,512): Lognorm: 0.5888810753822327'},\n",
       "  6: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.57779706,\n",
       "   'summary': 'Weight matrix 7/9 (512,512): Lognorm: 0.5777970552444458'},\n",
       "  7: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.5947224,\n",
       "   'summary': 'Weight matrix 8/9 (512,512): Lognorm: 0.5947223901748657'},\n",
       "  8: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.57866377,\n",
       "   'summary': 'Weight matrix 9/9 (512,512): Lognorm: 0.5786637663841248'}},\n",
       " 13: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  0: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.5988106,\n",
       "   'summary': 'Weight matrix 1/9 (512,512): Lognorm: 0.598810613155365'},\n",
       "  1: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6240572,\n",
       "   'summary': 'Weight matrix 2/9 (512,512): Lognorm: 0.6240571737289429'},\n",
       "  2: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.60022944,\n",
       "   'summary': 'Weight matrix 3/9 (512,512): Lognorm: 0.6002294421195984'},\n",
       "  3: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.60692656,\n",
       "   'summary': 'Weight matrix 4/9 (512,512): Lognorm: 0.6069265604019165'},\n",
       "  4: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6537208,\n",
       "   'summary': 'Weight matrix 5/9 (512,512): Lognorm: 0.6537207961082458'},\n",
       "  5: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.60511047,\n",
       "   'summary': 'Weight matrix 6/9 (512,512): Lognorm: 0.6051104664802551'},\n",
       "  6: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.59665924,\n",
       "   'summary': 'Weight matrix 7/9 (512,512): Lognorm: 0.596659243106842'},\n",
       "  7: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6204672,\n",
       "   'summary': 'Weight matrix 8/9 (512,512): Lognorm: 0.6204671859741211'},\n",
       "  8: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.5969996,\n",
       "   'summary': 'Weight matrix 9/9 (512,512): Lognorm: 0.5969995856285095'}},\n",
       " 14: {'id': 14,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb316f2518>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 15: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  0: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6414387,\n",
       "   'summary': 'Weight matrix 1/9 (512,512): Lognorm: 0.6414387226104736'},\n",
       "  1: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.65848255,\n",
       "   'summary': 'Weight matrix 2/9 (512,512): Lognorm: 0.658482551574707'},\n",
       "  2: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6415495,\n",
       "   'summary': 'Weight matrix 3/9 (512,512): Lognorm: 0.6415495276451111'},\n",
       "  3: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6379083,\n",
       "   'summary': 'Weight matrix 4/9 (512,512): Lognorm: 0.6379082798957825'},\n",
       "  4: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.69306207,\n",
       "   'summary': 'Weight matrix 5/9 (512,512): Lognorm: 0.6930620670318604'},\n",
       "  5: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6355615,\n",
       "   'summary': 'Weight matrix 6/9 (512,512): Lognorm: 0.6355615258216858'},\n",
       "  6: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6379796,\n",
       "   'summary': 'Weight matrix 7/9 (512,512): Lognorm: 0.6379796266555786'},\n",
       "  7: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6546916,\n",
       "   'summary': 'Weight matrix 8/9 (512,512): Lognorm: 0.6546915769577026'},\n",
       "  8: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6379216,\n",
       "   'summary': 'Weight matrix 9/9 (512,512): Lognorm: 0.6379215717315674'}},\n",
       " 16: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  0: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6483021,\n",
       "   'summary': 'Weight matrix 1/9 (512,512): Lognorm: 0.6483020782470703'},\n",
       "  1: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6716189,\n",
       "   'summary': 'Weight matrix 2/9 (512,512): Lognorm: 0.6716188788414001'},\n",
       "  2: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6487487,\n",
       "   'summary': 'Weight matrix 3/9 (512,512): Lognorm: 0.6487486958503723'},\n",
       "  3: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6313163,\n",
       "   'summary': 'Weight matrix 4/9 (512,512): Lognorm: 0.6313163042068481'},\n",
       "  4: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6901614,\n",
       "   'summary': 'Weight matrix 5/9 (512,512): Lognorm: 0.690161406993866'},\n",
       "  5: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6324495,\n",
       "   'summary': 'Weight matrix 6/9 (512,512): Lognorm: 0.6324495077133179'},\n",
       "  6: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.64357775,\n",
       "   'summary': 'Weight matrix 7/9 (512,512): Lognorm: 0.6435777544975281'},\n",
       "  7: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6643065,\n",
       "   'summary': 'Weight matrix 8/9 (512,512): Lognorm: 0.6643065214157104'},\n",
       "  8: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.64264107,\n",
       "   'summary': 'Weight matrix 9/9 (512,512): Lognorm: 0.6426410675048828'}},\n",
       " 17: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  0: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6312969,\n",
       "   'summary': 'Weight matrix 1/9 (512,512): Lognorm: 0.6312968730926514'},\n",
       "  1: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6557008,\n",
       "   'summary': 'Weight matrix 2/9 (512,512): Lognorm: 0.6557008028030396'},\n",
       "  2: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6303039,\n",
       "   'summary': 'Weight matrix 3/9 (512,512): Lognorm: 0.6303039193153381'},\n",
       "  3: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.62993187,\n",
       "   'summary': 'Weight matrix 4/9 (512,512): Lognorm: 0.6299318671226501'},\n",
       "  4: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6738649,\n",
       "   'summary': 'Weight matrix 5/9 (512,512): Lognorm: 0.6738649010658264'},\n",
       "  5: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6266793,\n",
       "   'summary': 'Weight matrix 6/9 (512,512): Lognorm: 0.6266793012619019'},\n",
       "  6: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.63024,\n",
       "   'summary': 'Weight matrix 7/9 (512,512): Lognorm: 0.6302400231361389'},\n",
       "  7: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6563602,\n",
       "   'summary': 'Weight matrix 8/9 (512,512): Lognorm: 0.6563602089881897'},\n",
       "  8: {'N': 512,\n",
       "   'M': 512,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 0.6300157,\n",
       "   'summary': 'Weight matrix 9/9 (512,512): Lognorm: 0.6300156712532043'}},\n",
       " 18: {'id': 18,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb31774518>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 19: {'id': 19,\n",
       "  'type': <keras.layers.core.Flatten at 0xb31774390>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 20: {'id': 20,\n",
       "  'type': <keras.layers.core.Dense at 0xb31794320>,\n",
       "  'layer_type': <LAYER_TYPE.DENSE: 1>,\n",
       "  0: {'N': 25088,\n",
       "   'M': 4096,\n",
       "   'Q': 6.125,\n",
       "   'lognorm': 1.3697518,\n",
       "   'summary': 'Weight matrix 1/1 (4096,25088): Lognorm: 1.3697518110275269'}},\n",
       " 21: {'id': 21,\n",
       "  'type': <keras.layers.core.Dense at 0xb317afb70>,\n",
       "  'layer_type': <LAYER_TYPE.DENSE: 1>,\n",
       "  0: {'N': 4096,\n",
       "   'M': 4096,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 1.2557974,\n",
       "   'summary': 'Weight matrix 1/1 (4096,4096): Lognorm: 1.2557973861694336'}},\n",
       " 22: {'id': 22,\n",
       "  'type': <keras.layers.core.Dense at 0xb317d4470>,\n",
       "  'layer_type': <LAYER_TYPE.DENSE: 1>,\n",
       "  0: {'N': 4096,\n",
       "   'M': 1000,\n",
       "   'Q': 4.096,\n",
       "   'lognorm': 1.224209,\n",
       "   'summary': 'Weight matrix 1/1 (1000,4096): Lognorm: 1.224208950996399'}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T00:40:44.647028Z",
     "start_time": "2018-11-27T00:40:44.631773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lognorm': 0.5674789, 'lognorm_compound': 0.6947275543654406}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watcher.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T00:40:44.739183Z",
     "start_time": "2018-11-27T00:40:44.654749Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:40:44,658 INFO ### Printing results ###\n",
      "2018-11-26 16:40:44,663 DEBUG Layer 2: Lognorm compound: 0.43449219730165267\n",
      "2018-11-26 16:40:44,667 DEBUG Layer 4: Lognorm compound: 0.46344298124313354\n",
      "2018-11-26 16:40:44,671 DEBUG Layer 5: Lognorm compound: 0.4776083065403832\n",
      "2018-11-26 16:40:44,674 DEBUG Layer 7: Lognorm compound: 0.487847367922465\n",
      "2018-11-26 16:40:44,676 DEBUG Layer 8: Lognorm compound: 0.49566464953952366\n",
      "2018-11-26 16:40:44,679 DEBUG Layer 9: Lognorm compound: 0.5085808568530612\n",
      "2018-11-26 16:40:44,682 DEBUG Layer 11: Lognorm compound: 0.5586807264222039\n",
      "2018-11-26 16:40:44,685 DEBUG Layer 12: Lognorm compound: 0.5916056036949158\n",
      "2018-11-26 16:40:44,687 DEBUG Layer 13: Lognorm compound: 0.6114423407448663\n",
      "2018-11-26 16:40:44,690 DEBUG Layer 15: Lognorm compound: 0.6487328277693855\n",
      "2018-11-26 16:40:44,692 DEBUG Layer 16: Lognorm compound: 0.6525691350301107\n",
      "2018-11-26 16:40:44,695 DEBUG Layer 17: Lognorm compound: 0.6404881742265489\n",
      "2018-11-26 16:40:44,699 DEBUG Layer 20: Lognorm: 1.3697518110275269\n",
      "2018-11-26 16:40:44,704 DEBUG Layer 21: Lognorm: 1.2557973861694336\n",
      "2018-11-26 16:40:44,711 DEBUG Layer 22: Lognorm: 1.224208950996399\n",
      "2018-11-26 16:40:44,716 INFO LogNorm: min: 0.3889707922935486, max: 1.3697518110275269, avg: 0.5674788951873779\n",
      "2018-11-26 16:40:44,724 INFO LogNorm compound: min: 0.43449219730165267, max: 1.3697518110275269, avg: 0.6947275543654406\n"
     ]
    }
   ],
   "source": [
    "watcher.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Filter by layer type (CONV1D, CONV2D, DENSE)\n",
    "\n",
    "In this example we are interested in the DENSE layers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T00:41:10.339876Z",
     "start_time": "2018-11-27T00:40:44.757289Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:41:08,664 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 16:41:08,667 INFO Analyzing model 'vgg16' with 23 layers\n",
      "2018-11-26 16:41:08,670 INFO Layer 1: <keras.engine.input_layer.InputLayer object at 0xb39b05ef0>\n",
      "2018-11-26 16:41:08,672 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:08,675 INFO Layer 2: <keras.layers.convolutional.Conv2D object at 0xb39b056d8>\n",
      "2018-11-26 16:41:08,677 INFO Layer 2: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:08,680 INFO Layer 3: <keras.layers.convolutional.Conv2D object at 0xb39b42080>\n",
      "2018-11-26 16:41:08,683 INFO Layer 3: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:08,685 INFO Layer 4: <keras.layers.pooling.MaxPooling2D object at 0xb39b42550>\n",
      "2018-11-26 16:41:08,688 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:08,691 INFO Layer 5: <keras.layers.convolutional.Conv2D object at 0xb39b42e80>\n",
      "2018-11-26 16:41:08,693 INFO Layer 5: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:08,696 INFO Layer 6: <keras.layers.convolutional.Conv2D object at 0xb3ddd62b0>\n",
      "2018-11-26 16:41:08,699 INFO Layer 6: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:08,702 INFO Layer 7: <keras.layers.pooling.MaxPooling2D object at 0xb3ddf2470>\n",
      "2018-11-26 16:41:08,705 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:08,707 INFO Layer 8: <keras.layers.convolutional.Conv2D object at 0xb3ddf29b0>\n",
      "2018-11-26 16:41:08,709 INFO Layer 8: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:08,712 INFO Layer 9: <keras.layers.convolutional.Conv2D object at 0xb34693390>\n",
      "2018-11-26 16:41:08,716 INFO Layer 9: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:08,719 INFO Layer 10: <keras.layers.convolutional.Conv2D object at 0xb346b4748>\n",
      "2018-11-26 16:41:08,722 INFO Layer 10: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:08,724 INFO Layer 11: <keras.layers.pooling.MaxPooling2D object at 0xb346d8048>\n",
      "2018-11-26 16:41:08,727 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:08,732 INFO Layer 12: <keras.layers.convolutional.Conv2D object at 0xb346d8978>\n",
      "2018-11-26 16:41:08,735 INFO Layer 12: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:08,738 INFO Layer 13: <keras.layers.convolutional.Conv2D object at 0xb34717358>\n",
      "2018-11-26 16:41:08,741 INFO Layer 13: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:08,744 INFO Layer 14: <keras.layers.convolutional.Conv2D object at 0xb34739748>\n",
      "2018-11-26 16:41:08,746 INFO Layer 14: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:08,749 INFO Layer 15: <keras.layers.pooling.MaxPooling2D object at 0xb3475a048>\n",
      "2018-11-26 16:41:08,751 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:08,754 INFO Layer 16: <keras.layers.convolutional.Conv2D object at 0xb3475a978>\n",
      "2018-11-26 16:41:08,758 INFO Layer 16: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:08,760 INFO Layer 17: <keras.layers.convolutional.Conv2D object at 0xb34798358>\n",
      "2018-11-26 16:41:08,762 INFO Layer 17: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:08,766 INFO Layer 18: <keras.layers.convolutional.Conv2D object at 0xb347b8748>\n",
      "2018-11-26 16:41:08,769 INFO Layer 18: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:08,771 INFO Layer 19: <keras.layers.pooling.MaxPooling2D object at 0xb347df048>\n",
      "2018-11-26 16:41:08,774 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:08,779 INFO Layer 20: <keras.layers.core.Flatten object at 0xb347df978>\n",
      "2018-11-26 16:41:08,782 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:08,785 INFO Layer 21: <keras.layers.core.Dense object at 0xb347fa4a8>\n",
      "2018-11-26 16:41:09,927 INFO Layer 21: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:41:09,930 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 16:41:09,973 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.3697518110275269\n",
      "2018-11-26 16:41:09,977 INFO Layer 22: <keras.layers.core.Dense object at 0xb3481ccc0>\n",
      "2018-11-26 16:41:10,176 INFO Layer 22: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:41:10,180 INFO     Weight matrix 1/1 (4096,4096): Analyzing ...\n",
      "2018-11-26 16:41:10,191 INFO     Weight matrix 1/1 (4096,4096): Lognorm: 1.2557973861694336\n",
      "2018-11-26 16:41:10,194 INFO Layer 23: <keras.layers.core.Dense object at 0xb3483f780>\n",
      "2018-11-26 16:41:10,281 INFO Layer 23: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:41:10,284 INFO     Weight matrix 1/1 (1000,4096): Analyzing ...\n",
      "2018-11-26 16:41:10,289 INFO     Weight matrix 1/1 (1000,4096): Lognorm: 1.224208950996399\n",
      "2018-11-26 16:41:10,291 INFO ### Printing results ###\n",
      "2018-11-26 16:41:10,294 DEBUG Layer 20: Lognorm: 1.3697518110275269\n",
      "2018-11-26 16:41:10,297 DEBUG Layer 21: Lognorm: 1.2557973861694336\n",
      "2018-11-26 16:41:10,299 DEBUG Layer 22: Lognorm: 1.224208950996399\n",
      "2018-11-26 16:41:10,303 INFO LogNorm: min: 1.224208950996399, max: 1.3697518110275269, avg: 1.2832527160644531\n",
      "2018-11-26 16:41:10,305 INFO LogNorm compound: min: 1.224208950996399, max: 1.3697518110275269, avg: 1.2832527160644531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'id': 0,\n",
       "  'type': <keras.engine.input_layer.InputLayer at 0xb39b05ef0>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 1: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 2: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 3: {'id': 3,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb39b42550>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 4: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 5: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 6: {'id': 6,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb3ddf2470>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 7: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 8: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 9: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 10: {'id': 10,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb346d8048>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 11: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 12: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 13: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 14: {'id': 14,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb3475a048>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 15: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 16: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 17: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 18: {'id': 18,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb347df048>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 19: {'id': 19,\n",
       "  'type': <keras.layers.core.Flatten at 0xb347df978>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 20: {'id': 20,\n",
       "  'type': <keras.layers.core.Dense at 0xb347fa4a8>,\n",
       "  'layer_type': <LAYER_TYPE.DENSE: 1>,\n",
       "  0: {'N': 25088,\n",
       "   'M': 4096,\n",
       "   'Q': 6.125,\n",
       "   'lognorm': 1.3697518,\n",
       "   'summary': 'Weight matrix 1/1 (4096,25088): Lognorm: 1.3697518110275269'}},\n",
       " 21: {'id': 21,\n",
       "  'type': <keras.layers.core.Dense at 0xb3481ccc0>,\n",
       "  'layer_type': <LAYER_TYPE.DENSE: 1>,\n",
       "  0: {'N': 4096,\n",
       "   'M': 4096,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 1.2557974,\n",
       "   'summary': 'Weight matrix 1/1 (4096,4096): Lognorm: 1.2557973861694336'}},\n",
       " 22: {'id': 22,\n",
       "  'type': <keras.layers.core.Dense at 0xb3483f780>,\n",
       "  'layer_type': <LAYER_TYPE.DENSE: 1>,\n",
       "  0: {'N': 4096,\n",
       "   'M': 1000,\n",
       "   'Q': 4.096,\n",
       "   'lognorm': 1.224209,\n",
       "   'summary': 'Weight matrix 1/1 (1000,4096): Lognorm: 1.224208950996399'}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications import vgg16\n",
    "\n",
    "kmodel = vgg16.VGG16\n",
    "model = kmodel(weights='imagenet')\n",
    "\n",
    "import weightwatcher as ww\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "watcher.analyze(layers=ww.LAYER_TYPE.DENSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T00:41:10.386608Z",
     "start_time": "2018-11-27T00:41:10.352993Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:41:10,359 INFO ### Printing results ###\n",
      "2018-11-26 16:41:10,363 DEBUG Layer 20: Lognorm: 1.3697518110275269\n",
      "2018-11-26 16:41:10,368 DEBUG Layer 21: Lognorm: 1.2557973861694336\n",
      "2018-11-26 16:41:10,370 DEBUG Layer 22: Lognorm: 1.224208950996399\n",
      "2018-11-26 16:41:10,374 INFO LogNorm: min: 1.224208950996399, max: 1.3697518110275269, avg: 1.2832527160644531\n",
      "2018-11-26 16:41:10,377 INFO LogNorm compound: min: 1.224208950996399, max: 1.3697518110275269, avg: 1.2832527160644531\n"
     ]
    }
   ],
   "source": [
    "watcher.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Filter by multiple layer types\n",
    "\n",
    "In this example we are interested in the CONV1D and DENSE layers.\n",
    "\n",
    "Filter the layers using a bitmask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T00:41:12.083399Z",
     "start_time": "2018-11-27T00:41:10.398637Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:41:10,410 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 16:41:10,414 INFO Analyzing model 'vgg16' with 23 layers\n",
      "2018-11-26 16:41:10,419 INFO Layer 1: <keras.engine.input_layer.InputLayer object at 0xb39b05ef0>\n",
      "2018-11-26 16:41:10,421 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:10,425 INFO Layer 2: <keras.layers.convolutional.Conv2D object at 0xb39b056d8>\n",
      "2018-11-26 16:41:10,428 INFO Layer 2: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:10,431 INFO Layer 3: <keras.layers.convolutional.Conv2D object at 0xb39b42080>\n",
      "2018-11-26 16:41:10,436 INFO Layer 3: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:10,439 INFO Layer 4: <keras.layers.pooling.MaxPooling2D object at 0xb39b42550>\n",
      "2018-11-26 16:41:10,442 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:10,445 INFO Layer 5: <keras.layers.convolutional.Conv2D object at 0xb39b42e80>\n",
      "2018-11-26 16:41:10,448 INFO Layer 5: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:10,451 INFO Layer 6: <keras.layers.convolutional.Conv2D object at 0xb3ddd62b0>\n",
      "2018-11-26 16:41:10,454 INFO Layer 6: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:10,462 INFO Layer 7: <keras.layers.pooling.MaxPooling2D object at 0xb3ddf2470>\n",
      "2018-11-26 16:41:10,465 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:10,469 INFO Layer 8: <keras.layers.convolutional.Conv2D object at 0xb3ddf29b0>\n",
      "2018-11-26 16:41:10,473 INFO Layer 8: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:10,479 INFO Layer 9: <keras.layers.convolutional.Conv2D object at 0xb34693390>\n",
      "2018-11-26 16:41:10,482 INFO Layer 9: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:10,486 INFO Layer 10: <keras.layers.convolutional.Conv2D object at 0xb346b4748>\n",
      "2018-11-26 16:41:10,490 INFO Layer 10: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:10,493 INFO Layer 11: <keras.layers.pooling.MaxPooling2D object at 0xb346d8048>\n",
      "2018-11-26 16:41:10,496 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:10,501 INFO Layer 12: <keras.layers.convolutional.Conv2D object at 0xb346d8978>\n",
      "2018-11-26 16:41:10,505 INFO Layer 12: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:10,509 INFO Layer 13: <keras.layers.convolutional.Conv2D object at 0xb34717358>\n",
      "2018-11-26 16:41:10,513 INFO Layer 13: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:10,517 INFO Layer 14: <keras.layers.convolutional.Conv2D object at 0xb34739748>\n",
      "2018-11-26 16:41:10,521 INFO Layer 14: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:10,524 INFO Layer 15: <keras.layers.pooling.MaxPooling2D object at 0xb3475a048>\n",
      "2018-11-26 16:41:10,527 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:10,531 INFO Layer 16: <keras.layers.convolutional.Conv2D object at 0xb3475a978>\n",
      "2018-11-26 16:41:10,534 INFO Layer 16: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:10,537 INFO Layer 17: <keras.layers.convolutional.Conv2D object at 0xb34798358>\n",
      "2018-11-26 16:41:10,539 INFO Layer 17: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:10,543 INFO Layer 18: <keras.layers.convolutional.Conv2D object at 0xb347b8748>\n",
      "2018-11-26 16:41:10,546 INFO Layer 18: Skipping (Layer type not requested to analyze)\n",
      "2018-11-26 16:41:10,551 INFO Layer 19: <keras.layers.pooling.MaxPooling2D object at 0xb347df048>\n",
      "2018-11-26 16:41:10,555 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:10,559 INFO Layer 20: <keras.layers.core.Flatten object at 0xb347df978>\n",
      "2018-11-26 16:41:10,562 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:10,566 INFO Layer 21: <keras.layers.core.Dense object at 0xb347fa4a8>\n",
      "2018-11-26 16:41:11,668 INFO Layer 21: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:41:11,672 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 16:41:11,710 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.3697518110275269\n",
      "2018-11-26 16:41:11,714 INFO Layer 22: <keras.layers.core.Dense object at 0xb3481ccc0>\n",
      "2018-11-26 16:41:11,919 INFO Layer 22: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:41:11,921 INFO     Weight matrix 1/1 (4096,4096): Analyzing ...\n",
      "2018-11-26 16:41:11,932 INFO     Weight matrix 1/1 (4096,4096): Lognorm: 1.2557973861694336\n",
      "2018-11-26 16:41:11,941 INFO Layer 23: <keras.layers.core.Dense object at 0xb3483f780>\n",
      "2018-11-26 16:41:11,986 INFO Layer 23: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:41:11,991 INFO     Weight matrix 1/1 (1000,4096): Analyzing ...\n",
      "2018-11-26 16:41:11,998 INFO     Weight matrix 1/1 (1000,4096): Lognorm: 1.224208950996399\n",
      "2018-11-26 16:41:12,000 INFO ### Printing results ###\n",
      "2018-11-26 16:41:12,003 DEBUG Layer 20: Lognorm: 1.3697518110275269\n",
      "2018-11-26 16:41:12,010 DEBUG Layer 21: Lognorm: 1.2557973861694336\n",
      "2018-11-26 16:41:12,014 DEBUG Layer 22: Lognorm: 1.224208950996399\n",
      "2018-11-26 16:41:12,017 INFO LogNorm: min: 1.224208950996399, max: 1.3697518110275269, avg: 1.2832527160644531\n",
      "2018-11-26 16:41:12,038 INFO LogNorm compound: min: 1.224208950996399, max: 1.3697518110275269, avg: 1.2832527160644531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'id': 0,\n",
       "  'type': <keras.engine.input_layer.InputLayer at 0xb39b05ef0>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 1: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 2: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 3: {'id': 3,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb39b42550>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 4: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 5: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 6: {'id': 6,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb3ddf2470>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 7: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 8: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 9: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 10: {'id': 10,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb346d8048>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 11: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 12: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 13: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 14: {'id': 14,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb3475a048>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 15: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 16: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 17: {'layer_type': <LAYER_TYPE.CONV2D: 4>,\n",
       "  'message': 'Skipping (Layer type not requested to analyze)'},\n",
       " 18: {'id': 18,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb347df048>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 19: {'id': 19,\n",
       "  'type': <keras.layers.core.Flatten at 0xb347df978>,\n",
       "  'message': 'Skipping (Layer not supported)'},\n",
       " 20: {'id': 20,\n",
       "  'type': <keras.layers.core.Dense at 0xb347fa4a8>,\n",
       "  'layer_type': <LAYER_TYPE.DENSE: 1>,\n",
       "  0: {'N': 25088,\n",
       "   'M': 4096,\n",
       "   'Q': 6.125,\n",
       "   'lognorm': 1.3697518,\n",
       "   'summary': 'Weight matrix 1/1 (4096,25088): Lognorm: 1.3697518110275269'}},\n",
       " 21: {'id': 21,\n",
       "  'type': <keras.layers.core.Dense at 0xb3481ccc0>,\n",
       "  'layer_type': <LAYER_TYPE.DENSE: 1>,\n",
       "  0: {'N': 4096,\n",
       "   'M': 4096,\n",
       "   'Q': 1.0,\n",
       "   'lognorm': 1.2557974,\n",
       "   'summary': 'Weight matrix 1/1 (4096,4096): Lognorm: 1.2557973861694336'}},\n",
       " 22: {'id': 22,\n",
       "  'type': <keras.layers.core.Dense at 0xb3483f780>,\n",
       "  'layer_type': <LAYER_TYPE.DENSE: 1>,\n",
       "  0: {'N': 4096,\n",
       "   'M': 1000,\n",
       "   'Q': 4.096,\n",
       "   'lognorm': 1.224209,\n",
       "   'summary': 'Weight matrix 1/1 (1000,4096): Lognorm: 1.224208950996399'}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "watcher.analyze(layers=ww.LAYER_TYPE.CONV1D|ww.LAYER_TYPE.DENSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Filter by layer Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T00:41:13.535694Z",
     "start_time": "2018-11-27T00:41:12.091849Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:41:12,103 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 16:41:12,107 INFO Analyzing model 'vgg16' with 23 layers\n",
      "2018-11-26 16:41:12,112 INFO Layer 1: <keras.engine.input_layer.InputLayer object at 0xb39b05ef0>\n",
      "2018-11-26 16:41:12,120 INFO Layer 1: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,126 INFO Layer 2: <keras.layers.convolutional.Conv2D object at 0xb39b056d8>\n",
      "2018-11-26 16:41:12,130 INFO Layer 2: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,136 INFO Layer 3: <keras.layers.convolutional.Conv2D object at 0xb39b42080>\n",
      "2018-11-26 16:41:12,145 INFO Layer 3: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,148 INFO Layer 4: <keras.layers.pooling.MaxPooling2D object at 0xb39b42550>\n",
      "2018-11-26 16:41:12,153 INFO Layer 4: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,158 INFO Layer 5: <keras.layers.convolutional.Conv2D object at 0xb39b42e80>\n",
      "2018-11-26 16:41:12,161 INFO Layer 5: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,165 INFO Layer 6: <keras.layers.convolutional.Conv2D object at 0xb3ddd62b0>\n",
      "2018-11-26 16:41:12,175 INFO Layer 6: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,178 INFO Layer 7: <keras.layers.pooling.MaxPooling2D object at 0xb3ddf2470>\n",
      "2018-11-26 16:41:12,183 INFO Layer 7: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,187 INFO Layer 8: <keras.layers.convolutional.Conv2D object at 0xb3ddf29b0>\n",
      "2018-11-26 16:41:12,193 INFO Layer 8: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,203 INFO Layer 9: <keras.layers.convolutional.Conv2D object at 0xb34693390>\n",
      "2018-11-26 16:41:12,206 INFO Layer 9: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,210 INFO Layer 10: <keras.layers.convolutional.Conv2D object at 0xb346b4748>\n",
      "2018-11-26 16:41:12,216 INFO Layer 10: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,222 INFO Layer 11: <keras.layers.pooling.MaxPooling2D object at 0xb346d8048>\n",
      "2018-11-26 16:41:12,224 INFO Layer 11: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,229 INFO Layer 12: <keras.layers.convolutional.Conv2D object at 0xb346d8978>\n",
      "2018-11-26 16:41:12,235 INFO Layer 12: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,240 INFO Layer 13: <keras.layers.convolutional.Conv2D object at 0xb34717358>\n",
      "2018-11-26 16:41:12,246 INFO Layer 13: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,250 INFO Layer 14: <keras.layers.convolutional.Conv2D object at 0xb34739748>\n",
      "2018-11-26 16:41:12,253 INFO Layer 14: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,257 INFO Layer 15: <keras.layers.pooling.MaxPooling2D object at 0xb3475a048>\n",
      "2018-11-26 16:41:12,267 INFO Layer 15: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,269 INFO Layer 16: <keras.layers.convolutional.Conv2D object at 0xb3475a978>\n",
      "2018-11-26 16:41:12,272 INFO Layer 16: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,276 INFO Layer 17: <keras.layers.convolutional.Conv2D object at 0xb34798358>\n",
      "2018-11-26 16:41:12,279 INFO Layer 17: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,281 INFO Layer 18: <keras.layers.convolutional.Conv2D object at 0xb347b8748>\n",
      "2018-11-26 16:41:12,285 INFO Layer 18: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,291 INFO Layer 19: <keras.layers.pooling.MaxPooling2D object at 0xb347df048>\n",
      "2018-11-26 16:41:12,294 INFO Layer 19: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,302 INFO Layer 20: <keras.layers.core.Flatten object at 0xb347df978>\n",
      "2018-11-26 16:41:12,306 INFO Layer 20: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:12,309 INFO Layer 21: <keras.layers.core.Dense object at 0xb347fa4a8>\n",
      "2018-11-26 16:41:13,353 INFO Layer 21: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:41:13,357 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 16:41:13,394 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.3697518110275269\n",
      "2018-11-26 16:41:13,397 INFO Layer 22: <keras.layers.core.Dense object at 0xb3481ccc0>\n",
      "2018-11-26 16:41:13,494 INFO Layer 22: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:13,496 INFO Layer 23: <keras.layers.core.Dense object at 0xb3483f780>\n",
      "2018-11-26 16:41:13,499 INFO Layer 23: Skipping (Layer id not requested to analyze)\n",
      "2018-11-26 16:41:13,502 INFO ### Printing results ###\n",
      "2018-11-26 16:41:13,504 DEBUG Layer 20: Lognorm: 1.3697518110275269\n",
      "2018-11-26 16:41:13,507 INFO LogNorm: min: 1.3697518110275269, max: 1.3697518110275269, avg: 1.3697518110275269\n",
      "2018-11-26 16:41:13,510 INFO LogNorm compound: min: 1.3697518110275269, max: 1.3697518110275269, avg: 1.3697518110275269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'id': 0,\n",
       "  'type': <keras.engine.input_layer.InputLayer at 0xb39b05ef0>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 1: {'id': 1,\n",
       "  'type': <keras.layers.convolutional.Conv2D at 0xb39b056d8>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 2: {'id': 2,\n",
       "  'type': <keras.layers.convolutional.Conv2D at 0xb39b42080>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 3: {'id': 3,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb39b42550>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 4: {'id': 4,\n",
       "  'type': <keras.layers.convolutional.Conv2D at 0xb39b42e80>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 5: {'id': 5,\n",
       "  'type': <keras.layers.convolutional.Conv2D at 0xb3ddd62b0>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 6: {'id': 6,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb3ddf2470>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 7: {'id': 7,\n",
       "  'type': <keras.layers.convolutional.Conv2D at 0xb3ddf29b0>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 8: {'id': 8,\n",
       "  'type': <keras.layers.convolutional.Conv2D at 0xb34693390>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 9: {'id': 9,\n",
       "  'type': <keras.layers.convolutional.Conv2D at 0xb346b4748>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 10: {'id': 10,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb346d8048>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 11: {'id': 11,\n",
       "  'type': <keras.layers.convolutional.Conv2D at 0xb346d8978>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 12: {'id': 12,\n",
       "  'type': <keras.layers.convolutional.Conv2D at 0xb34717358>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 13: {'id': 13,\n",
       "  'type': <keras.layers.convolutional.Conv2D at 0xb34739748>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 14: {'id': 14,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb3475a048>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 15: {'id': 15,\n",
       "  'type': <keras.layers.convolutional.Conv2D at 0xb3475a978>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 16: {'id': 16,\n",
       "  'type': <keras.layers.convolutional.Conv2D at 0xb34798358>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 17: {'id': 17,\n",
       "  'type': <keras.layers.convolutional.Conv2D at 0xb347b8748>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 18: {'id': 18,\n",
       "  'type': <keras.layers.pooling.MaxPooling2D at 0xb347df048>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 19: {'id': 19,\n",
       "  'type': <keras.layers.core.Flatten at 0xb347df978>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 20: {'id': 20,\n",
       "  'type': <keras.layers.core.Dense at 0xb347fa4a8>,\n",
       "  'layer_type': <LAYER_TYPE.DENSE: 1>,\n",
       "  0: {'N': 25088,\n",
       "   'M': 4096,\n",
       "   'Q': 6.125,\n",
       "   'lognorm': 1.3697518,\n",
       "   'summary': 'Weight matrix 1/1 (4096,25088): Lognorm: 1.3697518110275269'}},\n",
       " 21: {'id': 21,\n",
       "  'type': <keras.layers.core.Dense at 0xb3481ccc0>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'},\n",
       " 22: {'id': 22,\n",
       "  'type': <keras.layers.core.Dense at 0xb3483f780>,\n",
       "  'message': 'Skipping (Layer id not requested to analyze)'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "watcher.analyze(layers=[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T22:51:12.554859Z",
     "start_time": "2018-10-01T22:51:12.518859Z"
    }
   },
   "source": [
    "## 2.4 Get the return values per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T00:41:17.074770Z",
     "start_time": "2018-11-27T00:41:13.542599Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:41:13,550 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 16:41:13,555 INFO Analyzing model 'vgg16' with 23 layers\n",
      "2018-11-26 16:41:13,559 INFO Layer 1: <keras.engine.input_layer.InputLayer object at 0xb39b05ef0>\n",
      "2018-11-26 16:41:13,561 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:13,565 INFO Layer 2: <keras.layers.convolutional.Conv2D object at 0xb39b056d8>\n",
      "2018-11-26 16:41:13,640 INFO Keras tensor shape detected: 3x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:13,643 INFO Layer 2: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:13,649 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:13,656 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:13,664 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:13,672 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:13,678 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:13,682 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:13,686 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:13,690 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:13,699 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:13,704 INFO Layer 3: <keras.layers.convolutional.Conv2D object at 0xb39b42080>\n",
      "2018-11-26 16:41:13,767 INFO Keras tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:13,772 INFO Layer 3: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:13,778 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:13,782 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.3978934586048126\n",
      "2018-11-26 16:41:13,789 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:13,797 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.45358702540397644\n",
      "2018-11-26 16:41:13,800 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:13,804 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.40578144788742065\n",
      "2018-11-26 16:41:13,808 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:13,816 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.45428669452667236\n",
      "2018-11-26 16:41:13,820 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:13,826 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.49695152044296265\n",
      "2018-11-26 16:41:13,832 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:13,835 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.45737624168395996\n",
      "2018-11-26 16:41:13,842 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:13,847 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.4044671952724457\n",
      "2018-11-26 16:41:13,853 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:13,864 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.4511153995990753\n",
      "2018-11-26 16:41:13,868 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:13,875 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.3889707922935486\n",
      "2018-11-26 16:41:13,879 INFO Layer 4: <keras.layers.pooling.MaxPooling2D object at 0xb39b42550>\n",
      "2018-11-26 16:41:13,884 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:13,890 INFO Layer 5: <keras.layers.convolutional.Conv2D object at 0xb39b42e80>\n",
      "2018-11-26 16:41:13,977 INFO Keras tensor shape detected: 64x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:13,980 INFO Layer 5: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:13,988 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:13,992 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.44109997153282166\n",
      "2018-11-26 16:41:13,997 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:14,001 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.4613628089427948\n",
      "2018-11-26 16:41:14,011 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:14,020 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.4370166063308716\n",
      "2018-11-26 16:41:14,023 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:14,027 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.4667660593986511\n",
      "2018-11-26 16:41:14,030 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:14,034 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.5201410055160522\n",
      "2018-11-26 16:41:14,039 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:14,050 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.46935534477233887\n",
      "2018-11-26 16:41:14,054 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:14,060 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.4464665651321411\n",
      "2018-11-26 16:41:14,064 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:14,068 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.48161619901657104\n",
      "2018-11-26 16:41:14,072 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:14,076 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.4471622705459595\n",
      "2018-11-26 16:41:14,079 INFO Layer 6: <keras.layers.convolutional.Conv2D object at 0xb3ddd62b0>\n",
      "2018-11-26 16:41:14,146 INFO Keras tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:14,150 INFO Layer 6: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:14,153 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:14,158 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.45507872104644775\n",
      "2018-11-26 16:41:14,161 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:14,165 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.4839082956314087\n",
      "2018-11-26 16:41:14,168 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:14,174 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.4593982994556427\n",
      "2018-11-26 16:41:14,177 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:14,185 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.48676982522010803\n",
      "2018-11-26 16:41:14,189 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:14,193 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.5329121351242065\n",
      "2018-11-26 16:41:14,196 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:14,200 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.486453115940094\n",
      "2018-11-26 16:41:14,203 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:14,206 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.4555995762348175\n",
      "2018-11-26 16:41:14,208 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:14,211 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.4885979890823364\n",
      "2018-11-26 16:41:14,215 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:14,218 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.44975680112838745\n",
      "2018-11-26 16:41:14,223 INFO Layer 7: <keras.layers.pooling.MaxPooling2D object at 0xb3ddf2470>\n",
      "2018-11-26 16:41:14,226 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:14,229 INFO Layer 8: <keras.layers.convolutional.Conv2D object at 0xb3ddf29b0>\n",
      "2018-11-26 16:41:14,296 INFO Keras tensor shape detected: 128x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:14,298 INFO Layer 8: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:14,302 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:14,305 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.4331028163433075\n",
      "2018-11-26 16:41:14,308 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:14,311 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.501900315284729\n",
      "2018-11-26 16:41:14,314 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:14,317 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.435834139585495\n",
      "2018-11-26 16:41:14,321 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:14,325 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.5173439979553223\n",
      "2018-11-26 16:41:14,328 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:14,332 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.630874752998352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:41:14,335 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:14,339 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.5137887597084045\n",
      "2018-11-26 16:41:14,345 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:14,349 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.4312974512577057\n",
      "2018-11-26 16:41:14,355 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:14,361 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.4997106194496155\n",
      "2018-11-26 16:41:14,365 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:14,370 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.42677345871925354\n",
      "2018-11-26 16:41:14,372 INFO Layer 9: <keras.layers.convolutional.Conv2D object at 0xb34693390>\n",
      "2018-11-26 16:41:14,444 INFO Keras tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:14,447 INFO Layer 9: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:14,449 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,452 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4611811339855194\n",
      "2018-11-26 16:41:14,455 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,458 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.5103280544281006\n",
      "2018-11-26 16:41:14,461 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,464 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.46348103880882263\n",
      "2018-11-26 16:41:14,466 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,471 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5043201446533203\n",
      "2018-11-26 16:41:14,476 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,480 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.5939016342163086\n",
      "2018-11-26 16:41:14,483 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,490 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.5075631737709045\n",
      "2018-11-26 16:41:14,493 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,497 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.45727992057800293\n",
      "2018-11-26 16:41:14,500 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,502 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.5017167329788208\n",
      "2018-11-26 16:41:14,505 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,509 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4612100124359131\n",
      "2018-11-26 16:41:14,511 INFO Layer 10: <keras.layers.convolutional.Conv2D object at 0xb346b4748>\n",
      "2018-11-26 16:41:14,569 INFO Keras tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:14,572 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:14,575 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,580 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4767092168331146\n",
      "2018-11-26 16:41:14,584 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,587 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.5228332281112671\n",
      "2018-11-26 16:41:14,589 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,593 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.48029711842536926\n",
      "2018-11-26 16:41:14,596 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,600 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5129597187042236\n",
      "2018-11-26 16:41:14,604 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,609 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.590246319770813\n",
      "2018-11-26 16:41:14,612 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,627 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.52484530210495\n",
      "2018-11-26 16:41:14,630 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,634 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.4757029116153717\n",
      "2018-11-26 16:41:14,637 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,642 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.5153258442878723\n",
      "2018-11-26 16:41:14,645 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:14,652 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4783080518245697\n",
      "2018-11-26 16:41:14,656 INFO Layer 11: <keras.layers.pooling.MaxPooling2D object at 0xb346d8048>\n",
      "2018-11-26 16:41:14,659 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:14,662 INFO Layer 12: <keras.layers.convolutional.Conv2D object at 0xb346d8978>\n",
      "2018-11-26 16:41:14,724 INFO Keras tensor shape detected: 256x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:14,726 INFO Layer 12: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:14,729 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:41:14,732 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.533117413520813\n",
      "2018-11-26 16:41:14,734 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:41:14,737 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.5677251815795898\n",
      "2018-11-26 16:41:14,741 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:41:14,745 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.5357765555381775\n",
      "2018-11-26 16:41:14,748 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:41:14,761 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.5680774450302124\n",
      "2018-11-26 16:41:14,763 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:41:14,766 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.6403180360794067\n",
      "2018-11-26 16:41:14,770 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:41:14,772 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.5651501417160034\n",
      "2018-11-26 16:41:14,775 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:41:14,778 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.5288751721382141\n",
      "2018-11-26 16:41:14,781 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:41:14,784 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.5627536177635193\n",
      "2018-11-26 16:41:14,787 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:41:14,791 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.5263329744338989\n",
      "2018-11-26 16:41:14,794 INFO Layer 13: <keras.layers.convolutional.Conv2D object at 0xb34717358>\n",
      "2018-11-26 16:41:14,854 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:14,857 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:14,860 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:14,864 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.5816661715507507\n",
      "2018-11-26 16:41:14,867 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:14,870 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.5994589924812317\n",
      "2018-11-26 16:41:14,877 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:14,880 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.5804641246795654\n",
      "2018-11-26 16:41:14,884 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:14,887 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.5878161787986755\n",
      "2018-11-26 16:41:14,892 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:14,896 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.6349806785583496\n",
      "2018-11-26 16:41:14,899 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:14,902 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.5888810753822327\n",
      "2018-11-26 16:41:14,905 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:14,908 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.5777970552444458\n",
      "2018-11-26 16:41:14,912 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:14,915 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.5947223901748657\n",
      "2018-11-26 16:41:14,918 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:14,922 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.5786637663841248\n",
      "2018-11-26 16:41:14,925 INFO Layer 14: <keras.layers.convolutional.Conv2D object at 0xb34739748>\n",
      "2018-11-26 16:41:15,007 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:15,009 INFO Layer 14: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:15,012 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,015 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.598810613155365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:41:15,018 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,021 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.6240571737289429\n",
      "2018-11-26 16:41:15,024 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,028 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.6002294421195984\n",
      "2018-11-26 16:41:15,030 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,034 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.6069265604019165\n",
      "2018-11-26 16:41:15,038 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,041 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.6537207961082458\n",
      "2018-11-26 16:41:15,043 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,046 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.6051104664802551\n",
      "2018-11-26 16:41:15,049 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,052 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.596659243106842\n",
      "2018-11-26 16:41:15,056 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,059 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.6204671859741211\n",
      "2018-11-26 16:41:15,062 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,065 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.5969995856285095\n",
      "2018-11-26 16:41:15,068 INFO Layer 15: <keras.layers.pooling.MaxPooling2D object at 0xb3475a048>\n",
      "2018-11-26 16:41:15,071 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:15,075 INFO Layer 16: <keras.layers.convolutional.Conv2D object at 0xb3475a978>\n",
      "2018-11-26 16:41:15,167 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:15,170 INFO Layer 16: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:15,174 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,178 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.6414387226104736\n",
      "2018-11-26 16:41:15,181 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,185 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.658482551574707\n",
      "2018-11-26 16:41:15,188 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,192 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.6415495276451111\n",
      "2018-11-26 16:41:15,196 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,201 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.6379082798957825\n",
      "2018-11-26 16:41:15,206 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,211 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.6930620670318604\n",
      "2018-11-26 16:41:15,215 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,219 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.6355615258216858\n",
      "2018-11-26 16:41:15,226 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,232 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.6379796266555786\n",
      "2018-11-26 16:41:15,239 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,246 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.6546915769577026\n",
      "2018-11-26 16:41:15,254 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,258 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.6379215717315674\n",
      "2018-11-26 16:41:15,263 INFO Layer 17: <keras.layers.convolutional.Conv2D object at 0xb34798358>\n",
      "2018-11-26 16:41:15,342 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:15,347 INFO Layer 17: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:15,354 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,358 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.6483020782470703\n",
      "2018-11-26 16:41:15,365 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,371 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.6716188788414001\n",
      "2018-11-26 16:41:15,376 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,380 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.6487486958503723\n",
      "2018-11-26 16:41:15,386 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,394 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.6313163042068481\n",
      "2018-11-26 16:41:15,397 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,403 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.690161406993866\n",
      "2018-11-26 16:41:15,410 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,414 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.6324495077133179\n",
      "2018-11-26 16:41:15,419 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,423 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.6435777544975281\n",
      "2018-11-26 16:41:15,427 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,431 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.6643065214157104\n",
      "2018-11-26 16:41:15,437 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,442 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.6426410675048828\n",
      "2018-11-26 16:41:15,445 INFO Layer 18: <keras.layers.convolutional.Conv2D object at 0xb347b8748>\n",
      "2018-11-26 16:41:15,525 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:15,528 INFO Layer 18: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:15,533 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,541 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.6312968730926514\n",
      "2018-11-26 16:41:15,544 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,548 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.6557008028030396\n",
      "2018-11-26 16:41:15,553 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,559 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.6303039193153381\n",
      "2018-11-26 16:41:15,564 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,568 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.6299318671226501\n",
      "2018-11-26 16:41:15,575 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,583 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.6738649010658264\n",
      "2018-11-26 16:41:15,588 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,600 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.6266793012619019\n",
      "2018-11-26 16:41:15,604 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,611 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.6302400231361389\n",
      "2018-11-26 16:41:15,620 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,629 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.6563602089881897\n",
      "2018-11-26 16:41:15,634 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:41:15,639 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.6300156712532043\n",
      "2018-11-26 16:41:15,646 INFO Layer 19: <keras.layers.pooling.MaxPooling2D object at 0xb347df048>\n",
      "2018-11-26 16:41:15,651 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:15,658 INFO Layer 20: <keras.layers.core.Flatten object at 0xb347df978>\n",
      "2018-11-26 16:41:15,662 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:15,667 INFO Layer 21: <keras.layers.core.Dense object at 0xb347fa4a8>\n",
      "2018-11-26 16:41:16,730 INFO Layer 21: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:41:16,733 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 16:41:16,773 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.3697518110275269\n",
      "2018-11-26 16:41:16,776 INFO Layer 22: <keras.layers.core.Dense object at 0xb3481ccc0>\n",
      "2018-11-26 16:41:16,932 INFO Layer 22: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:41:16,935 INFO     Weight matrix 1/1 (4096,4096): Analyzing ...\n",
      "2018-11-26 16:41:16,945 INFO     Weight matrix 1/1 (4096,4096): Lognorm: 1.2557973861694336\n",
      "2018-11-26 16:41:16,948 INFO Layer 23: <keras.layers.core.Dense object at 0xb3483f780>\n",
      "2018-11-26 16:41:16,986 INFO Layer 23: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:41:16,989 INFO     Weight matrix 1/1 (1000,4096): Analyzing ...\n",
      "2018-11-26 16:41:16,994 INFO     Weight matrix 1/1 (1000,4096): Lognorm: 1.224208950996399\n",
      "2018-11-26 16:41:16,998 INFO ### Printing results ###\n",
      "2018-11-26 16:41:17,001 DEBUG Layer 2: Lognorm compound: 0.43449219730165267\n",
      "2018-11-26 16:41:17,004 DEBUG Layer 4: Lognorm compound: 0.46344298124313354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:41:17,008 DEBUG Layer 5: Lognorm compound: 0.4776083065403832\n",
      "2018-11-26 16:41:17,013 DEBUG Layer 7: Lognorm compound: 0.487847367922465\n",
      "2018-11-26 16:41:17,017 DEBUG Layer 8: Lognorm compound: 0.49566464953952366\n",
      "2018-11-26 16:41:17,022 DEBUG Layer 9: Lognorm compound: 0.5085808568530612\n",
      "2018-11-26 16:41:17,025 DEBUG Layer 11: Lognorm compound: 0.5586807264222039\n",
      "2018-11-26 16:41:17,027 DEBUG Layer 12: Lognorm compound: 0.5916056036949158\n",
      "2018-11-26 16:41:17,030 DEBUG Layer 13: Lognorm compound: 0.6114423407448663\n",
      "2018-11-26 16:41:17,033 DEBUG Layer 15: Lognorm compound: 0.6487328277693855\n",
      "2018-11-26 16:41:17,036 DEBUG Layer 16: Lognorm compound: 0.6525691350301107\n",
      "2018-11-26 16:41:17,039 DEBUG Layer 17: Lognorm compound: 0.6404881742265489\n",
      "2018-11-26 16:41:17,042 DEBUG Layer 20: Lognorm: 1.3697518110275269\n",
      "2018-11-26 16:41:17,045 DEBUG Layer 21: Lognorm: 1.2557973861694336\n",
      "2018-11-26 16:41:17,048 DEBUG Layer 22: Lognorm: 1.224208950996399\n",
      "2018-11-26 16:41:17,051 INFO LogNorm: min: 0.3889707922935486, max: 1.3697518110275269, avg: 0.5674788951873779\n",
      "2018-11-26 16:41:17,053 INFO LogNorm compound: min: 0.43449219730165267, max: 1.3697518110275269, avg: 0.6947275543654406\n"
     ]
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "results = watcher.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T00:41:17.125512Z",
     "start_time": "2018-11-27T00:41:17.085017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2, Slice 0: Lognorm: 0.3978934586048126\n",
      "Layer 2, Slice 1: Lognorm: 0.45358702540397644\n",
      "Layer 2, Slice 2: Lognorm: 0.40578144788742065\n",
      "Layer 2, Slice 3: Lognorm: 0.45428669452667236\n",
      "Layer 2, Slice 4: Lognorm: 0.49695152044296265\n",
      "Layer 2, Slice 5: Lognorm: 0.45737624168395996\n",
      "Layer 2, Slice 6: Lognorm: 0.4044671952724457\n",
      "Layer 2, Slice 7: Lognorm: 0.4511153995990753\n",
      "Layer 2, Slice 8: Lognorm: 0.3889707922935486\n",
      "Layer 4, Slice 0: Lognorm: 0.44109997153282166\n",
      "Layer 4, Slice 1: Lognorm: 0.4613628089427948\n",
      "Layer 4, Slice 2: Lognorm: 0.4370166063308716\n",
      "Layer 4, Slice 3: Lognorm: 0.4667660593986511\n",
      "Layer 4, Slice 4: Lognorm: 0.5201410055160522\n",
      "Layer 4, Slice 5: Lognorm: 0.46935534477233887\n",
      "Layer 4, Slice 6: Lognorm: 0.4464665651321411\n",
      "Layer 4, Slice 7: Lognorm: 0.48161619901657104\n",
      "Layer 4, Slice 8: Lognorm: 0.4471622705459595\n",
      "Layer 5, Slice 0: Lognorm: 0.45507872104644775\n",
      "Layer 5, Slice 1: Lognorm: 0.4839082956314087\n",
      "Layer 5, Slice 2: Lognorm: 0.4593982994556427\n",
      "Layer 5, Slice 3: Lognorm: 0.48676982522010803\n",
      "Layer 5, Slice 4: Lognorm: 0.5329121351242065\n",
      "Layer 5, Slice 5: Lognorm: 0.486453115940094\n",
      "Layer 5, Slice 6: Lognorm: 0.4555995762348175\n",
      "Layer 5, Slice 7: Lognorm: 0.4885979890823364\n",
      "Layer 5, Slice 8: Lognorm: 0.44975680112838745\n",
      "Layer 7, Slice 0: Lognorm: 0.4331028163433075\n",
      "Layer 7, Slice 1: Lognorm: 0.501900315284729\n",
      "Layer 7, Slice 2: Lognorm: 0.435834139585495\n",
      "Layer 7, Slice 3: Lognorm: 0.5173439979553223\n",
      "Layer 7, Slice 4: Lognorm: 0.630874752998352\n",
      "Layer 7, Slice 5: Lognorm: 0.5137887597084045\n",
      "Layer 7, Slice 6: Lognorm: 0.4312974512577057\n",
      "Layer 7, Slice 7: Lognorm: 0.4997106194496155\n",
      "Layer 7, Slice 8: Lognorm: 0.42677345871925354\n",
      "Layer 8, Slice 0: Lognorm: 0.4611811339855194\n",
      "Layer 8, Slice 1: Lognorm: 0.5103280544281006\n",
      "Layer 8, Slice 2: Lognorm: 0.46348103880882263\n",
      "Layer 8, Slice 3: Lognorm: 0.5043201446533203\n",
      "Layer 8, Slice 4: Lognorm: 0.5939016342163086\n",
      "Layer 8, Slice 5: Lognorm: 0.5075631737709045\n",
      "Layer 8, Slice 6: Lognorm: 0.45727992057800293\n",
      "Layer 8, Slice 7: Lognorm: 0.5017167329788208\n",
      "Layer 8, Slice 8: Lognorm: 0.4612100124359131\n",
      "Layer 9, Slice 0: Lognorm: 0.4767092168331146\n",
      "Layer 9, Slice 1: Lognorm: 0.5228332281112671\n",
      "Layer 9, Slice 2: Lognorm: 0.48029711842536926\n",
      "Layer 9, Slice 3: Lognorm: 0.5129597187042236\n",
      "Layer 9, Slice 4: Lognorm: 0.590246319770813\n",
      "Layer 9, Slice 5: Lognorm: 0.52484530210495\n",
      "Layer 9, Slice 6: Lognorm: 0.4757029116153717\n",
      "Layer 9, Slice 7: Lognorm: 0.5153258442878723\n",
      "Layer 9, Slice 8: Lognorm: 0.4783080518245697\n",
      "Layer 11, Slice 0: Lognorm: 0.533117413520813\n",
      "Layer 11, Slice 1: Lognorm: 0.5677251815795898\n",
      "Layer 11, Slice 2: Lognorm: 0.5357765555381775\n",
      "Layer 11, Slice 3: Lognorm: 0.5680774450302124\n",
      "Layer 11, Slice 4: Lognorm: 0.6403180360794067\n",
      "Layer 11, Slice 5: Lognorm: 0.5651501417160034\n",
      "Layer 11, Slice 6: Lognorm: 0.5288751721382141\n",
      "Layer 11, Slice 7: Lognorm: 0.5627536177635193\n",
      "Layer 11, Slice 8: Lognorm: 0.5263329744338989\n",
      "Layer 12, Slice 0: Lognorm: 0.5816661715507507\n",
      "Layer 12, Slice 1: Lognorm: 0.5994589924812317\n",
      "Layer 12, Slice 2: Lognorm: 0.5804641246795654\n",
      "Layer 12, Slice 3: Lognorm: 0.5878161787986755\n",
      "Layer 12, Slice 4: Lognorm: 0.6349806785583496\n",
      "Layer 12, Slice 5: Lognorm: 0.5888810753822327\n",
      "Layer 12, Slice 6: Lognorm: 0.5777970552444458\n",
      "Layer 12, Slice 7: Lognorm: 0.5947223901748657\n",
      "Layer 12, Slice 8: Lognorm: 0.5786637663841248\n",
      "Layer 13, Slice 0: Lognorm: 0.598810613155365\n",
      "Layer 13, Slice 1: Lognorm: 0.6240571737289429\n",
      "Layer 13, Slice 2: Lognorm: 0.6002294421195984\n",
      "Layer 13, Slice 3: Lognorm: 0.6069265604019165\n",
      "Layer 13, Slice 4: Lognorm: 0.6537207961082458\n",
      "Layer 13, Slice 5: Lognorm: 0.6051104664802551\n",
      "Layer 13, Slice 6: Lognorm: 0.596659243106842\n",
      "Layer 13, Slice 7: Lognorm: 0.6204671859741211\n",
      "Layer 13, Slice 8: Lognorm: 0.5969995856285095\n",
      "Layer 15, Slice 0: Lognorm: 0.6414387226104736\n",
      "Layer 15, Slice 1: Lognorm: 0.658482551574707\n",
      "Layer 15, Slice 2: Lognorm: 0.6415495276451111\n",
      "Layer 15, Slice 3: Lognorm: 0.6379082798957825\n",
      "Layer 15, Slice 4: Lognorm: 0.6930620670318604\n",
      "Layer 15, Slice 5: Lognorm: 0.6355615258216858\n",
      "Layer 15, Slice 6: Lognorm: 0.6379796266555786\n",
      "Layer 15, Slice 7: Lognorm: 0.6546915769577026\n",
      "Layer 15, Slice 8: Lognorm: 0.6379215717315674\n",
      "Layer 16, Slice 0: Lognorm: 0.6483020782470703\n",
      "Layer 16, Slice 1: Lognorm: 0.6716188788414001\n",
      "Layer 16, Slice 2: Lognorm: 0.6487486958503723\n",
      "Layer 16, Slice 3: Lognorm: 0.6313163042068481\n",
      "Layer 16, Slice 4: Lognorm: 0.690161406993866\n",
      "Layer 16, Slice 5: Lognorm: 0.6324495077133179\n",
      "Layer 16, Slice 6: Lognorm: 0.6435777544975281\n",
      "Layer 16, Slice 7: Lognorm: 0.6643065214157104\n",
      "Layer 16, Slice 8: Lognorm: 0.6426410675048828\n",
      "Layer 17, Slice 0: Lognorm: 0.6312968730926514\n",
      "Layer 17, Slice 1: Lognorm: 0.6557008028030396\n",
      "Layer 17, Slice 2: Lognorm: 0.6303039193153381\n",
      "Layer 17, Slice 3: Lognorm: 0.6299318671226501\n",
      "Layer 17, Slice 4: Lognorm: 0.6738649010658264\n",
      "Layer 17, Slice 5: Lognorm: 0.6266793012619019\n",
      "Layer 17, Slice 6: Lognorm: 0.6302400231361389\n",
      "Layer 17, Slice 7: Lognorm: 0.6563602089881897\n",
      "Layer 17, Slice 8: Lognorm: 0.6300156712532043\n",
      "Layer 20, Slice 0: Lognorm: 1.3697518110275269\n",
      "Layer 21, Slice 0: Lognorm: 1.2557973861694336\n",
      "Layer 22, Slice 0: Lognorm: 1.224208950996399\n"
     ]
    }
   ],
   "source": [
    "for layer_id, result in results.items():\n",
    "    for slice_id, summary in result.items():\n",
    "        if not str(slice_id).isdigit() or \"lognorm\" not in summary:\n",
    "            continue\n",
    "        lognorm = summary[\"lognorm\"]\n",
    "        print(\"Layer {}, Slice {}: Lognorm: {}\".format(layer_id, slice_id, lognorm))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T22:51:12.554859Z",
     "start_time": "2018-10-01T22:51:12.518859Z"
    }
   },
   "source": [
    "## 2.5 Power Law Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T01:07:00.779260Z",
     "start_time": "2018-11-27T00:41:17.134974Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:41:17,140 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 16:41:17,144 INFO Analyzing model 'vgg16' with 23 layers\n",
      "2018-11-26 16:41:17,148 INFO Layer 1: <keras.engine.input_layer.InputLayer object at 0xb39b05ef0>\n",
      "2018-11-26 16:41:17,150 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:17,153 INFO Layer 2: <keras.layers.convolutional.Conv2D object at 0xb39b056d8>\n",
      "2018-11-26 16:41:17,158 INFO Keras tensor shape detected: 3x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:17,160 INFO Layer 2: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:17,162 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:17,167 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:17,170 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:17,175 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:17,178 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:17,182 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:17,185 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:17,187 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:17,190 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 16:41:17,192 INFO Layer 3: <keras.layers.convolutional.Conv2D object at 0xb39b42080>\n",
      "2018-11-26 16:41:17,198 INFO Keras tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:17,201 INFO Layer 3: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:17,207 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:17,964 INFO     Weight matrix 1/9 (64,64): Alpha: 1.2161096519963228, Alpha Weighted: 0.22362658026311097, D: 0.16421180631939913\n",
      "2018-11-26 16:41:17,966 INFO     Weight matrix 1/9 (64,64): Alpha 1.2161096519963228 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:17,969 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.3978934586048126\n",
      "2018-11-26 16:41:17,972 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:18,684 INFO     Weight matrix 2/9 (64,64): Alpha: 1.2249728181025226, Alpha Weighted: 0.3805813478547982, D: 0.170810020481601\n",
      "2018-11-26 16:41:18,687 INFO     Weight matrix 2/9 (64,64): Alpha 1.2249728181025226 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:18,689 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.45358702540397644\n",
      "2018-11-26 16:41:18,692 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:19,402 INFO     Weight matrix 3/9 (64,64): Alpha: 1.212181159645195, Alpha Weighted: 0.22159731278252812, D: 0.16896559100844222\n",
      "2018-11-26 16:41:19,405 INFO     Weight matrix 3/9 (64,64): Alpha 1.212181159645195 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:19,407 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.40578144788742065\n",
      "2018-11-26 16:41:19,410 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:20,103 INFO     Weight matrix 4/9 (64,64): Alpha: 1.2085927316124383, Alpha Weighted: 0.4062074553734556, D: 0.1563392105803787\n",
      "2018-11-26 16:41:20,105 INFO     Weight matrix 4/9 (64,64): Alpha 1.2085927316124383 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:20,108 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.45428669452667236\n",
      "2018-11-26 16:41:20,112 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:20,719 INFO     Weight matrix 5/9 (64,64): Alpha: 1.2069767289907984, Alpha Weighted: 0.5044894538203791, D: 0.1687756316308715\n",
      "2018-11-26 16:41:20,723 INFO     Weight matrix 5/9 (64,64): Alpha 1.2069767289907984 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:20,726 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.49695152044296265\n",
      "2018-11-26 16:41:20,729 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:21,210 INFO     Weight matrix 6/9 (64,64): Alpha: 1.2176375824308174, Alpha Weighted: 0.4417569215970778, D: 0.16845418001904244\n",
      "2018-11-26 16:41:21,213 INFO     Weight matrix 6/9 (64,64): Alpha 1.2176375824308174 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:21,216 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.45737624168395996\n",
      "2018-11-26 16:41:21,219 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:21,692 INFO     Weight matrix 7/9 (64,64): Alpha: 1.2299420662157012, Alpha Weighted: 0.2101468841980421, D: 0.17313531256051895\n",
      "2018-11-26 16:41:21,694 INFO     Weight matrix 7/9 (64,64): Alpha 1.2299420662157012 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:21,697 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.4044671952724457\n",
      "2018-11-26 16:41:21,699 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:22,167 INFO     Weight matrix 8/9 (64,64): Alpha: 1.2340212887536757, Alpha Weighted: 0.4244492759983183, D: 0.1632877164988063\n",
      "2018-11-26 16:41:22,170 INFO     Weight matrix 8/9 (64,64): Alpha 1.2340212887536757 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:22,172 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.4511153995990753\n",
      "2018-11-26 16:41:22,175 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 16:41:22,646 INFO     Weight matrix 9/9 (64,64): Alpha: 1.208272982792027, Alpha Weighted: 0.1431338354832048, D: 0.1766302824600463\n",
      "2018-11-26 16:41:22,649 INFO     Weight matrix 9/9 (64,64): Alpha 1.208272982792027 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:22,653 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.3889707922935486\n",
      "2018-11-26 16:41:22,657 INFO Layer 4: <keras.layers.pooling.MaxPooling2D object at 0xb39b42550>\n",
      "2018-11-26 16:41:22,660 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:22,662 INFO Layer 5: <keras.layers.convolutional.Conv2D object at 0xb39b42e80>\n",
      "2018-11-26 16:41:22,667 INFO Keras tensor shape detected: 64x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:22,669 INFO Layer 5: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:22,673 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:23,164 INFO     Weight matrix 1/9 (64,128): Alpha: 1.3661662294317036, Alpha Weighted: 0.268879480732599, D: 0.1629901546003104\n",
      "2018-11-26 16:41:23,166 INFO     Weight matrix 1/9 (64,128): Alpha 1.3661662294317036 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:23,169 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.44109997153282166\n",
      "2018-11-26 16:41:23,174 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:23,634 INFO     Weight matrix 2/9 (64,128): Alpha: 1.3317782331307018, Alpha Weighted: 0.048638863672571954, D: 0.19049227634905336\n",
      "2018-11-26 16:41:23,637 INFO     Weight matrix 2/9 (64,128): Alpha 1.3317782331307018 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:23,639 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.4613628089427948\n",
      "2018-11-26 16:41:23,642 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:24,105 INFO     Weight matrix 3/9 (64,128): Alpha: 1.3717680582491267, Alpha Weighted: 0.2734132099923901, D: 0.16321374812009126\n",
      "2018-11-26 16:41:24,107 INFO     Weight matrix 3/9 (64,128): Alpha 1.3717680582491267 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:24,111 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.4370166063308716\n",
      "2018-11-26 16:41:24,115 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:24,683 INFO     Weight matrix 4/9 (64,128): Alpha: 1.3604810393573958, Alpha Weighted: 0.08520494781415014, D: 0.18113814257187688\n",
      "2018-11-26 16:41:24,685 INFO     Weight matrix 4/9 (64,128): Alpha 1.3604810393573958 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:24,689 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.4667660593986511\n",
      "2018-11-26 16:41:24,691 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:25,341 INFO     Weight matrix 5/9 (64,128): Alpha: 1.5275779547107815, Alpha Weighted: 0.5909503141860099, D: 0.16718321407184888\n",
      "2018-11-26 16:41:25,345 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.5201410055160522\n",
      "2018-11-26 16:41:25,350 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:41:25,918 INFO     Weight matrix 6/9 (64,128): Alpha: 1.3558540115233908, Alpha Weighted: 0.10245061691134408, D: 0.1839298194906579\n",
      "2018-11-26 16:41:25,923 INFO     Weight matrix 6/9 (64,128): Alpha 1.3558540115233908 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:25,929 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.46935534477233887\n",
      "2018-11-26 16:41:25,935 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:26,564 INFO     Weight matrix 7/9 (64,128): Alpha: 1.3434109601398498, Alpha Weighted: 0.252610717283402, D: 0.1554494128742393\n",
      "2018-11-26 16:41:26,566 INFO     Weight matrix 7/9 (64,128): Alpha 1.3434109601398498 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:26,569 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.4464665651321411\n",
      "2018-11-26 16:41:26,573 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:27,387 INFO     Weight matrix 8/9 (64,128): Alpha: 1.3569155885268285, Alpha Weighted: 0.08792181378671417, D: 0.18552311126537557\n",
      "2018-11-26 16:41:27,393 INFO     Weight matrix 8/9 (64,128): Alpha 1.3569155885268285 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:27,400 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.48161619901657104\n",
      "2018-11-26 16:41:27,406 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 16:41:28,073 INFO     Weight matrix 9/9 (64,128): Alpha: 1.3499599958926047, Alpha Weighted: 0.27428350433044446, D: 0.16330665157891744\n",
      "2018-11-26 16:41:28,076 INFO     Weight matrix 9/9 (64,128): Alpha 1.3499599958926047 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:28,080 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.4471622705459595\n",
      "2018-11-26 16:41:28,089 INFO Layer 6: <keras.layers.convolutional.Conv2D object at 0xb3ddd62b0>\n",
      "2018-11-26 16:41:28,096 INFO Keras tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:28,099 INFO Layer 6: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:28,105 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:29,353 INFO     Weight matrix 1/9 (128,128): Alpha: 3.2638749471375847, Alpha Weighted: -0.06970038188493057, D: 0.1702619101239422\n",
      "2018-11-26 16:41:29,357 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.45507872104644775\n",
      "2018-11-26 16:41:29,360 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:30,406 INFO     Weight matrix 2/9 (128,128): Alpha: 1.3800728088777188, Alpha Weighted: -0.11781755150498616, D: 0.1944985702001938\n",
      "2018-11-26 16:41:30,409 INFO     Weight matrix 2/9 (128,128): Alpha 1.3800728088777188 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:30,414 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.4839082956314087\n",
      "2018-11-26 16:41:30,418 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:31,421 INFO     Weight matrix 3/9 (128,128): Alpha: 3.1691016223412753, Alpha Weighted: 0.08503500932307162, D: 0.13552009044594526\n",
      "2018-11-26 16:41:31,424 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.4593982994556427\n",
      "2018-11-26 16:41:31,426 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:32,469 INFO     Weight matrix 4/9 (128,128): Alpha: 1.6451526925519924, Alpha Weighted: -0.0663282935461865, D: 0.1931038931266449\n",
      "2018-11-26 16:41:32,472 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.48676982522010803\n",
      "2018-11-26 16:41:32,475 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:33,713 INFO     Weight matrix 5/9 (128,128): Alpha: 3.045125217549562, Alpha Weighted: 0.10438264491382065, D: 0.1774883779685429\n",
      "2018-11-26 16:41:33,716 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.5329121351242065\n",
      "2018-11-26 16:41:33,719 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:34,706 INFO     Weight matrix 6/9 (128,128): Alpha: 1.3984495342559926, Alpha Weighted: -0.04776420534272548, D: 0.1937820636810363\n",
      "2018-11-26 16:41:34,709 INFO     Weight matrix 6/9 (128,128): Alpha 1.3984495342559926 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:34,712 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.486453115940094\n",
      "2018-11-26 16:41:34,715 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:35,721 INFO     Weight matrix 7/9 (128,128): Alpha: 4.433820169405862, Alpha Weighted: 0.10263231951663904, D: 0.14285714285714257\n",
      "2018-11-26 16:41:35,724 INFO     Weight matrix 7/9 (128,128): Alpha 4.433820169405862 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:41:35,728 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.4555995762348175\n",
      "2018-11-26 16:41:35,731 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:36,807 INFO     Weight matrix 8/9 (128,128): Alpha: 1.5929456421491468, Alpha Weighted: -0.12536019107516302, D: 0.20169450942092204\n",
      "2018-11-26 16:41:36,809 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.4885979890823364\n",
      "2018-11-26 16:41:36,812 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 16:41:37,870 INFO     Weight matrix 9/9 (128,128): Alpha: 3.4309825702999706, Alpha Weighted: -0.03263179247565314, D: 0.13033441796991285\n",
      "2018-11-26 16:41:37,873 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.44975680112838745\n",
      "2018-11-26 16:41:37,875 INFO Layer 7: <keras.layers.pooling.MaxPooling2D object at 0xb3ddf2470>\n",
      "2018-11-26 16:41:37,878 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 16:41:37,881 INFO Layer 8: <keras.layers.convolutional.Conv2D object at 0xb3ddf29b0>\n",
      "2018-11-26 16:41:37,891 INFO Keras tensor shape detected: 128x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:37,894 INFO Layer 8: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:37,897 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:39,262 INFO     Weight matrix 1/9 (128,256): Alpha: 3.0216067231004096, Alpha Weighted: -0.8172064934889326, D: 0.14660942122247222\n",
      "2018-11-26 16:41:39,265 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.4331028163433075\n",
      "2018-11-26 16:41:39,267 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:40,539 INFO     Weight matrix 2/9 (128,256): Alpha: 2.110112266754127, Alpha Weighted: -0.19661169441526063, D: 0.14569075023960465\n",
      "2018-11-26 16:41:40,542 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.501900315284729\n",
      "2018-11-26 16:41:40,546 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:41,977 INFO     Weight matrix 3/9 (128,256): Alpha: 3.0517294576952834, Alpha Weighted: -0.8768828063458, D: 0.1454625323576042\n",
      "2018-11-26 16:41:41,980 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.435834139585495\n",
      "2018-11-26 16:41:41,986 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:43,142 INFO     Weight matrix 4/9 (128,256): Alpha: 1.9422340651633743, Alpha Weighted: -0.07996973738750789, D: 0.16584182745850057\n",
      "2018-11-26 16:41:43,146 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.5173439979553223\n",
      "2018-11-26 16:41:43,148 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:44,180 INFO     Weight matrix 5/9 (128,256): Alpha: 1.9678178949961929, Alpha Weighted: 0.3598443034424527, D: 0.15354685161567783\n",
      "2018-11-26 16:41:44,183 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.630874752998352\n",
      "2018-11-26 16:41:44,186 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:45,494 INFO     Weight matrix 6/9 (128,256): Alpha: 2.128361089101459, Alpha Weighted: -0.07032491592350922, D: 0.1402810146665514\n",
      "2018-11-26 16:41:45,497 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.5137887597084045\n",
      "2018-11-26 16:41:45,500 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:46,597 INFO     Weight matrix 7/9 (128,256): Alpha: 2.939156741054643, Alpha Weighted: -0.7864180488431498, D: 0.1351691128452447\n",
      "2018-11-26 16:41:46,600 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.4312974512577057\n",
      "2018-11-26 16:41:46,603 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:47,624 INFO     Weight matrix 8/9 (128,256): Alpha: 2.2091636958484937, Alpha Weighted: -0.3162172622256039, D: 0.14612568508638757\n",
      "2018-11-26 16:41:47,627 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.4997106194496155\n",
      "2018-11-26 16:41:47,630 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 16:41:48,675 INFO     Weight matrix 9/9 (128,256): Alpha: 2.939458225246966, Alpha Weighted: -0.8309820434390611, D: 0.18470799743862643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:41:48,679 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.42677345871925354\n",
      "2018-11-26 16:41:48,681 INFO Layer 9: <keras.layers.convolutional.Conv2D object at 0xb34693390>\n",
      "2018-11-26 16:41:48,687 INFO Keras tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:41:48,690 INFO Layer 9: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:41:48,694 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:51,226 INFO     Weight matrix 1/9 (256,256): Alpha: 2.7401523375464, Alpha Weighted: -0.8124559775252056, D: 0.13306955094020018\n",
      "2018-11-26 16:41:51,230 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4611811339855194\n",
      "2018-11-26 16:41:51,233 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:53,846 INFO     Weight matrix 2/9 (256,256): Alpha: 2.0788314572583904, Alpha Weighted: -0.43420123852685927, D: 0.15684703744224643\n",
      "2018-11-26 16:41:53,849 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.5103280544281006\n",
      "2018-11-26 16:41:53,851 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:56,410 INFO     Weight matrix 3/9 (256,256): Alpha: 2.929131990322833, Alpha Weighted: -0.856396842353084, D: 0.13673808412076605\n",
      "2018-11-26 16:41:56,413 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.46348103880882263\n",
      "2018-11-26 16:41:56,416 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:41:59,075 INFO     Weight matrix 4/9 (256,256): Alpha: 2.33307787016737, Alpha Weighted: -0.4680144779689566, D: 0.13255306172666326\n",
      "2018-11-26 16:41:59,078 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5043201446533203\n",
      "2018-11-26 16:41:59,081 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:02,116 INFO     Weight matrix 5/9 (256,256): Alpha: 1.9301406640802774, Alpha Weighted: 0.03289294638762482, D: 0.15902799665572537\n",
      "2018-11-26 16:42:02,119 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.5939016342163086\n",
      "2018-11-26 16:42:02,126 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:05,147 INFO     Weight matrix 6/9 (256,256): Alpha: 2.937056616246706, Alpha Weighted: -0.5370697408353378, D: 0.12162771172924713\n",
      "2018-11-26 16:42:05,152 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.5075631737709045\n",
      "2018-11-26 16:42:05,157 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:08,057 INFO     Weight matrix 7/9 (256,256): Alpha: 2.3697628810564892, Alpha Weighted: -0.7309425868757045, D: 0.13089911281829436\n",
      "2018-11-26 16:42:08,060 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.45727992057800293\n",
      "2018-11-26 16:42:08,066 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:10,639 INFO     Weight matrix 8/9 (256,256): Alpha: 3.637365141205676, Alpha Weighted: -0.7520705206954105, D: 0.14873549913752715\n",
      "2018-11-26 16:42:10,641 INFO     Weight matrix 8/9 (256,256): Alpha 3.637365141205676 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:42:10,644 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.5017167329788208\n",
      "2018-11-26 16:42:10,648 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:13,295 INFO     Weight matrix 9/9 (256,256): Alpha: 2.2190458629617207, Alpha Weighted: -0.6613311699738796, D: 0.1387840065615082\n",
      "2018-11-26 16:42:13,299 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4612100124359131\n",
      "2018-11-26 16:42:13,302 INFO Layer 10: <keras.layers.convolutional.Conv2D object at 0xb346b4748>\n",
      "2018-11-26 16:42:13,316 INFO Keras tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:42:13,319 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:42:13,322 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:16,142 INFO     Weight matrix 1/9 (256,256): Alpha: 2.4329666463377526, Alpha Weighted: -0.7286360685779852, D: 0.13521441743662455\n",
      "2018-11-26 16:42:16,145 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4767092168331146\n",
      "2018-11-26 16:42:16,149 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:18,822 INFO     Weight matrix 2/9 (256,256): Alpha: 2.931654561985182, Alpha Weighted: -0.6002028489352846, D: 0.12059377124601056\n",
      "2018-11-26 16:42:18,825 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.5228332281112671\n",
      "2018-11-26 16:42:18,828 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:21,498 INFO     Weight matrix 3/9 (256,256): Alpha: 2.9850770948194345, Alpha Weighted: -0.8591149266199288, D: 0.1043137139740743\n",
      "2018-11-26 16:42:21,502 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.48029711842536926\n",
      "2018-11-26 16:42:21,504 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:24,207 INFO     Weight matrix 4/9 (256,256): Alpha: 3.2786248931523376, Alpha Weighted: -0.6636659317936437, D: 0.10557271404205903\n",
      "2018-11-26 16:42:24,209 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5129597187042236\n",
      "2018-11-26 16:42:24,212 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:26,708 INFO     Weight matrix 5/9 (256,256): Alpha: 2.469854742208894, Alpha Weighted: -0.11088505981166903, D: 0.15543620170392858\n",
      "2018-11-26 16:42:26,711 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.590246319770813\n",
      "2018-11-26 16:42:26,713 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:29,174 INFO     Weight matrix 6/9 (256,256): Alpha: 3.13928659658157, Alpha Weighted: -0.6160019824091935, D: 0.11066300539574625\n",
      "2018-11-26 16:42:29,176 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.52484530210495\n",
      "2018-11-26 16:42:29,179 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:31,649 INFO     Weight matrix 7/9 (256,256): Alpha: 2.81027429536793, Alpha Weighted: -0.8489652793033805, D: 0.1277299296019747\n",
      "2018-11-26 16:42:31,652 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.4757029116153717\n",
      "2018-11-26 16:42:31,655 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:34,108 INFO     Weight matrix 8/9 (256,256): Alpha: 3.2167841319281556, Alpha Weighted: -0.8382287567808533, D: 0.12622344927223117\n",
      "2018-11-26 16:42:34,111 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.5153258442878723\n",
      "2018-11-26 16:42:34,114 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 16:42:36,578 INFO     Weight matrix 9/9 (256,256): Alpha: 2.7758696185178784, Alpha Weighted: -0.8847856743327502, D: 0.13046000094992405\n",
      "2018-11-26 16:42:36,581 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4783080518245697\n",
      "2018-11-26 16:42:36,583 INFO Layer 11: <keras.layers.pooling.MaxPooling2D object at 0xb346d8048>\n",
      "2018-11-26 16:42:36,587 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 16:42:36,590 INFO Layer 12: <keras.layers.convolutional.Conv2D object at 0xb346d8978>\n",
      "2018-11-26 16:42:36,621 INFO Keras tensor shape detected: 256x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:42:36,624 INFO Layer 12: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:42:36,627 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:42:39,104 INFO     Weight matrix 1/9 (256,512): Alpha: 2.364167640234239, Alpha Weighted: -0.6609432623611989, D: 0.13490830392132092\n",
      "2018-11-26 16:42:39,107 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.533117413520813\n",
      "2018-11-26 16:42:39,110 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:42:41,615 INFO     Weight matrix 2/9 (256,512): Alpha: 3.1590544680237254, Alpha Weighted: -0.707769160977521, D: 0.1446858266859874\n",
      "2018-11-26 16:42:41,618 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.5677251815795898\n",
      "2018-11-26 16:42:41,620 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:42:44,326 INFO     Weight matrix 3/9 (256,512): Alpha: 2.2482585375237853, Alpha Weighted: -0.5067889007401266, D: 0.12790646751725993\n",
      "2018-11-26 16:42:44,330 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.5357765555381775\n",
      "2018-11-26 16:42:44,336 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:42:47,094 INFO     Weight matrix 4/9 (256,512): Alpha: 3.817123143221276, Alpha Weighted: -0.7588555612622296, D: 0.14265396988713175\n",
      "2018-11-26 16:42:47,098 INFO     Weight matrix 4/9 (256,512): Alpha 3.817123143221276 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:42:47,102 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.5680774450302124\n",
      "2018-11-26 16:42:47,105 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:42:49,714 INFO     Weight matrix 5/9 (256,512): Alpha: 4.558138051733277, Alpha Weighted: -0.31937864011004025, D: 0.13152441739994614\n",
      "2018-11-26 16:42:49,716 INFO     Weight matrix 5/9 (256,512): Alpha 4.558138051733277 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:42:49,720 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.6403180360794067\n",
      "2018-11-26 16:42:49,722 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:42:52,237 INFO     Weight matrix 6/9 (256,512): Alpha: 2.8729921549850315, Alpha Weighted: -0.5960262464640637, D: 0.14687150282062983\n",
      "2018-11-26 16:42:52,240 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.5651501417160034\n",
      "2018-11-26 16:42:52,243 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:42:54,768 INFO     Weight matrix 7/9 (256,512): Alpha: 2.7529105519454653, Alpha Weighted: -0.8162863768774217, D: 0.1467726778957955\n",
      "2018-11-26 16:42:54,771 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.5288751721382141\n",
      "2018-11-26 16:42:54,774 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:42:57,297 INFO     Weight matrix 8/9 (256,512): Alpha: 3.20460185567771, Alpha Weighted: -0.7782013824476754, D: 0.14424607079603458\n",
      "2018-11-26 16:42:57,300 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.5627536177635193\n",
      "2018-11-26 16:42:57,303 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 16:43:00,051 INFO     Weight matrix 9/9 (256,512): Alpha: 2.094559147350272, Alpha Weighted: -0.6582193159745848, D: 0.14547176099700332\n",
      "2018-11-26 16:43:00,054 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.5263329744338989\n",
      "2018-11-26 16:43:00,057 INFO Layer 13: <keras.layers.convolutional.Conv2D object at 0xb34717358>\n",
      "2018-11-26 16:43:00,086 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:43:00,089 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:43:00,095 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:43:07,148 INFO     Weight matrix 1/9 (512,512): Alpha: 2.4960760781361, Alpha Weighted: -0.5649404623958039, D: 0.08592897757923768\n",
      "2018-11-26 16:43:07,152 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.5816661715507507\n",
      "2018-11-26 16:43:07,155 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:43:14,797 INFO     Weight matrix 2/9 (512,512): Alpha: 3.265329711465425, Alpha Weighted: -0.5795340656473416, D: 0.0779974744256503\n",
      "2018-11-26 16:43:14,802 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.5994589924812317\n",
      "2018-11-26 16:43:14,806 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:43:23,362 INFO     Weight matrix 3/9 (512,512): Alpha: 2.549171709452101, Alpha Weighted: -0.5588675913840842, D: 0.08084215422870339\n",
      "2018-11-26 16:43:23,367 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.5804641246795654\n",
      "2018-11-26 16:43:23,370 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:43:31,541 INFO     Weight matrix 4/9 (512,512): Alpha: 3.0763252056615777, Alpha Weighted: -0.4517510825037836, D: 0.079901130314318\n",
      "2018-11-26 16:43:31,544 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.5878161787986755\n",
      "2018-11-26 16:43:31,551 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:43:40,080 INFO     Weight matrix 5/9 (512,512): Alpha: 3.593485620460209, Alpha Weighted: -0.21350209385008495, D: 0.10705730181425482\n",
      "2018-11-26 16:43:40,083 INFO     Weight matrix 5/9 (512,512): Alpha 3.593485620460209 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:43:40,087 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.6349806785583496\n",
      "2018-11-26 16:43:40,089 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:43:47,700 INFO     Weight matrix 6/9 (512,512): Alpha: 3.16241304934653, Alpha Weighted: -0.4576774792612034, D: 0.08532748032028292\n",
      "2018-11-26 16:43:47,703 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.5888810753822327\n",
      "2018-11-26 16:43:47,710 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:43:54,581 INFO     Weight matrix 7/9 (512,512): Alpha: 2.506251687443547, Alpha Weighted: -0.6090012730784675, D: 0.08892058640280565\n",
      "2018-11-26 16:43:54,585 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.5777970552444458\n",
      "2018-11-26 16:43:54,588 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:44:02,113 INFO     Weight matrix 8/9 (512,512): Alpha: 3.1905810585219134, Alpha Weighted: -0.5626129873274365, D: 0.0816796090221037\n",
      "2018-11-26 16:44:02,118 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.5947223901748657\n",
      "2018-11-26 16:44:02,122 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:44:09,537 INFO     Weight matrix 9/9 (512,512): Alpha: 2.4162544922384406, Alpha Weighted: -0.5766148530327043, D: 0.09833403841306304\n",
      "2018-11-26 16:44:09,540 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.5786637663841248\n",
      "2018-11-26 16:44:09,547 INFO Layer 14: <keras.layers.convolutional.Conv2D object at 0xb34739748>\n",
      "2018-11-26 16:44:09,585 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:44:09,589 INFO Layer 14: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:44:09,592 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:44:16,709 INFO     Weight matrix 1/9 (512,512): Alpha: 2.9842382686636397, Alpha Weighted: -0.3543459390391824, D: 0.0603761378851454\n",
      "2018-11-26 16:44:16,712 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.598810613155365\n",
      "2018-11-26 16:44:16,715 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:44:23,523 INFO     Weight matrix 2/9 (512,512): Alpha: 3.241834986237952, Alpha Weighted: -0.2306731202219697, D: 0.05412788687285386\n",
      "2018-11-26 16:44:23,526 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.6240571737289429\n",
      "2018-11-26 16:44:23,530 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:44:30,294 INFO     Weight matrix 3/9 (512,512): Alpha: 3.0541200625404965, Alpha Weighted: -0.3454762045425034, D: 0.05098465941003516\n",
      "2018-11-26 16:44:30,298 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.6002294421195984\n",
      "2018-11-26 16:44:30,303 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:44:37,346 INFO     Weight matrix 4/9 (512,512): Alpha: 3.270886819986247, Alpha Weighted: -0.3341216512383068, D: 0.07138686016070184\n",
      "2018-11-26 16:44:37,349 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.6069265604019165\n",
      "2018-11-26 16:44:37,351 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:44:44,483 INFO     Weight matrix 5/9 (512,512): Alpha: 3.699726908701783, Alpha Weighted: 0.05518207357267268, D: 0.07766433640753806\n",
      "2018-11-26 16:44:44,486 INFO     Weight matrix 5/9 (512,512): Alpha 3.699726908701783 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:44:44,494 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.6537207961082458\n",
      "2018-11-26 16:44:44,498 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:44:52,586 INFO     Weight matrix 6/9 (512,512): Alpha: 3.1718046950119403, Alpha Weighted: -0.2573170943104603, D: 0.06083424388974662\n",
      "2018-11-26 16:44:52,590 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.6051104664802551\n",
      "2018-11-26 16:44:52,593 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:45:00,165 INFO     Weight matrix 7/9 (512,512): Alpha: 2.9744387920239257, Alpha Weighted: -0.3306135374131475, D: 0.05249609559498117\n",
      "2018-11-26 16:45:00,169 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.596659243106842\n",
      "2018-11-26 16:45:00,175 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:45:06,964 INFO     Weight matrix 8/9 (512,512): Alpha: 3.3124412266437444, Alpha Weighted: -0.2155779017034764, D: 0.059719762338485305\n",
      "2018-11-26 16:45:06,967 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.6204671859741211\n",
      "2018-11-26 16:45:06,970 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:45:13,770 INFO     Weight matrix 9/9 (512,512): Alpha: 3.138694648927828, Alpha Weighted: -0.3304816347864379, D: 0.06231186729775995\n",
      "2018-11-26 16:45:13,773 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.5969995856285095\n",
      "2018-11-26 16:45:13,776 INFO Layer 15: <keras.layers.pooling.MaxPooling2D object at 0xb3475a048>\n",
      "2018-11-26 16:45:13,779 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 16:45:13,783 INFO Layer 16: <keras.layers.convolutional.Conv2D object at 0xb3475a978>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:45:13,801 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:45:13,805 INFO Layer 16: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:45:13,808 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:45:20,575 INFO     Weight matrix 1/9 (512,512): Alpha: 3.1962287489072323, Alpha Weighted: -0.6066026192764318, D: 0.07444709319382659\n",
      "2018-11-26 16:45:20,578 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.6414387226104736\n",
      "2018-11-26 16:45:20,581 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:45:27,383 INFO     Weight matrix 2/9 (512,512): Alpha: 2.679294589678197, Alpha Weighted: -0.747789445445618, D: 0.11304185171330272\n",
      "2018-11-26 16:45:27,387 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.658482551574707\n",
      "2018-11-26 16:45:27,390 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:45:34,189 INFO     Weight matrix 3/9 (512,512): Alpha: 3.4455258778825484, Alpha Weighted: -0.623572905720464, D: 0.07937940486618666\n",
      "2018-11-26 16:45:34,192 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.6415495276451111\n",
      "2018-11-26 16:45:34,195 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:45:41,112 INFO     Weight matrix 4/9 (512,512): Alpha: 2.5474498913326813, Alpha Weighted: -0.6873564339729658, D: 0.1013780616085137\n",
      "2018-11-26 16:45:41,115 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.6379082798957825\n",
      "2018-11-26 16:45:41,118 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:45:48,002 INFO     Weight matrix 5/9 (512,512): Alpha: 2.295223212665247, Alpha Weighted: -0.4812999358275576, D: 0.12530103507550105\n",
      "2018-11-26 16:45:48,005 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.6930620670318604\n",
      "2018-11-26 16:45:48,008 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:45:55,303 INFO     Weight matrix 6/9 (512,512): Alpha: 3.911934955361376, Alpha Weighted: -1.087618285865235, D: 0.07847108385672474\n",
      "2018-11-26 16:45:55,305 INFO     Weight matrix 6/9 (512,512): Alpha 3.911934955361376 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:45:55,309 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.6355615258216858\n",
      "2018-11-26 16:45:55,312 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:46:02,332 INFO     Weight matrix 7/9 (512,512): Alpha: 3.3407872976338746, Alpha Weighted: -0.7529659679388202, D: 0.0747493817599606\n",
      "2018-11-26 16:46:02,335 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.6379796266555786\n",
      "2018-11-26 16:46:02,339 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:46:09,504 INFO     Weight matrix 8/9 (512,512): Alpha: 2.6617349352396453, Alpha Weighted: -0.8816255593282073, D: 0.12208522817618422\n",
      "2018-11-26 16:46:09,507 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.6546915769577026\n",
      "2018-11-26 16:46:09,510 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:46:16,582 INFO     Weight matrix 9/9 (512,512): Alpha: 3.285669338592831, Alpha Weighted: -0.6937854025589778, D: 0.07387939339647198\n",
      "2018-11-26 16:46:16,586 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.6379215717315674\n",
      "2018-11-26 16:46:16,588 INFO Layer 17: <keras.layers.convolutional.Conv2D object at 0xb34798358>\n",
      "2018-11-26 16:46:16,610 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:46:16,615 INFO Layer 17: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:46:16,618 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:46:23,765 INFO     Weight matrix 1/9 (512,512): Alpha: 3.1422218843693117, Alpha Weighted: -0.26782847521566955, D: 0.054497916224028664\n",
      "2018-11-26 16:46:23,768 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.6483020782470703\n",
      "2018-11-26 16:46:23,773 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:46:31,225 INFO     Weight matrix 2/9 (512,512): Alpha: 3.430055256241677, Alpha Weighted: -0.06702944110436285, D: 0.06414077335692847\n",
      "2018-11-26 16:46:31,229 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.6716188788414001\n",
      "2018-11-26 16:46:31,232 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:46:38,378 INFO     Weight matrix 3/9 (512,512): Alpha: 3.2457943392582753, Alpha Weighted: -0.3294655519356853, D: 0.04778948976420455\n",
      "2018-11-26 16:46:38,382 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.6487486958503723\n",
      "2018-11-26 16:46:38,385 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:46:45,866 INFO     Weight matrix 4/9 (512,512): Alpha: 4.090218600220149, Alpha Weighted: -0.14575234225507097, D: 0.06250000000000178\n",
      "2018-11-26 16:46:45,869 INFO     Weight matrix 4/9 (512,512): Alpha 4.090218600220149 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:46:45,872 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.6313163042068481\n",
      "2018-11-26 16:46:45,877 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:46:52,697 INFO     Weight matrix 5/9 (512,512): Alpha: 4.244437184023717, Alpha Weighted: 0.3232629084262457, D: 0.07149916085852515\n",
      "2018-11-26 16:46:52,700 INFO     Weight matrix 5/9 (512,512): Alpha 4.244437184023717 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:46:52,703 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.690161406993866\n",
      "2018-11-26 16:46:52,705 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:46:59,663 INFO     Weight matrix 6/9 (512,512): Alpha: 3.3948847694147344, Alpha Weighted: -0.1196376430238255, D: 0.06673600330827001\n",
      "2018-11-26 16:46:59,667 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.6324495077133179\n",
      "2018-11-26 16:46:59,669 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:47:06,519 INFO     Weight matrix 7/9 (512,512): Alpha: 2.9551832553831865, Alpha Weighted: -0.3688356595898972, D: 0.06453998253175769\n",
      "2018-11-26 16:47:06,522 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.6435777544975281\n",
      "2018-11-26 16:47:06,525 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:47:13,702 INFO     Weight matrix 8/9 (512,512): Alpha: 3.171797236441771, Alpha Weighted: -0.21275032946768244, D: 0.05726160795812674\n",
      "2018-11-26 16:47:13,705 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.6643065214157104\n",
      "2018-11-26 16:47:13,709 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:47:21,095 INFO     Weight matrix 9/9 (512,512): Alpha: 3.5624738657676778, Alpha Weighted: -0.5086922953442536, D: 0.06397800626980299\n",
      "2018-11-26 16:47:21,097 INFO     Weight matrix 9/9 (512,512): Alpha 3.5624738657676778 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:47:21,104 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.6426410675048828\n",
      "2018-11-26 16:47:21,110 INFO Layer 18: <keras.layers.convolutional.Conv2D object at 0xb347b8748>\n",
      "2018-11-26 16:47:21,131 INFO Keras tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 16:47:21,134 INFO Layer 18: Analyzing 9 weight matrices...\n",
      "2018-11-26 16:47:21,137 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:47:28,398 INFO     Weight matrix 1/9 (512,512): Alpha: 4.055430941942035, Alpha Weighted: 0.36830066974963666, D: 0.030749984418757093\n",
      "2018-11-26 16:47:28,401 INFO     Weight matrix 1/9 (512,512): Alpha 4.055430941942035 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:47:28,404 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.6312968730926514\n",
      "2018-11-26 16:47:28,407 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:47:35,284 INFO     Weight matrix 2/9 (512,512): Alpha: 4.036542645986655, Alpha Weighted: 0.7331067775402423, D: 0.03502801997613103\n",
      "2018-11-26 16:47:35,289 INFO     Weight matrix 2/9 (512,512): Alpha 4.036542645986655 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:47:35,292 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.6557008028030396\n",
      "2018-11-26 16:47:35,295 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:47:42,519 INFO     Weight matrix 3/9 (512,512): Alpha: 4.005847611174101, Alpha Weighted: 0.3402297208902219, D: 0.03455556537322474\n",
      "2018-11-26 16:47:42,522 INFO     Weight matrix 3/9 (512,512): Alpha 4.005847611174101 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:47:42,527 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.6303039193153381\n",
      "2018-11-26 16:47:42,529 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:47:49,788 INFO     Weight matrix 4/9 (512,512): Alpha: 3.929595157094424, Alpha Weighted: 0.5935545211398565, D: 0.03720632359496501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 16:47:49,790 INFO     Weight matrix 4/9 (512,512): Alpha 3.929595157094424 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:47:49,794 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.6299318671226501\n",
      "2018-11-26 16:47:49,800 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:47:57,194 INFO     Weight matrix 5/9 (512,512): Alpha: 3.7515811933607113, Alpha Weighted: 1.0023443168292188, D: 0.05735131740602434\n",
      "2018-11-26 16:47:57,196 INFO     Weight matrix 5/9 (512,512): Alpha 3.7515811933607113 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:47:57,200 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.6738649010658264\n",
      "2018-11-26 16:47:57,202 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:48:04,061 INFO     Weight matrix 6/9 (512,512): Alpha: 4.0071019441594, Alpha Weighted: 0.5714011530234173, D: 0.044626628044583894\n",
      "2018-11-26 16:48:04,063 INFO     Weight matrix 6/9 (512,512): Alpha 4.0071019441594 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:48:04,066 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.6266793012619019\n",
      "2018-11-26 16:48:04,072 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:48:10,936 INFO     Weight matrix 7/9 (512,512): Alpha: 4.017888287127517, Alpha Weighted: 0.3536369722412187, D: 0.04300860353596292\n",
      "2018-11-26 16:48:10,939 INFO     Weight matrix 7/9 (512,512): Alpha 4.017888287127517 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:48:10,943 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.6302400231361389\n",
      "2018-11-26 16:48:10,949 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:48:18,067 INFO     Weight matrix 8/9 (512,512): Alpha: 3.979190387863764, Alpha Weighted: 0.7160303427336009, D: 0.04162254433830115\n",
      "2018-11-26 16:48:18,070 INFO     Weight matrix 8/9 (512,512): Alpha 3.979190387863764 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:48:18,074 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.6563602089881897\n",
      "2018-11-26 16:48:18,077 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 16:48:25,006 INFO     Weight matrix 9/9 (512,512): Alpha: 3.859529112685292, Alpha Weighted: 0.5423957490895095, D: 0.055472034903126965\n",
      "2018-11-26 16:48:25,009 INFO     Weight matrix 9/9 (512,512): Alpha 3.859529112685292 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 16:48:25,012 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.6300156712532043\n",
      "2018-11-26 16:48:25,014 INFO Layer 19: <keras.layers.pooling.MaxPooling2D object at 0xb347df048>\n",
      "2018-11-26 16:48:25,018 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 16:48:25,021 INFO Layer 20: <keras.layers.core.Flatten object at 0xb347df978>\n",
      "2018-11-26 16:48:25,023 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 16:48:25,025 INFO Layer 21: <keras.layers.core.Dense object at 0xb347fa4a8>\n",
      "2018-11-26 16:48:26,054 INFO Layer 21: Analyzing 1 weight matrices...\n",
      "2018-11-26 16:48:26,056 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 17:00:37,663 INFO     Weight matrix 1/1 (4096,25088): Alpha: 2.1147462620694144, Alpha Weighted: 1.695871433035691, D: 0.025720071896209507\n",
      "2018-11-26 17:00:37,702 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.3697518110275269\n",
      "2018-11-26 17:00:37,724 INFO Layer 22: <keras.layers.core.Dense object at 0xb3481ccc0>\n",
      "2018-11-26 17:00:37,875 INFO Layer 22: Analyzing 1 weight matrices...\n",
      "2018-11-26 17:00:37,878 INFO     Weight matrix 1/1 (4096,4096): Analyzing ...\n",
      "2018-11-26 17:06:33,359 INFO     Weight matrix 1/1 (4096,4096): Alpha: 2.0334381252912888, Alpha Weighted: 1.8155002884591067, D: 0.03389595363478082\n",
      "2018-11-26 17:06:33,368 INFO     Weight matrix 1/1 (4096,4096): Lognorm: 1.2557973861694336\n",
      "2018-11-26 17:06:33,392 INFO Layer 23: <keras.layers.core.Dense object at 0xb3483f780>\n",
      "2018-11-26 17:06:33,434 INFO Layer 23: Analyzing 1 weight matrices...\n",
      "2018-11-26 17:06:33,438 INFO     Weight matrix 1/1 (1000,4096): Analyzing ...\n",
      "2018-11-26 17:07:00,580 INFO     Weight matrix 1/1 (1000,4096): Alpha: 3.030620668795173, Alpha Weighted: 2.8689031815207517, D: 0.03604809516649565\n",
      "2018-11-26 17:07:00,585 INFO     Weight matrix 1/1 (1000,4096): Lognorm: 1.224208950996399\n",
      "2018-11-26 17:07:00,605 INFO ### Printing results ###\n",
      "2018-11-26 17:07:00,608 DEBUG Layer 2: Lognorm compound: 0.43449219730165267\n",
      "2018-11-26 17:07:00,612 DEBUG Layer 4: Lognorm compound: 0.46344298124313354\n",
      "2018-11-26 17:07:00,616 DEBUG Layer 5: Lognorm compound: 0.4776083065403832\n",
      "2018-11-26 17:07:00,618 DEBUG Layer 7: Lognorm compound: 0.487847367922465\n",
      "2018-11-26 17:07:00,621 DEBUG Layer 8: Lognorm compound: 0.49566464953952366\n",
      "2018-11-26 17:07:00,624 DEBUG Layer 9: Lognorm compound: 0.5085808568530612\n",
      "2018-11-26 17:07:00,627 DEBUG Layer 11: Lognorm compound: 0.5586807264222039\n",
      "2018-11-26 17:07:00,629 DEBUG Layer 12: Lognorm compound: 0.5916056036949158\n",
      "2018-11-26 17:07:00,632 DEBUG Layer 13: Lognorm compound: 0.6114423407448663\n",
      "2018-11-26 17:07:00,635 DEBUG Layer 15: Lognorm compound: 0.6487328277693855\n",
      "2018-11-26 17:07:00,637 DEBUG Layer 16: Lognorm compound: 0.6525691350301107\n",
      "2018-11-26 17:07:00,640 DEBUG Layer 17: Lognorm compound: 0.6404881742265489\n",
      "2018-11-26 17:07:00,642 DEBUG Layer 20: Lognorm: 1.3697518110275269\n",
      "2018-11-26 17:07:00,645 DEBUG Layer 21: Lognorm: 1.2557973861694336\n",
      "2018-11-26 17:07:00,647 DEBUG Layer 22: Lognorm: 1.224208950996399\n",
      "2018-11-26 17:07:00,650 INFO LogNorm: min: 0.3889707922935486, max: 1.3697518110275269, avg: 0.5674788951873779\n",
      "2018-11-26 17:07:00,652 INFO LogNorm compound: min: 0.43449219730165267, max: 1.3697518110275269, avg: 0.6947275543654406\n",
      "2018-11-26 17:07:00,654 DEBUG Layer 2: Alpha compound: 1.2176341122821663\n",
      "2018-11-26 17:07:00,657 DEBUG Layer 4: Alpha compound: 1.373768007884709\n",
      "2018-11-26 17:07:00,659 DEBUG Layer 5: Alpha compound: 2.5955028005076786\n",
      "2018-11-26 17:07:00,662 DEBUG Layer 7: Alpha compound: 2.478848906551217\n",
      "2018-11-26 17:07:00,664 DEBUG Layer 8: Alpha compound: 2.5749516467606512\n",
      "2018-11-26 17:07:00,667 DEBUG Layer 9: Alpha compound: 2.8933769534332368\n",
      "2018-11-26 17:07:00,669 DEBUG Layer 11: Alpha compound: 3.007978394521642\n",
      "2018-11-26 17:07:00,673 DEBUG Layer 12: Alpha compound: 2.9173209569695384\n",
      "2018-11-26 17:07:00,675 DEBUG Layer 13: Alpha compound: 3.205354045415284\n",
      "2018-11-26 17:07:00,678 DEBUG Layer 15: Alpha compound: 3.040427649699293\n",
      "2018-11-26 17:07:00,680 DEBUG Layer 16: Alpha compound: 3.4707851545689445\n",
      "2018-11-26 17:07:00,682 DEBUG Layer 17: Alpha compound: 3.9603008090437664\n",
      "2018-11-26 17:07:00,685 DEBUG Layer 20: Alpha: 2.1147462620694144\n",
      "2018-11-26 17:07:00,690 DEBUG Layer 21: Alpha: 2.0334381252912888\n",
      "2018-11-26 17:07:00,693 DEBUG Layer 22: Alpha: 3.030620668795173\n",
      "2018-11-26 17:07:00,696 INFO Alpha: min: 1.2069767289907984, max: 4.558138051733277, avg: 2.718964414368459\n",
      "2018-11-26 17:07:00,699 INFO Alpha compound: min: 1.2176341122821663, max: 3.9603008090437664, avg: 2.6610036329196007\n",
      "2018-11-26 17:07:00,703 DEBUG Layer 2: Alpha Weighted compound: 0.3284432297078794\n",
      "2018-11-26 17:07:00,705 DEBUG Layer 4: Alpha Weighted compound: 0.22048371874551398\n",
      "2018-11-26 17:07:00,707 DEBUG Layer 5: Alpha Weighted compound: -0.01861693800845706\n",
      "2018-11-26 17:07:00,710 DEBUG Layer 7: Alpha Weighted compound: -0.4016409665140414\n",
      "2018-11-26 17:07:00,712 DEBUG Layer 8: Alpha Weighted compound: -0.5799544009296459\n",
      "2018-11-26 17:07:00,715 DEBUG Layer 9: Alpha Weighted compound: -0.6833873920627432\n",
      "2018-11-26 17:07:00,718 DEBUG Layer 11: Alpha Weighted compound: -0.6447187608016514\n",
      "2018-11-26 17:07:00,720 DEBUG Layer 12: Alpha Weighted compound: -0.50827798760899\n",
      "2018-11-26 17:07:00,723 DEBUG Layer 13: Alpha Weighted compound: -0.2603805566314235\n",
      "2018-11-26 17:07:00,726 DEBUG Layer 15: Alpha Weighted compound: -0.7291796173260308\n",
      "2018-11-26 17:07:00,729 DEBUG Layer 16: Alpha Weighted compound: -0.18852542550113352\n",
      "2018-11-26 17:07:00,731 DEBUG Layer 17: Alpha Weighted compound: 0.5801111359152136\n",
      "2018-11-26 17:07:00,734 DEBUG Layer 20: Alpha Weigthed: 1.695871433035691\n",
      "2018-11-26 17:07:00,736 DEBUG Layer 21: Alpha Weigthed: 1.8155002884591067\n",
      "2018-11-26 17:07:00,738 DEBUG Layer 22: Alpha Weigthed: 2.8689031815207517\n",
      "2018-11-26 17:07:00,741 INFO Alpha Weighted: min: -1.087618285865235, max: 2.8689031815207517, avg: -0.1764911778930094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 17:07:00,743 INFO Alpha Weighted compound: min: -0.7291796173260308, max: 2.8689031815207517, avg: 0.23297539613333593\n"
     ]
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "results = watcher.analyze(compute_alphas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. pyTorch Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T01:07:00.832588Z",
     "start_time": "2018-11-27T01:07:00.818992Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T01:56:40.672990Z",
     "start_time": "2018-11-27T01:32:19.498660Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 17:32:26,765 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 17:32:26,768 INFO Analyzing model\n",
      "2018-11-26 17:32:26,772 INFO Layer 1: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 17:32:26,777 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 17:32:26,782 INFO Layer 2: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace)\n",
      "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 17:32:26,785 INFO Layer 2: Skipping (Layer not supported)\n",
      "2018-11-26 17:32:26,787 INFO Layer 3: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:32:26,793 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:32:26,795 INFO Layer 3: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:32:26,798 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:32:26,806 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:32:26,808 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:32:26,810 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:32:26,814 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:32:26,817 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:32:26,820 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:32:26,823 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:32:26,825 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:32:26,828 INFO Layer 4: ReLU(inplace)\n",
      "2018-11-26 17:32:26,830 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 17:32:26,834 INFO Layer 5: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:32:26,839 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:32:26,841 INFO Layer 5: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:32:26,844 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:32:27,474 INFO     Weight matrix 1/9 (64,64): Alpha: 3.142422624589125, Alpha Weighted: 1.0356264827948563, D: 0.15201147360962397\n",
      "2018-11-26 17:32:27,477 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.5160806179046631\n",
      "2018-11-26 17:32:27,480 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:32:27,969 INFO     Weight matrix 2/9 (64,64): Alpha: 2.6926874054635874, Alpha Weighted: 1.4322326965670529, D: 0.1534784109075178\n",
      "2018-11-26 17:32:27,972 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.5779937505722046\n",
      "2018-11-26 17:32:27,975 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:32:28,427 INFO     Weight matrix 3/9 (64,64): Alpha: 1.7915681803151364, Alpha Weighted: 0.6032889084882009, D: 0.1834562240245426\n",
      "2018-11-26 17:32:28,430 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.5458888411521912\n",
      "2018-11-26 17:32:28,435 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:32:28,887 INFO     Weight matrix 4/9 (64,64): Alpha: 2.6447149023681438, Alpha Weighted: 1.3996292025787689, D: 0.13734371437252257\n",
      "2018-11-26 17:32:28,889 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.5552008152008057\n",
      "2018-11-26 17:32:28,892 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:32:29,412 INFO     Weight matrix 5/9 (64,64): Alpha: 2.8553866197707762, Alpha Weighted: 1.8627007634019093, D: 0.14285714285714324\n",
      "2018-11-26 17:32:29,415 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.6158302426338196\n",
      "2018-11-26 17:32:29,418 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:32:29,881 INFO     Weight matrix 6/9 (64,64): Alpha: 1.5722768658271273, Alpha Weighted: 0.7493920300952568, D: 0.15895596376900445\n",
      "2018-11-26 17:32:29,883 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.575312614440918\n",
      "2018-11-26 17:32:29,886 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:32:30,350 INFO     Weight matrix 7/9 (64,64): Alpha: 1.5593464674916802, Alpha Weighted: 0.3687302460809226, D: 0.17842349473647579\n",
      "2018-11-26 17:32:30,352 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.5055575966835022\n",
      "2018-11-26 17:32:30,355 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:32:30,845 INFO     Weight matrix 8/9 (64,64): Alpha: 2.3832925684368904, Alpha Weighted: 1.296885259312267, D: 0.1385260217761305\n",
      "2018-11-26 17:32:30,849 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.5518020987510681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 17:32:30,852 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:32:31,357 INFO     Weight matrix 9/9 (64,64): Alpha: 3.1091440125202143, Alpha Weighted: 0.8731617486323695, D: 0.17602399279348685\n",
      "2018-11-26 17:32:31,360 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.5120531916618347\n",
      "2018-11-26 17:32:31,362 INFO Layer 6: ReLU(inplace)\n",
      "2018-11-26 17:32:31,366 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 17:32:31,374 INFO Layer 7: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 17:32:31,378 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 17:32:31,381 INFO Layer 8: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:32:31,386 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:32:31,390 INFO Layer 8: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:32:31,395 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:32:31,892 INFO     Weight matrix 1/9 (64,128): Alpha: 1.7198477231421028, Alpha Weighted: 0.6326232372122542, D: 0.154902604293305\n",
      "2018-11-26 17:32:31,896 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.6252495050430298\n",
      "2018-11-26 17:32:31,899 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:32:32,362 INFO     Weight matrix 2/9 (64,128): Alpha: 1.6920180724926328, Alpha Weighted: 0.6797983621627005, D: 0.15375686234752517\n",
      "2018-11-26 17:32:32,367 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.6631074547767639\n",
      "2018-11-26 17:32:32,369 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:32:32,824 INFO     Weight matrix 3/9 (64,128): Alpha: 1.8732094995243895, Alpha Weighted: 0.706494638506219, D: 0.14726965575147122\n",
      "2018-11-26 17:32:32,827 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.6152138710021973\n",
      "2018-11-26 17:32:32,830 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:32:33,281 INFO     Weight matrix 4/9 (64,128): Alpha: 1.6454380004242601, Alpha Weighted: 0.8071385888861151, D: 0.1565297620922238\n",
      "2018-11-26 17:32:33,284 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.6701611280441284\n",
      "2018-11-26 17:32:33,287 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:32:33,743 INFO     Weight matrix 5/9 (64,128): Alpha: 1.6638427065256067, Alpha Weighted: 1.1859452734694642, D: 0.14086583702426608\n",
      "2018-11-26 17:32:33,746 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.7314475178718567\n",
      "2018-11-26 17:32:33,748 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:32:34,217 INFO     Weight matrix 6/9 (64,128): Alpha: 1.7355904518383798, Alpha Weighted: 0.7603759016040842, D: 0.14747526157127516\n",
      "2018-11-26 17:32:34,221 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.6492814421653748\n",
      "2018-11-26 17:32:34,224 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:32:34,686 INFO     Weight matrix 7/9 (64,128): Alpha: 1.9029354721563823, Alpha Weighted: 0.6787662569347408, D: 0.15153538903052177\n",
      "2018-11-26 17:32:34,691 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.6226702332496643\n",
      "2018-11-26 17:32:34,699 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:32:35,162 INFO     Weight matrix 8/9 (64,128): Alpha: 1.6830602152924485, Alpha Weighted: 0.8073421143819843, D: 0.15261492211878785\n",
      "2018-11-26 17:32:35,166 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.6656328439712524\n",
      "2018-11-26 17:32:35,170 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:32:35,665 INFO     Weight matrix 9/9 (64,128): Alpha: 1.8657863757867528, Alpha Weighted: 0.728350662964443, D: 0.1452661793912876\n",
      "2018-11-26 17:32:35,669 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.6046348810195923\n",
      "2018-11-26 17:32:35,671 INFO Layer 9: ReLU(inplace)\n",
      "2018-11-26 17:32:35,674 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 17:32:35,677 INFO Layer 10: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:32:35,682 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:32:35,685 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:32:35,687 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:32:36,725 INFO     Weight matrix 1/9 (128,128): Alpha: 1.9708087310767561, Alpha Weighted: 0.3627348820499047, D: 0.1533051789541121\n",
      "2018-11-26 17:32:36,728 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.6705517768859863\n",
      "2018-11-26 17:32:36,731 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:32:37,740 INFO     Weight matrix 2/9 (128,128): Alpha: 1.771790579992397, Alpha Weighted: 0.44331843099300766, D: 0.16173600512563208\n",
      "2018-11-26 17:32:37,744 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.707156240940094\n",
      "2018-11-26 17:32:37,748 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:32:38,741 INFO     Weight matrix 3/9 (128,128): Alpha: 1.9148813379867815, Alpha Weighted: 0.4394516766873766, D: 0.15214607900339866\n",
      "2018-11-26 17:32:38,745 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.6703708171844482\n",
      "2018-11-26 17:32:38,749 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:32:39,770 INFO     Weight matrix 4/9 (128,128): Alpha: 1.9932234483973792, Alpha Weighted: 0.5333418049744489, D: 0.16250371307627492\n",
      "2018-11-26 17:32:39,774 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.708335816860199\n",
      "2018-11-26 17:32:39,777 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:32:40,778 INFO     Weight matrix 5/9 (128,128): Alpha: 1.8607002357124875, Alpha Weighted: 0.6109738015544449, D: 0.18034601869099343\n",
      "2018-11-26 17:32:40,783 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.7527784705162048\n",
      "2018-11-26 17:32:40,786 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:32:41,810 INFO     Weight matrix 6/9 (128,128): Alpha: 1.9678267515713992, Alpha Weighted: 0.5040800078140927, D: 0.1560897772885056\n",
      "2018-11-26 17:32:41,813 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.6959487795829773\n",
      "2018-11-26 17:32:41,818 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:32:42,836 INFO     Weight matrix 7/9 (128,128): Alpha: 1.8584877197254208, Alpha Weighted: 0.3537002379603508, D: 0.16694163259821815\n",
      "2018-11-26 17:32:42,840 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.6658181548118591\n",
      "2018-11-26 17:32:42,843 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:32:43,866 INFO     Weight matrix 8/9 (128,128): Alpha: 1.950535876129496, Alpha Weighted: 0.5586787397014297, D: 0.1492966083512549\n",
      "2018-11-26 17:32:43,870 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.6898443102836609\n",
      "2018-11-26 17:32:43,872 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:32:44,894 INFO     Weight matrix 9/9 (128,128): Alpha: 1.8140198633768492, Alpha Weighted: 0.35767533193553785, D: 0.1445975545077023\n",
      "2018-11-26 17:32:44,899 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.6580457091331482\n",
      "2018-11-26 17:32:44,901 INFO Layer 11: ReLU(inplace)\n",
      "2018-11-26 17:32:44,903 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 17:32:44,906 INFO Layer 12: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 17:32:44,908 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 17:32:44,910 INFO Layer 13: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:32:44,921 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:32:44,923 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:32:44,926 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:32:45,948 INFO     Weight matrix 1/9 (128,256): Alpha: 2.980997546533984, Alpha Weighted: 0.5434271948919844, D: 0.13899253471883644\n",
      "2018-11-26 17:32:45,952 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.7062947750091553\n",
      "2018-11-26 17:32:45,954 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:32:46,960 INFO     Weight matrix 2/9 (128,256): Alpha: 3.6120507555843804, Alpha Weighted: 1.491393153933572, D: 0.14968121912236987\n",
      "2018-11-26 17:32:46,962 INFO     Weight matrix 2/9 (128,256): Alpha 3.6120507555843804 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:32:46,966 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.7732203006744385\n",
      "2018-11-26 17:32:46,972 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 17:32:48,017 INFO     Weight matrix 3/9 (128,256): Alpha: 2.773223980860115, Alpha Weighted: 0.5484073623242045, D: 0.12591375018658202\n",
      "2018-11-26 17:32:48,022 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.7141814231872559\n",
      "2018-11-26 17:32:48,024 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:32:49,025 INFO     Weight matrix 4/9 (128,256): Alpha: 3.4532214418482057, Alpha Weighted: 1.2880493197046632, D: 0.1537974151804365\n",
      "2018-11-26 17:32:49,031 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.7659935355186462\n",
      "2018-11-26 17:32:49,034 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:32:50,042 INFO     Weight matrix 5/9 (128,256): Alpha: 1.5250535090545694, Alpha Weighted: 0.8890992939029106, D: 0.15304425542819206\n",
      "2018-11-26 17:32:50,046 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.8792248964309692\n",
      "2018-11-26 17:32:50,050 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:32:51,091 INFO     Weight matrix 6/9 (128,256): Alpha: 1.7512999313915545, Alpha Weighted: 0.6956801963661614, D: 0.15087960449310134\n",
      "2018-11-26 17:32:51,095 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.7701500058174133\n",
      "2018-11-26 17:32:51,098 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:32:52,143 INFO     Weight matrix 7/9 (128,256): Alpha: 2.406611467877192, Alpha Weighted: 0.39244152559311724, D: 0.16482891553491757\n",
      "2018-11-26 17:32:52,146 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.7016052007675171\n",
      "2018-11-26 17:32:52,152 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:32:53,180 INFO     Weight matrix 8/9 (128,256): Alpha: 2.9214692080444844, Alpha Weighted: 1.0782930534023316, D: 0.1478455640629449\n",
      "2018-11-26 17:32:53,184 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.7585638165473938\n",
      "2018-11-26 17:32:53,189 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:32:54,244 INFO     Weight matrix 9/9 (128,256): Alpha: 2.8104434366811226, Alpha Weighted: 0.46751912819604763, D: 0.1446305880748452\n",
      "2018-11-26 17:32:54,248 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.7090867161750793\n",
      "2018-11-26 17:32:54,251 INFO Layer 14: ReLU(inplace)\n",
      "2018-11-26 17:32:54,254 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 17:32:54,257 INFO Layer 15: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:32:54,275 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:32:54,277 INFO Layer 15: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:32:54,280 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:32:56,757 INFO     Weight matrix 1/9 (256,256): Alpha: 3.1610547409054557, Alpha Weighted: 0.7746760442393343, D: 0.12169468325696764\n",
      "2018-11-26 17:32:56,762 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7806764245033264\n",
      "2018-11-26 17:32:56,765 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:32:59,283 INFO     Weight matrix 2/9 (256,256): Alpha: 2.170991823320292, Alpha Weighted: 0.7334356293221443, D: 0.11154511438662629\n",
      "2018-11-26 17:32:59,287 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.8059756755828857\n",
      "2018-11-26 17:32:59,289 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:01,867 INFO     Weight matrix 3/9 (256,256): Alpha: 2.257073441068872, Alpha Weighted: 0.44293941054821034, D: 0.1307043057071664\n",
      "2018-11-26 17:33:01,871 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.7829821705818176\n",
      "2018-11-26 17:33:01,874 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:04,364 INFO     Weight matrix 4/9 (256,256): Alpha: 2.5386169417966666, Alpha Weighted: 0.720960425973891, D: 0.12819916217808447\n",
      "2018-11-26 17:33:04,368 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.7989984750747681\n",
      "2018-11-26 17:33:04,371 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:06,842 INFO     Weight matrix 5/9 (256,256): Alpha: 1.7526517640884887, Alpha Weighted: 0.8924835625378258, D: 0.12736088420662117\n",
      "2018-11-26 17:33:06,847 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8561845421791077\n",
      "2018-11-26 17:33:06,850 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:09,358 INFO     Weight matrix 6/9 (256,256): Alpha: 3.326342635167146, Alpha Weighted: 1.0367021933184533, D: 0.11796503875528197\n",
      "2018-11-26 17:33:09,363 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.799529492855072\n",
      "2018-11-26 17:33:09,368 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:11,852 INFO     Weight matrix 7/9 (256,256): Alpha: 2.971281054225308, Alpha Weighted: 0.6230906637843997, D: 0.11973031610787849\n",
      "2018-11-26 17:33:11,856 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.7790930867195129\n",
      "2018-11-26 17:33:11,863 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:14,351 INFO     Weight matrix 8/9 (256,256): Alpha: 3.3636060440376245, Alpha Weighted: 1.0094460371147171, D: 0.11377352310797523\n",
      "2018-11-26 17:33:14,354 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7961214780807495\n",
      "2018-11-26 17:33:14,359 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:16,903 INFO     Weight matrix 9/9 (256,256): Alpha: 2.512983060411856, Alpha Weighted: 0.5481955083929518, D: 0.13451817112546982\n",
      "2018-11-26 17:33:16,907 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7766077518463135\n",
      "2018-11-26 17:33:16,910 INFO Layer 16: ReLU(inplace)\n",
      "2018-11-26 17:33:16,917 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 17:33:16,920 INFO Layer 17: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:33:16,943 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:33:16,946 INFO Layer 17: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:33:16,952 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:19,739 INFO     Weight matrix 1/9 (256,256): Alpha: 3.324629202913658, Alpha Weighted: 1.0493379152723756, D: 0.10513497292233537\n",
      "2018-11-26 17:33:19,743 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7941233515739441\n",
      "2018-11-26 17:33:19,747 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:22,275 INFO     Weight matrix 2/9 (256,256): Alpha: 2.553583721655549, Alpha Weighted: 1.0952654760815128, D: 0.09881861386088847\n",
      "2018-11-26 17:33:22,280 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.8185930848121643\n",
      "2018-11-26 17:33:22,285 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:24,817 INFO     Weight matrix 3/9 (256,256): Alpha: 3.1631154497668703, Alpha Weighted: 0.7856250321557615, D: 0.11637832556125666\n",
      "2018-11-26 17:33:24,821 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.7924150824546814\n",
      "2018-11-26 17:33:24,825 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:27,307 INFO     Weight matrix 4/9 (256,256): Alpha: 3.6272610123651083, Alpha Weighted: 1.4692685908226746, D: 0.07678727808310559\n",
      "2018-11-26 17:33:27,309 INFO     Weight matrix 4/9 (256,256): Alpha 3.6272610123651083 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:33:27,314 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.8125602006912231\n",
      "2018-11-26 17:33:27,317 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:29,800 INFO     Weight matrix 5/9 (256,256): Alpha: 3.557917175215558, Alpha Weighted: 2.1850252309560063, D: 0.09332130912051628\n",
      "2018-11-26 17:33:29,802 INFO     Weight matrix 5/9 (256,256): Alpha 3.557917175215558 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:33:29,806 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8733867406845093\n",
      "2018-11-26 17:33:29,812 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:32,325 INFO     Weight matrix 6/9 (256,256): Alpha: 3.380909272642594, Alpha Weighted: 1.3060732547874776, D: 0.09701463271719546\n",
      "2018-11-26 17:33:32,330 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.8054749369621277\n",
      "2018-11-26 17:33:32,333 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:34,803 INFO     Weight matrix 7/9 (256,256): Alpha: 2.5100763846878937, Alpha Weighted: 0.7078849411891285, D: 0.11533549488105344\n",
      "2018-11-26 17:33:34,808 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.7954062223434448\n",
      "2018-11-26 17:33:34,811 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 17:33:37,341 INFO     Weight matrix 8/9 (256,256): Alpha: 3.817706946103756, Alpha Weighted: 1.4716270949314345, D: 0.09791833617147094\n",
      "2018-11-26 17:33:37,344 INFO     Weight matrix 8/9 (256,256): Alpha 3.817706946103756 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:33:37,349 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.8186802864074707\n",
      "2018-11-26 17:33:37,353 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:33:39,849 INFO     Weight matrix 9/9 (256,256): Alpha: 3.600901106362161, Alpha Weighted: 0.9486591016669621, D: 0.09744259110076736\n",
      "2018-11-26 17:33:39,852 INFO     Weight matrix 9/9 (256,256): Alpha 3.600901106362161 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:33:39,858 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7906112670898438\n",
      "2018-11-26 17:33:39,861 INFO Layer 18: ReLU(inplace)\n",
      "2018-11-26 17:33:39,863 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 17:33:39,866 INFO Layer 19: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 17:33:39,868 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 17:33:39,871 INFO Layer 20: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:33:39,898 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:33:39,902 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:33:39,905 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:33:42,428 INFO     Weight matrix 1/9 (256,512): Alpha: 2.7172858924723293, Alpha Weighted: 0.9502842047837508, D: 0.11392934427299783\n",
      "2018-11-26 17:33:42,433 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.873299241065979\n",
      "2018-11-26 17:33:42,435 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:33:44,942 INFO     Weight matrix 2/9 (256,512): Alpha: 3.396348607440043, Alpha Weighted: 1.4291680089496752, D: 0.11273020795838296\n",
      "2018-11-26 17:33:44,948 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.8999274373054504\n",
      "2018-11-26 17:33:44,951 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:33:47,486 INFO     Weight matrix 3/9 (256,512): Alpha: 2.8379204815915084, Alpha Weighted: 0.9623304714241276, D: 0.10389358101067991\n",
      "2018-11-26 17:33:47,496 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.8732175230979919\n",
      "2018-11-26 17:33:47,499 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:33:50,025 INFO     Weight matrix 4/9 (256,512): Alpha: 3.103763042631277, Alpha Weighted: 1.4523455641934817, D: 0.08322523963989126\n",
      "2018-11-26 17:33:50,029 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.893368124961853\n",
      "2018-11-26 17:33:50,033 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:33:52,584 INFO     Weight matrix 5/9 (256,512): Alpha: 1.7970234387322581, Alpha Weighted: 1.1138169268882743, D: 0.12000329068080728\n",
      "2018-11-26 17:33:52,588 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.9529684782028198\n",
      "2018-11-26 17:33:52,590 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:33:55,107 INFO     Weight matrix 6/9 (256,512): Alpha: 2.9390042246586283, Alpha Weighted: 1.2124720103073794, D: 0.09788329470457019\n",
      "2018-11-26 17:33:55,112 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.8931679725646973\n",
      "2018-11-26 17:33:55,115 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:33:57,682 INFO     Weight matrix 7/9 (256,512): Alpha: 2.333041192891962, Alpha Weighted: 0.7612649332403806, D: 0.12725536434945328\n",
      "2018-11-26 17:33:57,686 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.8703255653381348\n",
      "2018-11-26 17:33:57,689 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:34:00,216 INFO     Weight matrix 8/9 (256,512): Alpha: 3.62428575866909, Alpha Weighted: 1.4318543029195625, D: 0.12512611707304333\n",
      "2018-11-26 17:34:00,219 INFO     Weight matrix 8/9 (256,512): Alpha 3.62428575866909 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:34:00,224 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.895790159702301\n",
      "2018-11-26 17:34:00,228 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:34:02,849 INFO     Weight matrix 9/9 (256,512): Alpha: 3.335725314037542, Alpha Weighted: 1.149952885896877, D: 0.10742990877526215\n",
      "2018-11-26 17:34:02,853 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.8725559115409851\n",
      "2018-11-26 17:34:02,856 INFO Layer 21: ReLU(inplace)\n",
      "2018-11-26 17:34:02,859 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 17:34:02,861 INFO Layer 22: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:34:02,903 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:34:02,907 INFO Layer 22: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:34:02,911 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:34:09,698 INFO     Weight matrix 1/9 (512,512): Alpha: 3.250245071144418, Alpha Weighted: 1.189708150903316, D: 0.07135065764887905\n",
      "2018-11-26 17:34:09,703 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9203029870986938\n",
      "2018-11-26 17:34:09,705 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:34:16,521 INFO     Weight matrix 2/9 (512,512): Alpha: 3.529780574829723, Alpha Weighted: 1.8115921104633579, D: 0.06025004003337475\n",
      "2018-11-26 17:34:16,523 INFO     Weight matrix 2/9 (512,512): Alpha 3.529780574829723 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:34:16,529 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9294671416282654\n",
      "2018-11-26 17:34:16,532 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:34:23,567 INFO     Weight matrix 3/9 (512,512): Alpha: 3.1805592236665037, Alpha Weighted: 1.2076594907588412, D: 0.0723539456097756\n",
      "2018-11-26 17:34:23,572 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.920695424079895\n",
      "2018-11-26 17:34:23,575 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:34:30,361 INFO     Weight matrix 4/9 (512,512): Alpha: 3.319810381126698, Alpha Weighted: 1.7117756447595058, D: 0.06750815455942055\n",
      "2018-11-26 17:34:30,366 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.915149450302124\n",
      "2018-11-26 17:34:30,369 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:34:37,201 INFO     Weight matrix 5/9 (512,512): Alpha: 3.8464768734135824, Alpha Weighted: 2.876767937643519, D: 0.0714285714285735\n",
      "2018-11-26 17:34:37,204 INFO     Weight matrix 5/9 (512,512): Alpha 3.8464768734135824 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:34:37,212 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9538557529449463\n",
      "2018-11-26 17:34:37,216 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:34:43,998 INFO     Weight matrix 6/9 (512,512): Alpha: 3.4603509765449227, Alpha Weighted: 1.8105246408689768, D: 0.05904679720288403\n",
      "2018-11-26 17:34:44,003 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9140542149543762\n",
      "2018-11-26 17:34:44,006 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:34:50,855 INFO     Weight matrix 7/9 (512,512): Alpha: 3.3066681754088125, Alpha Weighted: 1.2727633974741173, D: 0.06822600373390642\n",
      "2018-11-26 17:34:50,860 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9177790880203247\n",
      "2018-11-26 17:34:50,864 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:34:57,676 INFO     Weight matrix 8/9 (512,512): Alpha: 3.5722886080219634, Alpha Weighted: 1.8768584423986892, D: 0.06947915679821182\n",
      "2018-11-26 17:34:57,679 INFO     Weight matrix 8/9 (512,512): Alpha 3.5722886080219634 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:34:57,687 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9241966605186462\n",
      "2018-11-26 17:34:57,692 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:35:04,782 INFO     Weight matrix 9/9 (512,512): Alpha: 2.988022207618302, Alpha Weighted: 1.1182775362784796, D: 0.06670886402136422\n",
      "2018-11-26 17:35:04,787 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.915509819984436\n",
      "2018-11-26 17:35:04,790 INFO Layer 23: ReLU(inplace)\n",
      "2018-11-26 17:35:04,793 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 17:35:04,796 INFO Layer 24: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:35:04,828 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:35:04,830 INFO Layer 24: Analyzing 9 weight matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 17:35:04,833 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:35:11,632 INFO     Weight matrix 1/9 (512,512): Alpha: 3.5287044139287294, Alpha Weighted: 2.0182589600150704, D: 0.04011703821341425\n",
      "2018-11-26 17:35:11,634 INFO     Weight matrix 1/9 (512,512): Alpha 3.5287044139287294 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:35:11,640 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9187537431716919\n",
      "2018-11-26 17:35:11,643 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:35:18,450 INFO     Weight matrix 2/9 (512,512): Alpha: 3.692025286302128, Alpha Weighted: 2.557640749860396, D: 0.04769219815126036\n",
      "2018-11-26 17:35:18,452 INFO     Weight matrix 2/9 (512,512): Alpha 3.692025286302128 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:35:18,459 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9319085478782654\n",
      "2018-11-26 17:35:18,462 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:35:25,298 INFO     Weight matrix 3/9 (512,512): Alpha: 3.499151893802186, Alpha Weighted: 2.0556302689418167, D: 0.03990452146886769\n",
      "2018-11-26 17:35:25,303 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9165511131286621\n",
      "2018-11-26 17:35:25,307 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:35:32,141 INFO     Weight matrix 4/9 (512,512): Alpha: 3.121825869362268, Alpha Weighted: 2.10979736127296, D: 0.0507428428178312\n",
      "2018-11-26 17:35:32,146 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9146947860717773\n",
      "2018-11-26 17:35:32,151 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:35:38,931 INFO     Weight matrix 5/9 (512,512): Alpha: 2.3719264524502615, Alpha Weighted: 1.907103138635619, D: 0.0598537444931076\n",
      "2018-11-26 17:35:38,935 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9520865082740784\n",
      "2018-11-26 17:35:38,939 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:35:45,792 INFO     Weight matrix 6/9 (512,512): Alpha: 3.5493229993315274, Alpha Weighted: 2.4594784453195673, D: 0.04688908931335389\n",
      "2018-11-26 17:35:45,794 INFO     Weight matrix 6/9 (512,512): Alpha 3.5493229993315274 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:35:45,801 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9125211238861084\n",
      "2018-11-26 17:35:45,804 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:35:52,613 INFO     Weight matrix 7/9 (512,512): Alpha: 3.337986273502809, Alpha Weighted: 1.9842846322887124, D: 0.042908821420825805\n",
      "2018-11-26 17:35:52,618 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.914595901966095\n",
      "2018-11-26 17:35:52,620 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:35:59,443 INFO     Weight matrix 8/9 (512,512): Alpha: 3.629460004212453, Alpha Weighted: 2.58026405691285, D: 0.052631578947369806\n",
      "2018-11-26 17:35:59,445 INFO     Weight matrix 8/9 (512,512): Alpha 3.629460004212453 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:35:59,451 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9257221221923828\n",
      "2018-11-26 17:35:59,455 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:36:06,251 INFO     Weight matrix 9/9 (512,512): Alpha: 3.435621116039298, Alpha Weighted: 2.103574012509315, D: 0.029480683802517768\n",
      "2018-11-26 17:36:06,256 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9145614504814148\n",
      "2018-11-26 17:36:06,259 INFO Layer 25: ReLU(inplace)\n",
      "2018-11-26 17:36:06,262 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 17:36:06,264 INFO Layer 26: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 17:36:06,266 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 17:36:06,269 INFO Layer 27: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:36:06,292 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:36:06,295 INFO Layer 27: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:36:06,297 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:36:13,080 INFO     Weight matrix 1/9 (512,512): Alpha: 3.316594985454423, Alpha Weighted: 1.2485911983621987, D: 0.08371321836165746\n",
      "2018-11-26 17:36:13,085 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9477895498275757\n",
      "2018-11-26 17:36:13,087 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:36:19,888 INFO     Weight matrix 2/9 (512,512): Alpha: 3.7977715983614013, Alpha Weighted: 1.496501833067548, D: 0.08641305306074898\n",
      "2018-11-26 17:36:19,890 INFO     Weight matrix 2/9 (512,512): Alpha 3.7977715983614013 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:36:19,896 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9582177400588989\n",
      "2018-11-26 17:36:19,899 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:36:26,914 INFO     Weight matrix 3/9 (512,512): Alpha: 3.1990284075975994, Alpha Weighted: 1.1446363161618645, D: 0.07979717417547671\n",
      "2018-11-26 17:36:26,919 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9474737048149109\n",
      "2018-11-26 17:36:26,921 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:36:33,818 INFO     Weight matrix 4/9 (512,512): Alpha: 4.343342217752099, Alpha Weighted: 1.7075253279553941, D: 0.07389486727983291\n",
      "2018-11-26 17:36:33,820 INFO     Weight matrix 4/9 (512,512): Alpha 4.343342217752099 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:36:33,828 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9339495301246643\n",
      "2018-11-26 17:36:33,832 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:36:40,633 INFO     Weight matrix 5/9 (512,512): Alpha: 2.2667785996891308, Alpha Weighted: 1.1464997504354641, D: 0.09624265851061448\n",
      "2018-11-26 17:36:40,638 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9738436937332153\n",
      "2018-11-26 17:36:40,643 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:36:47,478 INFO     Weight matrix 6/9 (512,512): Alpha: 3.379163818094272, Alpha Weighted: 1.32988535761368, D: 0.08983239543049837\n",
      "2018-11-26 17:36:47,483 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9334749579429626\n",
      "2018-11-26 17:36:47,486 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:36:54,337 INFO     Weight matrix 7/9 (512,512): Alpha: 2.8322539753698823, Alpha Weighted: 0.904291161160067, D: 0.08331951012598582\n",
      "2018-11-26 17:36:54,342 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9431620240211487\n",
      "2018-11-26 17:36:54,346 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:37:01,209 INFO     Weight matrix 8/9 (512,512): Alpha: 3.214874622411441, Alpha Weighted: 1.169432714861909, D: 0.09671838341746514\n",
      "2018-11-26 17:37:01,213 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.950806736946106\n",
      "2018-11-26 17:37:01,216 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:37:07,992 INFO     Weight matrix 9/9 (512,512): Alpha: 3.400704425428475, Alpha Weighted: 1.0945895953378124, D: 0.08084405470716083\n",
      "2018-11-26 17:37:07,997 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9424883723258972\n",
      "2018-11-26 17:37:07,999 INFO Layer 28: ReLU(inplace)\n",
      "2018-11-26 17:37:08,002 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 17:37:08,006 INFO Layer 29: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:37:08,033 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:37:08,036 INFO Layer 29: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:37:08,039 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:37:14,832 INFO     Weight matrix 1/9 (512,512): Alpha: 3.3494769091008734, Alpha Weighted: 1.6690651601656044, D: 0.050793305493065766\n",
      "2018-11-26 17:37:14,837 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9396560192108154\n",
      "2018-11-26 17:37:14,842 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:37:21,656 INFO     Weight matrix 2/9 (512,512): Alpha: 3.960620092410946, Alpha Weighted: 2.2778503671939605, D: 0.05000000000000138\n",
      "2018-11-26 17:37:21,659 INFO     Weight matrix 2/9 (512,512): Alpha 3.960620092410946 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:37:21,665 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9501069188117981\n",
      "2018-11-26 17:37:21,668 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:37:28,525 INFO     Weight matrix 3/9 (512,512): Alpha: 3.4196100014206854, Alpha Weighted: 1.7690032175052282, D: 0.04570578908030011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 17:37:28,530 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9422363042831421\n",
      "2018-11-26 17:37:28,535 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:37:35,493 INFO     Weight matrix 4/9 (512,512): Alpha: 3.8988669596003187, Alpha Weighted: 2.2778483124542235, D: 0.04347826086956641\n",
      "2018-11-26 17:37:35,496 INFO     Weight matrix 4/9 (512,512): Alpha 3.8988669596003187 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:37:35,502 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9221203923225403\n",
      "2018-11-26 17:37:35,508 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:37:42,313 INFO     Weight matrix 5/9 (512,512): Alpha: 2.773514350014122, Alpha Weighted: 1.9024964144578858, D: 0.06381960848855017\n",
      "2018-11-26 17:37:42,319 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9579598307609558\n",
      "2018-11-26 17:37:42,321 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:37:49,133 INFO     Weight matrix 6/9 (512,512): Alpha: 3.744391658632949, Alpha Weighted: 2.2385583099909034, D: 0.04251359817089306\n",
      "2018-11-26 17:37:49,136 INFO     Weight matrix 6/9 (512,512): Alpha 3.744391658632949 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:37:49,145 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9227131605148315\n",
      "2018-11-26 17:37:49,149 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:37:56,019 INFO     Weight matrix 7/9 (512,512): Alpha: 3.494665713400551, Alpha Weighted: 1.6538979425643372, D: 0.05310517992012931\n",
      "2018-11-26 17:37:56,024 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9370439052581787\n",
      "2018-11-26 17:37:56,027 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:38:02,879 INFO     Weight matrix 8/9 (512,512): Alpha: 3.1023821149433988, Alpha Weighted: 1.7058702841248035, D: 0.07847222592625225\n",
      "2018-11-26 17:38:02,884 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9479745030403137\n",
      "2018-11-26 17:38:02,886 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:38:09,711 INFO     Weight matrix 9/9 (512,512): Alpha: 3.239654799251205, Alpha Weighted: 1.491280297575267, D: 0.06242817278179069\n",
      "2018-11-26 17:38:09,716 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9381680488586426\n",
      "2018-11-26 17:38:09,719 INFO Layer 30: ReLU(inplace)\n",
      "2018-11-26 17:38:09,723 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 17:38:09,726 INFO Layer 31: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:38:09,750 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:38:09,752 INFO Layer 31: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:38:09,755 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:38:16,540 INFO     Weight matrix 1/9 (512,512): Alpha: 3.9305867923916162, Alpha Weighted: 2.992400814625746, D: 0.04982654450210808\n",
      "2018-11-26 17:38:16,543 INFO     Weight matrix 1/9 (512,512): Alpha 3.9305867923916162 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:38:16,548 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9123738408088684\n",
      "2018-11-26 17:38:16,551 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:38:23,382 INFO     Weight matrix 2/9 (512,512): Alpha: 3.9506198576547527, Alpha Weighted: 3.0814772535849415, D: 0.05447700184102219\n",
      "2018-11-26 17:38:23,384 INFO     Weight matrix 2/9 (512,512): Alpha 3.9506198576547527 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:38:23,391 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9294504523277283\n",
      "2018-11-26 17:38:23,394 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:38:30,198 INFO     Weight matrix 3/9 (512,512): Alpha: 3.6595612401667084, Alpha Weighted: 2.668461772056765, D: 0.07018363422797055\n",
      "2018-11-26 17:38:30,200 INFO     Weight matrix 3/9 (512,512): Alpha 3.6595612401667084 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:38:30,207 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9104012250900269\n",
      "2018-11-26 17:38:30,211 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:38:37,052 INFO     Weight matrix 4/9 (512,512): Alpha: 3.9411686776363672, Alpha Weighted: 2.918724712082698, D: 0.04848009660623609\n",
      "2018-11-26 17:38:37,054 INFO     Weight matrix 4/9 (512,512): Alpha 3.9411686776363672 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:38:37,060 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9049561023712158\n",
      "2018-11-26 17:38:37,063 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:38:43,886 INFO     Weight matrix 5/9 (512,512): Alpha: 3.2437921242175234, Alpha Weighted: 2.4872550714687907, D: 0.0669658185648978\n",
      "2018-11-26 17:38:43,891 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9377350807189941\n",
      "2018-11-26 17:38:43,896 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:38:50,759 INFO     Weight matrix 6/9 (512,512): Alpha: 3.8216853619464652, Alpha Weighted: 2.7636244915242067, D: 0.05082872874960964\n",
      "2018-11-26 17:38:50,762 INFO     Weight matrix 6/9 (512,512): Alpha 3.8216853619464652 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:38:50,768 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9045703411102295\n",
      "2018-11-26 17:38:50,771 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:38:57,611 INFO     Weight matrix 7/9 (512,512): Alpha: 4.208599490742885, Alpha Weighted: 3.1651637175304868, D: 0.046799855837935556\n",
      "2018-11-26 17:38:57,614 INFO     Weight matrix 7/9 (512,512): Alpha 4.208599490742885 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:38:57,621 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9080918431282043\n",
      "2018-11-26 17:38:57,624 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:39:04,514 INFO     Weight matrix 8/9 (512,512): Alpha: 3.6948181768750485, Alpha Weighted: 2.853208585801675, D: 0.05813181908197518\n",
      "2018-11-26 17:39:04,516 INFO     Weight matrix 8/9 (512,512): Alpha 3.6948181768750485 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:39:04,523 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9252179265022278\n",
      "2018-11-26 17:39:04,527 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:39:11,385 INFO     Weight matrix 9/9 (512,512): Alpha: 4.126357267162975, Alpha Weighted: 2.959300379456264, D: 0.041870667080976975\n",
      "2018-11-26 17:39:11,387 INFO     Weight matrix 9/9 (512,512): Alpha 4.126357267162975 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:39:11,393 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9065619707107544\n",
      "2018-11-26 17:39:11,396 INFO Layer 32: ReLU(inplace)\n",
      "2018-11-26 17:39:11,400 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 17:39:11,402 INFO Layer 33: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 17:39:11,406 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 17:39:11,409 INFO Layer 34: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 17:39:11,412 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 17:39:11,415 INFO Layer 35: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 17:39:13,446 INFO Layer 35: Analyzing 1 weight matrices...\n",
      "2018-11-26 17:39:13,449 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 17:50:18,195 INFO     Weight matrix 1/1 (4096,25088): Alpha: 2.296433006183374, Alpha Weighted: 3.417221880890291, D: 0.027674865076783295\n",
      "2018-11-26 17:50:18,233 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.7093740701675415\n",
      "2018-11-26 17:50:18,326 INFO Layer 36: ReLU(inplace)\n",
      "2018-11-26 17:50:18,420 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 17:50:18,423 INFO Layer 37: Dropout(p=0.5)\n",
      "2018-11-26 17:50:18,429 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 17:50:18,435 INFO Layer 38: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 17:50:18,542 INFO Layer 38: Analyzing 1 weight matrices...\n",
      "2018-11-26 17:50:18,545 INFO     Weight matrix 1/1 (4096,4096): Analyzing ...\n",
      "2018-11-26 17:56:13,955 INFO     Weight matrix 1/1 (4096,4096): Alpha: 2.1836781246058194, Alpha Weighted: 3.7137963219178647, D: 0.032067886134730106\n",
      "2018-11-26 17:56:13,964 INFO     Weight matrix 1/1 (4096,4096): Lognorm: 1.613545298576355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 17:56:13,998 INFO Layer 39: ReLU(inplace)\n",
      "2018-11-26 17:56:14,021 INFO Layer 39: Skipping (Layer not supported)\n",
      "2018-11-26 17:56:14,024 INFO Layer 40: Dropout(p=0.5)\n",
      "2018-11-26 17:56:14,027 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 17:56:14,030 INFO Layer 41: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 17:56:14,060 INFO Layer 41: Analyzing 1 weight matrices...\n",
      "2018-11-26 17:56:14,063 INFO     Weight matrix 1/1 (1000,4096): Analyzing ...\n",
      "2018-11-26 17:56:40,416 INFO     Weight matrix 1/1 (1000,4096): Alpha: 2.0939370259491663, Alpha Weighted: 3.6317334350999113, D: 0.040029907913830154\n",
      "2018-11-26 17:56:40,421 INFO     Weight matrix 1/1 (1000,4096): Lognorm: 1.5725566148757935\n",
      "2018-11-26 17:56:40,448 INFO ### Printing results ###\n",
      "2018-11-26 17:56:40,451 DEBUG Layer 4: Lognorm compound: 0.5506355298890008\n",
      "2018-11-26 17:56:40,454 DEBUG Layer 7: Lognorm compound: 0.6497109863493178\n",
      "2018-11-26 17:56:40,457 DEBUG Layer 9: Lognorm compound: 0.690983341799842\n",
      "2018-11-26 17:56:40,460 DEBUG Layer 12: Lognorm compound: 0.7531467411253188\n",
      "2018-11-26 17:56:40,462 DEBUG Layer 14: Lognorm compound: 0.7973521219359504\n",
      "2018-11-26 17:56:40,469 DEBUG Layer 16: Lognorm compound: 0.8112501303354899\n",
      "2018-11-26 17:56:40,472 DEBUG Layer 19: Lognorm compound: 0.8916244904200236\n",
      "2018-11-26 17:56:40,475 DEBUG Layer 21: Lognorm compound: 0.9234456155035231\n",
      "2018-11-26 17:56:40,479 DEBUG Layer 23: Lognorm compound: 0.9223772552278307\n",
      "2018-11-26 17:56:40,482 DEBUG Layer 26: Lognorm compound: 0.9479118121994866\n",
      "2018-11-26 17:56:40,486 DEBUG Layer 28: Lognorm compound: 0.9397754536734687\n",
      "2018-11-26 17:56:40,489 DEBUG Layer 30: Lognorm compound: 0.9154843091964722\n",
      "2018-11-26 17:56:40,491 DEBUG Layer 34: Lognorm: 1.7093740701675415\n",
      "2018-11-26 17:56:40,494 DEBUG Layer 37: Lognorm: 1.613545298576355\n",
      "2018-11-26 17:56:40,496 DEBUG Layer 40: Lognorm: 1.5725566148757935\n",
      "2018-11-26 17:56:40,500 INFO LogNorm: min: 0.5055575966835022, max: 1.7093740701675415, avg: 0.8381869792938232\n",
      "2018-11-26 17:56:40,503 INFO LogNorm compound: min: 0.5506355298890008, max: 1.7093740701675415, avg: 0.979278251418361\n",
      "2018-11-26 17:56:40,506 DEBUG Layer 4: Alpha compound: 2.416759960753631\n",
      "2018-11-26 17:56:40,510 DEBUG Layer 7: Alpha compound: 1.753525390798106\n",
      "2018-11-26 17:56:40,512 DEBUG Layer 9: Alpha compound: 1.900252727107663\n",
      "2018-11-26 17:56:40,515 DEBUG Layer 12: Alpha compound: 2.692707919763956\n",
      "2018-11-26 17:56:40,518 DEBUG Layer 14: Alpha compound: 2.6727335005579675\n",
      "2018-11-26 17:56:40,522 DEBUG Layer 16: Alpha compound: 3.2817889190792386\n",
      "2018-11-26 17:56:40,524 DEBUG Layer 19: Alpha compound: 2.898266439236071\n",
      "2018-11-26 17:56:40,527 DEBUG Layer 21: Alpha compound: 3.383800232419437\n",
      "2018-11-26 17:56:40,530 DEBUG Layer 23: Alpha compound: 3.351780478770184\n",
      "2018-11-26 17:56:40,534 DEBUG Layer 26: Alpha compound: 3.305612516684303\n",
      "2018-11-26 17:56:40,539 DEBUG Layer 28: Alpha compound: 3.4425758443083385\n",
      "2018-11-26 17:56:40,541 DEBUG Layer 30: Alpha compound: 3.8419098876438156\n",
      "2018-11-26 17:56:40,547 DEBUG Layer 34: Alpha: 2.296433006183374\n",
      "2018-11-26 17:56:40,551 DEBUG Layer 37: Alpha: 2.1836781246058194\n",
      "2018-11-26 17:56:40,553 DEBUG Layer 40: Alpha: 2.0939370259491663\n",
      "2018-11-26 17:56:40,556 INFO Alpha: min: 1.5250535090545694, max: 4.343342217752099, avg: 2.8923375901877724\n",
      "2018-11-26 17:56:40,560 INFO Alpha compound: min: 1.753525390798106, max: 3.8419098876438156, avg: 2.767717464924071\n",
      "2018-11-26 17:56:40,564 DEBUG Layer 4: Alpha Weighted compound: 1.0690719264390671\n",
      "2018-11-26 17:56:40,567 DEBUG Layer 7: Alpha Weighted compound: 0.7763150040135561\n",
      "2018-11-26 17:56:40,570 DEBUG Layer 9: Alpha Weighted compound: 0.4626616570745104\n",
      "2018-11-26 17:56:40,573 DEBUG Layer 12: Alpha Weighted compound: 0.8215900253683326\n",
      "2018-11-26 17:56:40,575 DEBUG Layer 14: Alpha Weighted compound: 0.7535477194702142\n",
      "2018-11-26 17:56:40,579 DEBUG Layer 16: Alpha Weighted compound: 1.2243074042070372\n",
      "2018-11-26 17:56:40,584 DEBUG Layer 19: Alpha Weighted compound: 1.1626099231781675\n",
      "2018-11-26 17:56:40,586 DEBUG Layer 21: Alpha Weighted compound: 1.6528808168387557\n",
      "2018-11-26 17:56:40,589 DEBUG Layer 23: Alpha Weighted compound: 2.1973368473062567\n",
      "2018-11-26 17:56:40,592 DEBUG Layer 26: Alpha Weighted compound: 1.2491059172173264\n",
      "2018-11-26 17:56:40,598 DEBUG Layer 28: Alpha Weighted compound: 1.8873189228924678\n",
      "2018-11-26 17:56:40,601 DEBUG Layer 30: Alpha Weighted compound: 2.8766240886812855\n",
      "2018-11-26 17:56:40,605 DEBUG Layer 34: Alpha Weigthed: 3.417221880890291\n",
      "2018-11-26 17:56:40,607 DEBUG Layer 37: Alpha Weigthed: 3.7137963219178647\n",
      "2018-11-26 17:56:40,610 DEBUG Layer 40: Alpha Weigthed: 3.6317334350999113\n",
      "2018-11-26 17:56:40,613 INFO Alpha Weighted: min: 0.3537002379603508, max: 3.7137963219178647, avg: 1.4050728280368543\n",
      "2018-11-26 17:56:40,617 INFO Alpha Weighted compound: min: 0.4626616570745104, max: 3.7137963219178647, avg: 1.7930747927063362\n"
     ]
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "results = watcher.analyze(compute_alphas=True)\n",
    "\n",
    "data.append({\"name\": \"vgg16torch\", \"summary\": watcher.get_summary()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T02:20:23.737384Z",
     "start_time": "2018-11-27T01:56:40.687901Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 17:56:48,505 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 17:56:48,508 INFO Analyzing model\n",
      "2018-11-26 17:56:48,514 INFO Layer 1: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 17:56:48,517 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 17:56:48,521 INFO Layer 2: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace)\n",
      "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace)\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU(inplace)\n",
      "  (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU(inplace)\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (16): ReLU(inplace)\n",
      "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (19): ReLU(inplace)\n",
      "  (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (22): ReLU(inplace)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (26): ReLU(inplace)\n",
      "  (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (29): ReLU(inplace)\n",
      "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (32): ReLU(inplace)\n",
      "  (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (36): ReLU(inplace)\n",
      "  (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (39): ReLU(inplace)\n",
      "  (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (42): ReLU(inplace)\n",
      "  (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 17:56:48,525 INFO Layer 2: Skipping (Layer not supported)\n",
      "2018-11-26 17:56:48,528 INFO Layer 3: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:56:48,534 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:56:48,536 INFO Layer 3: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:56:48,539 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:56:48,542 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:56:48,545 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:56:48,549 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:56:48,553 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:56:48,557 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:56:48,559 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:56:48,563 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:56:48,568 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 17:56:48,571 INFO Layer 4: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 17:56:48,574 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 17:56:48,577 INFO Layer 5: ReLU(inplace)\n",
      "2018-11-26 17:56:48,579 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 17:56:48,582 INFO Layer 6: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:56:48,589 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 17:56:48,595 INFO Layer 6: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:56:48,602 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:56:49,151 INFO     Weight matrix 1/9 (64,64): Alpha: 3.067246042114857, Alpha Weighted: 0.08128032805170292, D: 0.16145711304065385\n",
      "2018-11-26 17:56:49,154 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.3020470440387726\n",
      "2018-11-26 17:56:49,157 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:56:49,665 INFO     Weight matrix 2/9 (64,64): Alpha: 2.487019328167813, Alpha Weighted: 0.7152870197005471, D: 0.1747309716215718\n",
      "2018-11-26 17:56:49,668 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.3800029456615448\n",
      "2018-11-26 17:56:49,671 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:56:50,137 INFO     Weight matrix 3/9 (64,64): Alpha: 3.209205464233937, Alpha Weighted: 0.4183594121167781, D: 0.216731296136003\n",
      "2018-11-26 17:56:50,139 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.3312205374240875\n",
      "2018-11-26 17:56:50,142 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:56:50,613 INFO     Weight matrix 4/9 (64,64): Alpha: 3.569984582151885, Alpha Weighted: 0.7476807885271962, D: 0.2000000000000005\n",
      "2018-11-26 17:56:50,615 INFO     Weight matrix 4/9 (64,64): Alpha 3.569984582151885 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:56:50,620 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.3538437783718109\n",
      "2018-11-26 17:56:50,624 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:56:51,070 INFO     Weight matrix 5/9 (64,64): Alpha: 2.3669408592474968, Alpha Weighted: 1.1595246665733747, D: 0.18520392153504528\n",
      "2018-11-26 17:56:51,073 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.457820862531662\n",
      "2018-11-26 17:56:51,076 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:56:51,547 INFO     Weight matrix 6/9 (64,64): Alpha: 1.6742878859009784, Alpha Weighted: 0.477696715466196, D: 0.19945472040909074\n",
      "2018-11-26 17:56:51,550 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.37926769256591797\n",
      "2018-11-26 17:56:51,553 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:56:52,019 INFO     Weight matrix 7/9 (64,64): Alpha: 3.451343039404728, Alpha Weighted: -0.03604443294544874, D: 0.2000000000000005\n",
      "2018-11-26 17:56:52,022 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.28816333413124084\n",
      "2018-11-26 17:56:52,024 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:56:52,487 INFO     Weight matrix 8/9 (64,64): Alpha: 3.057496794551882, Alpha Weighted: 0.7702203080087046, D: 0.2000000000000005\n",
      "2018-11-26 17:56:52,493 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.35348039865493774\n",
      "2018-11-26 17:56:52,496 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 17:56:52,947 INFO     Weight matrix 9/9 (64,64): Alpha: 1.6693840579058814, Alpha Weighted: -9.317455544004709e-05, D: 0.22794544073491085\n",
      "2018-11-26 17:56:52,949 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.30707016587257385\n",
      "2018-11-26 17:56:52,952 INFO Layer 7: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 17:56:52,956 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 17:56:52,960 INFO Layer 8: ReLU(inplace)\n",
      "2018-11-26 17:56:52,965 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 17:56:52,968 INFO Layer 9: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 17:56:52,972 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 17:56:52,976 INFO Layer 10: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:56:52,982 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:56:52,985 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:56:52,988 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:56:53,482 INFO     Weight matrix 1/9 (64,128): Alpha: 1.6570815437526, Alpha Weighted: 0.7180292170262772, D: 0.13282842775433334\n",
      "2018-11-26 17:56:53,486 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.5191804766654968\n",
      "2018-11-26 17:56:53,490 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:56:53,975 INFO     Weight matrix 2/9 (64,128): Alpha: 1.650524668741735, Alpha Weighted: 0.7264309038787279, D: 0.14066529617951778\n",
      "2018-11-26 17:56:53,979 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.5679644346237183\n",
      "2018-11-26 17:56:53,981 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:56:54,456 INFO     Weight matrix 3/9 (64,128): Alpha: 1.6339926739048214, Alpha Weighted: 0.6516254929132805, D: 0.1426634616163974\n",
      "2018-11-26 17:56:54,459 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.5102850794792175\n",
      "2018-11-26 17:56:54,462 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:56:54,935 INFO     Weight matrix 4/9 (64,128): Alpha: 1.5416898601966809, Alpha Weighted: 0.5503489022365248, D: 0.1406639198236922\n",
      "2018-11-26 17:56:54,938 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.5551800727844238\n",
      "2018-11-26 17:56:54,942 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:56:55,393 INFO     Weight matrix 5/9 (64,128): Alpha: 1.6504219631527637, Alpha Weighted: 0.9037237023221661, D: 0.15082607895515537\n",
      "2018-11-26 17:56:55,398 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.6409451961517334\n",
      "2018-11-26 17:56:55,401 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:56:55,876 INFO     Weight matrix 6/9 (64,128): Alpha: 1.6502861409549583, Alpha Weighted: 0.7007279800386546, D: 0.13379044762881986\n",
      "2018-11-26 17:56:55,879 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.5546641945838928\n",
      "2018-11-26 17:56:55,884 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:56:56,346 INFO     Weight matrix 7/9 (64,128): Alpha: 2.0074288220498815, Alpha Weighted: 0.7569141042227409, D: 0.13481680465573376\n",
      "2018-11-26 17:56:56,351 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.5064899325370789\n",
      "2018-11-26 17:56:56,353 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:56:56,820 INFO     Weight matrix 8/9 (64,128): Alpha: 1.5606137536171267, Alpha Weighted: 0.6558398815099636, D: 0.1382113726962113\n",
      "2018-11-26 17:56:56,825 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.5696483850479126\n",
      "2018-11-26 17:56:56,829 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 17:56:57,297 INFO     Weight matrix 9/9 (64,128): Alpha: 1.631992782801147, Alpha Weighted: 0.7257330900887972, D: 0.12051402892114732\n",
      "2018-11-26 17:56:57,300 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.5200129151344299\n",
      "2018-11-26 17:56:57,304 INFO Layer 11: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 17:56:57,307 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 17:56:57,309 INFO Layer 12: ReLU(inplace)\n",
      "2018-11-26 17:56:57,311 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 17:56:57,314 INFO Layer 13: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:56:57,321 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:56:57,324 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:56:57,327 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:56:58,388 INFO     Weight matrix 1/9 (128,128): Alpha: 2.8200343174995615, Alpha Weighted: -0.14159613714904265, D: 0.1747607359950326\n",
      "2018-11-26 17:56:58,391 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.515646755695343\n",
      "2018-11-26 17:56:58,394 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:56:59,449 INFO     Weight matrix 2/9 (128,128): Alpha: 3.480179520181706, Alpha Weighted: 0.24791370342671656, D: 0.18667768512429572\n",
      "2018-11-26 17:56:59,453 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.5774545669555664\n",
      "2018-11-26 17:56:59,456 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:57:00,558 INFO     Weight matrix 3/9 (128,128): Alpha: 2.472455377842222, Alpha Weighted: -0.1008075824026836, D: 0.15535180907618745\n",
      "2018-11-26 17:57:00,562 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.5236763954162598\n",
      "2018-11-26 17:57:00,567 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:57:01,653 INFO     Weight matrix 4/9 (128,128): Alpha: 3.025870917962053, Alpha Weighted: 0.2934039794621025, D: 0.1427496861970553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 17:57:01,658 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.5768951177597046\n",
      "2018-11-26 17:57:01,664 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:57:02,707 INFO     Weight matrix 5/9 (128,128): Alpha: 2.5531063639022538, Alpha Weighted: 0.5312905689512801, D: 0.1866319588834774\n",
      "2018-11-26 17:57:02,712 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.6633272767066956\n",
      "2018-11-26 17:57:02,716 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:57:03,759 INFO     Weight matrix 6/9 (128,128): Alpha: 2.9347511255896004, Alpha Weighted: 0.2728914972548323, D: 0.17412482270150087\n",
      "2018-11-26 17:57:03,766 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.5866610407829285\n",
      "2018-11-26 17:57:03,771 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:57:04,807 INFO     Weight matrix 7/9 (128,128): Alpha: 3.0368064390563916, Alpha Weighted: -0.03731662954558613, D: 0.17720243041572364\n",
      "2018-11-26 17:57:04,810 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.5274824500083923\n",
      "2018-11-26 17:57:04,817 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:57:05,850 INFO     Weight matrix 8/9 (128,128): Alpha: 1.8448496342726686, Alpha Weighted: 0.13346930944544755, D: 0.18721042418969347\n",
      "2018-11-26 17:57:05,854 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.5817798972129822\n",
      "2018-11-26 17:57:05,856 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 17:57:06,893 INFO     Weight matrix 9/9 (128,128): Alpha: 4.452908689662523, Alpha Weighted: 0.05057070156187614, D: 0.13292287650566703\n",
      "2018-11-26 17:57:06,895 INFO     Weight matrix 9/9 (128,128): Alpha 4.452908689662523 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:57:06,899 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.5293200016021729\n",
      "2018-11-26 17:57:06,904 INFO Layer 14: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 17:57:06,907 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 17:57:06,909 INFO Layer 15: ReLU(inplace)\n",
      "2018-11-26 17:57:06,912 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 17:57:06,914 INFO Layer 16: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 17:57:06,919 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 17:57:06,921 INFO Layer 17: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:57:06,932 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:57:06,935 INFO Layer 17: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:57:06,938 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:57:08,006 INFO     Weight matrix 1/9 (128,256): Alpha: 2.9493918786184037, Alpha Weighted: 0.2692261554931024, D: 0.1409193343017755\n",
      "2018-11-26 17:57:08,011 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.621558427810669\n",
      "2018-11-26 17:57:08,013 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:57:09,078 INFO     Weight matrix 2/9 (128,256): Alpha: 1.773718504207585, Alpha Weighted: 0.3463540156658837, D: 0.17773781800974925\n",
      "2018-11-26 17:57:09,082 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.681553304195404\n",
      "2018-11-26 17:57:09,085 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:57:10,147 INFO     Weight matrix 3/9 (128,256): Alpha: 2.130429007778414, Alpha Weighted: 0.18684154863991828, D: 0.16321053452307932\n",
      "2018-11-26 17:57:10,150 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.618149995803833\n",
      "2018-11-26 17:57:10,154 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:57:11,219 INFO     Weight matrix 4/9 (128,256): Alpha: 3.457186013821321, Alpha Weighted: 0.667588768311356, D: 0.15311777254863923\n",
      "2018-11-26 17:57:11,223 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.679372251033783\n",
      "2018-11-26 17:57:11,226 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:57:12,273 INFO     Weight matrix 5/9 (128,256): Alpha: 2.932223775602317, Alpha Weighted: 1.2654459886069689, D: 0.15869351132659926\n",
      "2018-11-26 17:57:12,280 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.7932197451591492\n",
      "2018-11-26 17:57:12,283 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:57:13,366 INFO     Weight matrix 6/9 (128,256): Alpha: 3.153117730982223, Alpha Weighted: 0.7266894638484406, D: 0.15079086251847074\n",
      "2018-11-26 17:57:13,370 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.6813148260116577\n",
      "2018-11-26 17:57:13,373 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:57:14,458 INFO     Weight matrix 7/9 (128,256): Alpha: 3.21546311694809, Alpha Weighted: 0.2274303554637589, D: 0.148474108260635\n",
      "2018-11-26 17:57:14,463 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.6089982390403748\n",
      "2018-11-26 17:57:14,465 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:57:15,541 INFO     Weight matrix 8/9 (128,256): Alpha: 3.107690903116211, Alpha Weighted: 0.7722381879546718, D: 0.1519495317159218\n",
      "2018-11-26 17:57:15,544 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.6769558191299438\n",
      "2018-11-26 17:57:15,547 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 17:57:16,596 INFO     Weight matrix 9/9 (128,256): Alpha: 3.216832021151838, Alpha Weighted: 0.40418589525868215, D: 0.12119178947542164\n",
      "2018-11-26 17:57:16,603 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.6168607473373413\n",
      "2018-11-26 17:57:16,607 INFO Layer 18: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 17:57:16,610 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 17:57:16,612 INFO Layer 19: ReLU(inplace)\n",
      "2018-11-26 17:57:16,616 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 17:57:16,619 INFO Layer 20: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:57:16,633 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:57:16,636 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:57:16,640 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:19,211 INFO     Weight matrix 1/9 (256,256): Alpha: 2.14720973114321, Alpha Weighted: 0.03712016462707825, D: 0.13660292187858386\n",
      "2018-11-26 17:57:19,216 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.6896229386329651\n",
      "2018-11-26 17:57:19,220 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:21,777 INFO     Weight matrix 2/9 (256,256): Alpha: 2.830266614264951, Alpha Weighted: 0.3383744340643511, D: 0.11647464149816622\n",
      "2018-11-26 17:57:21,780 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7224852442741394\n",
      "2018-11-26 17:57:21,783 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:24,355 INFO     Weight matrix 3/9 (256,256): Alpha: 2.690419818470598, Alpha Weighted: 0.0036342226466584016, D: 0.1341964741913101\n",
      "2018-11-26 17:57:24,360 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.689423143863678\n",
      "2018-11-26 17:57:24,366 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:26,924 INFO     Weight matrix 4/9 (256,256): Alpha: 2.313093736305263, Alpha Weighted: 0.3948951106170237, D: 0.1265620980276636\n",
      "2018-11-26 17:57:26,929 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.724673330783844\n",
      "2018-11-26 17:57:26,932 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:29,508 INFO     Weight matrix 5/9 (256,256): Alpha: 2.7179380239175748, Alpha Weighted: 1.4220980082772603, D: 0.10259248313635605\n",
      "2018-11-26 17:57:29,512 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.7996470332145691\n",
      "2018-11-26 17:57:29,516 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:32,105 INFO     Weight matrix 6/9 (256,256): Alpha: 2.5088690505814117, Alpha Weighted: 0.3771235714045967, D: 0.1231615565511569\n",
      "2018-11-26 17:57:32,110 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7196282148361206\n",
      "2018-11-26 17:57:32,115 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:34,975 INFO     Weight matrix 7/9 (256,256): Alpha: 2.49336721405328, Alpha Weighted: -0.0306510020755945, D: 0.1287191766795055\n",
      "2018-11-26 17:57:34,980 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.6880820989608765\n",
      "2018-11-26 17:57:34,983 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:37,542 INFO     Weight matrix 8/9 (256,256): Alpha: 2.2733615650007213, Alpha Weighted: 0.29750053138161164, D: 0.13540365631252604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 17:57:37,546 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7206573486328125\n",
      "2018-11-26 17:57:37,550 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:40,174 INFO     Weight matrix 9/9 (256,256): Alpha: 2.620186784562488, Alpha Weighted: -0.02583837412378613, D: 0.13129343697231521\n",
      "2018-11-26 17:57:40,179 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6866093277931213\n",
      "2018-11-26 17:57:40,181 INFO Layer 21: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 17:57:40,184 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 17:57:40,186 INFO Layer 22: ReLU(inplace)\n",
      "2018-11-26 17:57:40,191 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 17:57:40,195 INFO Layer 23: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:57:40,204 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:57:40,208 INFO Layer 23: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:57:40,211 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:42,800 INFO     Weight matrix 1/9 (256,256): Alpha: 2.8934244639732496, Alpha Weighted: 0.156112668665939, D: 0.1147668845607982\n",
      "2018-11-26 17:57:42,804 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7132302522659302\n",
      "2018-11-26 17:57:42,807 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:45,404 INFO     Weight matrix 2/9 (256,256): Alpha: 3.085923036379448, Alpha Weighted: 0.41249216624522533, D: 0.1328224936301456\n",
      "2018-11-26 17:57:45,408 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7523155808448792\n",
      "2018-11-26 17:57:45,413 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:48,004 INFO     Weight matrix 3/9 (256,256): Alpha: 2.9376578124258463, Alpha Weighted: 0.16314737862657924, D: 0.11812142335195264\n",
      "2018-11-26 17:57:48,008 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.713317334651947\n",
      "2018-11-26 17:57:48,012 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:50,635 INFO     Weight matrix 4/9 (256,256): Alpha: 2.9171232135917764, Alpha Weighted: 0.27537168192266614, D: 0.13221127667914812\n",
      "2018-11-26 17:57:50,639 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.74599289894104\n",
      "2018-11-26 17:57:50,646 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:53,209 INFO     Weight matrix 5/9 (256,256): Alpha: 4.579021559804192, Alpha Weighted: 1.6711741052027487, D: 0.1343512326699875\n",
      "2018-11-26 17:57:53,211 INFO     Weight matrix 5/9 (256,256): Alpha 4.579021559804192 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:57:53,218 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8240542411804199\n",
      "2018-11-26 17:57:53,221 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:55,802 INFO     Weight matrix 6/9 (256,256): Alpha: 2.493813340916816, Alpha Weighted: 0.37118927356823606, D: 0.12856092024617838\n",
      "2018-11-26 17:57:55,806 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7495875358581543\n",
      "2018-11-26 17:57:55,808 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:57:58,407 INFO     Weight matrix 7/9 (256,256): Alpha: 2.8328184260101286, Alpha Weighted: 0.04963803683239948, D: 0.1319641703701041\n",
      "2018-11-26 17:57:58,412 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.7099129557609558\n",
      "2018-11-26 17:57:58,415 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:58:01,015 INFO     Weight matrix 8/9 (256,256): Alpha: 3.1678926372577587, Alpha Weighted: 0.25123088403792765, D: 0.14974330900800775\n",
      "2018-11-26 17:58:01,020 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7456675171852112\n",
      "2018-11-26 17:58:01,025 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 17:58:03,651 INFO     Weight matrix 9/9 (256,256): Alpha: 2.6584012648714963, Alpha Weighted: 0.15033903822304445, D: 0.10004136801283514\n",
      "2018-11-26 17:58:03,656 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7092029452323914\n",
      "2018-11-26 17:58:03,659 INFO Layer 24: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 17:58:03,662 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 17:58:03,664 INFO Layer 25: ReLU(inplace)\n",
      "2018-11-26 17:58:03,666 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 17:58:03,670 INFO Layer 26: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 17:58:03,672 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 17:58:03,675 INFO Layer 27: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:58:03,706 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:58:03,709 INFO Layer 27: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:58:03,712 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:58:06,345 INFO     Weight matrix 1/9 (256,512): Alpha: 2.729421713507916, Alpha Weighted: 0.5437397805220295, D: 0.11244652634147356\n",
      "2018-11-26 17:58:06,350 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.8181129693984985\n",
      "2018-11-26 17:58:06,355 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:58:09,025 INFO     Weight matrix 2/9 (256,512): Alpha: 3.5810054594437277, Alpha Weighted: 0.9061119576011187, D: 0.1268262206902614\n",
      "2018-11-26 17:58:09,028 INFO     Weight matrix 2/9 (256,512): Alpha 3.5810054594437277 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:58:09,034 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.8462375998497009\n",
      "2018-11-26 17:58:09,037 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:58:11,647 INFO     Weight matrix 3/9 (256,512): Alpha: 2.6295552925456036, Alpha Weighted: 0.5023896467824799, D: 0.10358085872439232\n",
      "2018-11-26 17:58:11,652 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.8175792098045349\n",
      "2018-11-26 17:58:11,655 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:58:14,271 INFO     Weight matrix 4/9 (256,512): Alpha: 2.9705310507500062, Alpha Weighted: 0.8891787860223332, D: 0.11521410738042104\n",
      "2018-11-26 17:58:14,276 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.8492370843887329\n",
      "2018-11-26 17:58:14,279 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:58:16,968 INFO     Weight matrix 5/9 (256,512): Alpha: 3.715436189373441, Alpha Weighted: 1.3837737708146771, D: 0.15296704869891076\n",
      "2018-11-26 17:58:16,970 INFO     Weight matrix 5/9 (256,512): Alpha 3.715436189373441 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 17:58:16,978 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.920875608921051\n",
      "2018-11-26 17:58:16,984 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:58:19,630 INFO     Weight matrix 6/9 (256,512): Alpha: 2.875923341913267, Alpha Weighted: 0.8820268934183951, D: 0.11646472242269251\n",
      "2018-11-26 17:58:19,635 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.8457630276679993\n",
      "2018-11-26 17:58:19,638 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:58:22,317 INFO     Weight matrix 7/9 (256,512): Alpha: 2.991136061282754, Alpha Weighted: 0.5633856681775207, D: 0.10495291974896725\n",
      "2018-11-26 17:58:22,322 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.8130205869674683\n",
      "2018-11-26 17:58:22,326 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:58:24,936 INFO     Weight matrix 8/9 (256,512): Alpha: 2.409543418343933, Alpha Weighted: 0.600023700877802, D: 0.13512513334222342\n",
      "2018-11-26 17:58:24,941 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.8386633992195129\n",
      "2018-11-26 17:58:24,944 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 17:58:27,608 INFO     Weight matrix 9/9 (256,512): Alpha: 2.8159580854543, Alpha Weighted: 0.5228267363405303, D: 0.10759159711652161\n",
      "2018-11-26 17:58:27,613 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.8117393851280212\n",
      "2018-11-26 17:58:27,616 INFO Layer 28: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 17:58:27,618 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 17:58:27,621 INFO Layer 29: ReLU(inplace)\n",
      "2018-11-26 17:58:27,624 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 17:58:27,627 INFO Layer 30: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:58:27,681 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 17:58:27,684 INFO Layer 30: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:58:27,687 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:58:34,828 INFO     Weight matrix 1/9 (512,512): Alpha: 3.077831035654155, Alpha Weighted: 0.9374729371920627, D: 0.05623929781046899\n",
      "2018-11-26 17:58:34,835 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.8901210427284241\n",
      "2018-11-26 17:58:34,838 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:58:41,852 INFO     Weight matrix 2/9 (512,512): Alpha: 3.33477321167447, Alpha Weighted: 1.119456948669348, D: 0.07104214769293726\n",
      "2018-11-26 17:58:41,858 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9025092124938965\n",
      "2018-11-26 17:58:41,861 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:58:48,846 INFO     Weight matrix 3/9 (512,512): Alpha: 3.094363590748016, Alpha Weighted: 0.9549168493807979, D: 0.056787296747913496\n",
      "2018-11-26 17:58:48,850 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.8893307447433472\n",
      "2018-11-26 17:58:48,853 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:58:55,908 INFO     Weight matrix 4/9 (512,512): Alpha: 2.9625658375392625, Alpha Weighted: 1.0366808287786982, D: 0.0665170104887336\n",
      "2018-11-26 17:58:55,915 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8892399668693542\n",
      "2018-11-26 17:58:55,918 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:59:03,086 INFO     Weight matrix 5/9 (512,512): Alpha: 3.1150293515095764, Alpha Weighted: 1.9423904705674795, D: 0.07524908668737024\n",
      "2018-11-26 17:59:03,092 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9473748207092285\n",
      "2018-11-26 17:59:03,096 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:59:10,126 INFO     Weight matrix 6/9 (512,512): Alpha: 3.2342720692173708, Alpha Weighted: 1.1434930415991842, D: 0.07670127883657618\n",
      "2018-11-26 17:59:10,131 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8909873962402344\n",
      "2018-11-26 17:59:10,135 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:59:17,136 INFO     Weight matrix 7/9 (512,512): Alpha: 3.118191819897921, Alpha Weighted: 0.8321481089116436, D: 0.06556008853285433\n",
      "2018-11-26 17:59:17,141 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.8865201473236084\n",
      "2018-11-26 17:59:17,144 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:59:24,505 INFO     Weight matrix 8/9 (512,512): Alpha: 3.4440569044506653, Alpha Weighted: 1.0781970208879907, D: 0.07526415940773451\n",
      "2018-11-26 17:59:24,511 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.8996297121047974\n",
      "2018-11-26 17:59:24,514 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:59:32,753 INFO     Weight matrix 9/9 (512,512): Alpha: 3.0556299102817905, Alpha Weighted: 0.8536252226665051, D: 0.0681753260026744\n",
      "2018-11-26 17:59:32,758 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.8877934813499451\n",
      "2018-11-26 17:59:32,760 INFO Layer 31: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 17:59:32,763 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 17:59:32,765 INFO Layer 32: ReLU(inplace)\n",
      "2018-11-26 17:59:32,768 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 17:59:32,771 INFO Layer 33: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 17:59:32,804 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 17:59:32,806 INFO Layer 33: Analyzing 9 weight matrices...\n",
      "2018-11-26 17:59:32,809 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:59:39,762 INFO     Weight matrix 1/9 (512,512): Alpha: 3.315558579353047, Alpha Weighted: 1.7081766331803239, D: 0.03634725290968177\n",
      "2018-11-26 17:59:39,769 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.898830771446228\n",
      "2018-11-26 17:59:39,773 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:59:46,582 INFO     Weight matrix 2/9 (512,512): Alpha: 3.376202520385569, Alpha Weighted: 1.893972102138042, D: 0.0631108283105617\n",
      "2018-11-26 17:59:46,587 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9196177124977112\n",
      "2018-11-26 17:59:46,589 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 17:59:53,430 INFO     Weight matrix 3/9 (512,512): Alpha: 3.2514129066145836, Alpha Weighted: 1.6440627364766043, D: 0.03246287090468064\n",
      "2018-11-26 17:59:53,435 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.8968573808670044\n",
      "2018-11-26 17:59:53,437 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:00:00,276 INFO     Weight matrix 4/9 (512,512): Alpha: 3.3207382877653213, Alpha Weighted: 1.7068889669435001, D: 0.027587067042470603\n",
      "2018-11-26 18:00:00,281 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8948185443878174\n",
      "2018-11-26 18:00:00,286 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:00:07,038 INFO     Weight matrix 5/9 (512,512): Alpha: 3.561594507596153, Alpha Weighted: 2.3882471120207995, D: 0.06809443075594857\n",
      "2018-11-26 18:00:07,041 INFO     Weight matrix 5/9 (512,512): Alpha 3.561594507596153 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:00:07,046 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9519852995872498\n",
      "2018-11-26 18:00:07,049 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:00:13,849 INFO     Weight matrix 6/9 (512,512): Alpha: 3.463187199922885, Alpha Weighted: 1.7468849320510984, D: 0.04305791120345215\n",
      "2018-11-26 18:00:13,854 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8938843011856079\n",
      "2018-11-26 18:00:13,856 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:00:20,669 INFO     Weight matrix 7/9 (512,512): Alpha: 3.2013802590948517, Alpha Weighted: 1.5912207339070699, D: 0.03612844823911243\n",
      "2018-11-26 18:00:20,674 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.8940696120262146\n",
      "2018-11-26 18:00:20,677 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:00:27,443 INFO     Weight matrix 8/9 (512,512): Alpha: 3.394784833362624, Alpha Weighted: 1.7613613426133374, D: 0.05680129364527253\n",
      "2018-11-26 18:00:27,448 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9118329882621765\n",
      "2018-11-26 18:00:27,452 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:00:34,287 INFO     Weight matrix 9/9 (512,512): Alpha: 3.345067760287057, Alpha Weighted: 1.6299849546930736, D: 0.03297138894963775\n",
      "2018-11-26 18:00:34,292 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.8938714265823364\n",
      "2018-11-26 18:00:34,294 INFO Layer 34: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 18:00:34,297 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 18:00:34,299 INFO Layer 35: ReLU(inplace)\n",
      "2018-11-26 18:00:34,302 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 18:00:34,304 INFO Layer 36: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 18:00:34,308 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 18:00:34,311 INFO Layer 37: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:00:34,335 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:00:34,338 INFO Layer 37: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:00:34,341 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:00:41,111 INFO     Weight matrix 1/9 (512,512): Alpha: 3.4673265326687495, Alpha Weighted: 1.264190260097568, D: 0.06301081081600801\n",
      "2018-11-26 18:00:41,117 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9238779544830322\n",
      "2018-11-26 18:00:41,120 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:00:47,925 INFO     Weight matrix 2/9 (512,512): Alpha: 4.3177449585537655, Alpha Weighted: 0.9930956418322258, D: 0.1040115052385065\n",
      "2018-11-26 18:00:47,927 INFO     Weight matrix 2/9 (512,512): Alpha 4.3177449585537655 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:00:47,932 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9439283609390259\n",
      "2018-11-26 18:00:47,937 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:00:54,737 INFO     Weight matrix 3/9 (512,512): Alpha: 3.396454251722268, Alpha Weighted: 1.1695070068534266, D: 0.06710276103846502\n",
      "2018-11-26 18:00:54,742 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9234775900840759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 18:00:54,744 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:01:01,593 INFO     Weight matrix 4/9 (512,512): Alpha: 3.988708093945818, Alpha Weighted: 0.8576473226138809, D: 0.08491601618351419\n",
      "2018-11-26 18:01:01,596 INFO     Weight matrix 4/9 (512,512): Alpha 3.988708093945818 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:01:01,603 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9092395901679993\n",
      "2018-11-26 18:01:01,606 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:01:08,355 INFO     Weight matrix 5/9 (512,512): Alpha: 5.677348485791719, Alpha Weighted: 2.5110539653756843, D: 0.10000000000000286\n",
      "2018-11-26 18:01:08,358 INFO     Weight matrix 5/9 (512,512): Alpha 5.677348485791719 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:01:08,364 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9842214584350586\n",
      "2018-11-26 18:01:08,367 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:01:15,233 INFO     Weight matrix 6/9 (512,512): Alpha: 3.825659983378872, Alpha Weighted: 0.7683795130903741, D: 0.07187834711592411\n",
      "2018-11-26 18:01:15,235 INFO     Weight matrix 6/9 (512,512): Alpha 3.825659983378872 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:01:15,241 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9079837799072266\n",
      "2018-11-26 18:01:15,243 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:01:22,075 INFO     Weight matrix 7/9 (512,512): Alpha: 3.5254878651040746, Alpha Weighted: 1.0909118942649276, D: 0.0650024887787431\n",
      "2018-11-26 18:01:22,078 INFO     Weight matrix 7/9 (512,512): Alpha 3.5254878651040746 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:01:22,085 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9200848340988159\n",
      "2018-11-26 18:01:22,089 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:01:28,987 INFO     Weight matrix 8/9 (512,512): Alpha: 3.76665414555405, Alpha Weighted: 0.5759774169681872, D: 0.10605057716852306\n",
      "2018-11-26 18:01:28,990 INFO     Weight matrix 8/9 (512,512): Alpha 3.76665414555405 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:01:28,995 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9340345859527588\n",
      "2018-11-26 18:01:28,998 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:01:35,788 INFO     Weight matrix 9/9 (512,512): Alpha: 3.5168436915906245, Alpha Weighted: 1.110906666365429, D: 0.057275617395210254\n",
      "2018-11-26 18:01:35,790 INFO     Weight matrix 9/9 (512,512): Alpha 3.5168436915906245 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:01:35,796 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9187854528427124\n",
      "2018-11-26 18:01:35,799 INFO Layer 38: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 18:01:35,802 INFO Layer 38: Skipping (Layer not supported)\n",
      "2018-11-26 18:01:35,805 INFO Layer 39: ReLU(inplace)\n",
      "2018-11-26 18:01:35,807 INFO Layer 39: Skipping (Layer not supported)\n",
      "2018-11-26 18:01:35,809 INFO Layer 40: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:01:35,833 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:01:35,836 INFO Layer 40: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:01:35,839 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:01:42,652 INFO     Weight matrix 1/9 (512,512): Alpha: 3.432143322723026, Alpha Weighted: 2.308608428527423, D: 0.029890689253256997\n",
      "2018-11-26 18:01:42,658 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9184998869895935\n",
      "2018-11-26 18:01:42,660 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:01:49,445 INFO     Weight matrix 2/9 (512,512): Alpha: 3.7342031525784236, Alpha Weighted: 2.4437110311077417, D: 0.04336320977956698\n",
      "2018-11-26 18:01:49,450 INFO     Weight matrix 2/9 (512,512): Alpha 3.7342031525784236 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:01:49,454 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9365758895874023\n",
      "2018-11-26 18:01:49,457 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:01:56,263 INFO     Weight matrix 3/9 (512,512): Alpha: 3.3671441508313786, Alpha Weighted: 2.287165986648081, D: 0.03469721956934313\n",
      "2018-11-26 18:01:56,269 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9190678000450134\n",
      "2018-11-26 18:01:56,271 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:02:03,129 INFO     Weight matrix 4/9 (512,512): Alpha: 3.9145039808904745, Alpha Weighted: 2.4153235559838313, D: 0.03269282468772994\n",
      "2018-11-26 18:02:03,131 INFO     Weight matrix 4/9 (512,512): Alpha 3.9145039808904745 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:02:03,137 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8926184177398682\n",
      "2018-11-26 18:02:03,141 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:02:09,986 INFO     Weight matrix 5/9 (512,512): Alpha: 3.4179646971032067, Alpha Weighted: 2.0705890678508605, D: 0.07244192481919393\n",
      "2018-11-26 18:02:09,991 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9466754794120789\n",
      "2018-11-26 18:02:09,994 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:02:16,758 INFO     Weight matrix 6/9 (512,512): Alpha: 3.7869388651194282, Alpha Weighted: 2.356859101576862, D: 0.03900870280068025\n",
      "2018-11-26 18:02:16,761 INFO     Weight matrix 6/9 (512,512): Alpha 3.7869388651194282 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:02:16,766 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8962573409080505\n",
      "2018-11-26 18:02:16,770 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:02:23,575 INFO     Weight matrix 7/9 (512,512): Alpha: 3.506219202507494, Alpha Weighted: 2.2782028974566595, D: 0.029723883620612845\n",
      "2018-11-26 18:02:23,578 INFO     Weight matrix 7/9 (512,512): Alpha 3.506219202507494 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:02:23,583 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9141709804534912\n",
      "2018-11-26 18:02:23,586 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:02:30,410 INFO     Weight matrix 8/9 (512,512): Alpha: 3.8767831097291174, Alpha Weighted: 2.422656696617316, D: 0.039148629026716286\n",
      "2018-11-26 18:02:30,413 INFO     Weight matrix 8/9 (512,512): Alpha 3.8767831097291174 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:02:30,418 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9309837222099304\n",
      "2018-11-26 18:02:30,421 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:02:37,224 INFO     Weight matrix 9/9 (512,512): Alpha: 3.6576584248658177, Alpha Weighted: 2.358874802879612, D: 0.03703703703703809\n",
      "2018-11-26 18:02:37,226 INFO     Weight matrix 9/9 (512,512): Alpha 3.6576584248658177 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:02:37,232 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9144104719161987\n",
      "2018-11-26 18:02:37,236 INFO Layer 41: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 18:02:37,239 INFO Layer 41: Skipping (Layer not supported)\n",
      "2018-11-26 18:02:37,242 INFO Layer 42: ReLU(inplace)\n",
      "2018-11-26 18:02:37,244 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 18:02:37,247 INFO Layer 43: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:02:37,270 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:02:37,272 INFO Layer 43: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:02:37,275 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:02:44,066 INFO     Weight matrix 1/9 (512,512): Alpha: 5.186797054328852, Alpha Weighted: 1.6867749548370572, D: 0.0363925329672892\n",
      "2018-11-26 18:02:44,068 INFO     Weight matrix 1/9 (512,512): Alpha 5.186797054328852 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:02:44,075 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.8759857416152954\n",
      "2018-11-26 18:02:44,078 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:02:50,942 INFO     Weight matrix 2/9 (512,512): Alpha: 4.663723357156775, Alpha Weighted: 2.3769124382442115, D: 0.06143309601247665\n",
      "2018-11-26 18:02:50,944 INFO     Weight matrix 2/9 (512,512): Alpha 4.663723357156775 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:02:50,951 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.882684051990509\n",
      "2018-11-26 18:02:50,954 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 18:02:57,778 INFO     Weight matrix 3/9 (512,512): Alpha: 5.183862421916108, Alpha Weighted: 1.7007612797939162, D: 0.039576823463612576\n",
      "2018-11-26 18:02:57,780 INFO     Weight matrix 3/9 (512,512): Alpha 5.183862421916108 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:02:57,786 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.876889705657959\n",
      "2018-11-26 18:02:57,790 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:03:04,724 INFO     Weight matrix 4/9 (512,512): Alpha: 3.7748482245345496, Alpha Weighted: 3.2648263780278226, D: 0.07214935809368361\n",
      "2018-11-26 18:03:04,726 INFO     Weight matrix 4/9 (512,512): Alpha 3.7748482245345496 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:03:04,731 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8779275417327881\n",
      "2018-11-26 18:03:04,735 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:03:11,575 INFO     Weight matrix 5/9 (512,512): Alpha: 3.4360429717286216, Alpha Weighted: 3.563808384033567, D: 0.04467379637870311\n",
      "2018-11-26 18:03:11,580 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9018182158470154\n",
      "2018-11-26 18:03:11,583 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:03:18,360 INFO     Weight matrix 6/9 (512,512): Alpha: 3.909597037621061, Alpha Weighted: 3.410172661663601, D: 0.06684649525053132\n",
      "2018-11-26 18:03:18,363 INFO     Weight matrix 6/9 (512,512): Alpha 3.909597037621061 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:03:18,369 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8803690075874329\n",
      "2018-11-26 18:03:18,372 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:03:25,453 INFO     Weight matrix 7/9 (512,512): Alpha: 5.113536050289041, Alpha Weighted: 1.7952346361816836, D: 0.048743422857099095\n",
      "2018-11-26 18:03:25,455 INFO     Weight matrix 7/9 (512,512): Alpha 5.113536050289041 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:03:25,461 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.8681244850158691\n",
      "2018-11-26 18:03:25,464 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:03:32,428 INFO     Weight matrix 8/9 (512,512): Alpha: 4.634016490262876, Alpha Weighted: 2.203920032426283, D: 0.06334973555539003\n",
      "2018-11-26 18:03:32,430 INFO     Weight matrix 8/9 (512,512): Alpha 4.634016490262876 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:03:32,436 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.8740649819374084\n",
      "2018-11-26 18:03:32,439 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:03:39,396 INFO     Weight matrix 9/9 (512,512): Alpha: 5.228556443414164, Alpha Weighted: 1.776659117421908, D: 0.06556754531944498\n",
      "2018-11-26 18:03:39,399 INFO     Weight matrix 9/9 (512,512): Alpha 5.228556443414164 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:03:39,404 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.871013879776001\n",
      "2018-11-26 18:03:39,408 INFO Layer 44: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 18:03:39,410 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 18:03:39,413 INFO Layer 45: ReLU(inplace)\n",
      "2018-11-26 18:03:39,417 INFO Layer 45: Skipping (Layer not supported)\n",
      "2018-11-26 18:03:39,420 INFO Layer 46: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 18:03:39,422 INFO Layer 46: Skipping (Layer not supported)\n",
      "2018-11-26 18:03:39,426 INFO Layer 47: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 18:03:39,571 INFO Layer 47: Skipping (Layer not supported)\n",
      "2018-11-26 18:03:39,575 INFO Layer 48: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 18:03:41,790 INFO Layer 48: Analyzing 1 weight matrices...\n",
      "2018-11-26 18:03:41,793 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 18:14:35,947 INFO     Weight matrix 1/1 (4096,25088): Alpha: 2.052113319532734, Alpha Weighted: 2.6839501052667027, D: 0.02843069398503717\n",
      "2018-11-26 18:14:35,982 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.6797510385513306\n",
      "2018-11-26 18:14:36,084 INFO Layer 49: ReLU(inplace)\n",
      "2018-11-26 18:14:36,174 INFO Layer 49: Skipping (Layer not supported)\n",
      "2018-11-26 18:14:36,177 INFO Layer 50: Dropout(p=0.5)\n",
      "2018-11-26 18:14:36,179 INFO Layer 50: Skipping (Layer not supported)\n",
      "2018-11-26 18:14:36,182 INFO Layer 51: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 18:14:36,287 INFO Layer 51: Analyzing 1 weight matrices...\n",
      "2018-11-26 18:14:36,290 INFO     Weight matrix 1/1 (4096,4096): Analyzing ...\n",
      "2018-11-26 18:19:58,159 INFO     Weight matrix 1/1 (4096,4096): Alpha: 1.9682979761943988, Alpha Weighted: 3.2161213513487383, D: 0.0362937730865312\n",
      "2018-11-26 18:19:58,170 INFO     Weight matrix 1/1 (4096,4096): Lognorm: 1.5978648662567139\n",
      "2018-11-26 18:19:58,197 INFO Layer 52: ReLU(inplace)\n",
      "2018-11-26 18:19:58,223 INFO Layer 52: Skipping (Layer not supported)\n",
      "2018-11-26 18:19:58,228 INFO Layer 53: Dropout(p=0.5)\n",
      "2018-11-26 18:19:58,233 INFO Layer 53: Skipping (Layer not supported)\n",
      "2018-11-26 18:19:58,235 INFO Layer 54: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 18:19:58,270 INFO Layer 54: Analyzing 1 weight matrices...\n",
      "2018-11-26 18:19:58,273 INFO     Weight matrix 1/1 (1000,4096): Analyzing ...\n",
      "2018-11-26 18:20:23,221 INFO     Weight matrix 1/1 (1000,4096): Alpha: 3.03143324402249, Alpha Weighted: 5.226975027068021, D: 0.035839352726250495\n",
      "2018-11-26 18:20:23,226 INFO     Weight matrix 1/1 (1000,4096): Lognorm: 1.5973176956176758\n",
      "2018-11-26 18:20:23,249 INFO ### Printing results ###\n",
      "2018-11-26 18:20:23,252 DEBUG Layer 5: Lognorm compound: 0.35032408436139423\n",
      "2018-11-26 18:20:23,254 DEBUG Layer 9: Lognorm compound: 0.549374520778656\n",
      "2018-11-26 18:20:23,259 DEBUG Layer 12: Lognorm compound: 0.564693722460005\n",
      "2018-11-26 18:20:23,262 DEBUG Layer 16: Lognorm compound: 0.664220372835795\n",
      "2018-11-26 18:20:23,266 DEBUG Layer 19: Lognorm compound: 0.7156476312213473\n",
      "2018-11-26 18:20:23,268 DEBUG Layer 22: Lognorm compound: 0.740364584657881\n",
      "2018-11-26 18:20:23,272 DEBUG Layer 26: Lognorm compound: 0.8401365412606133\n",
      "2018-11-26 18:20:23,274 DEBUG Layer 29: Lognorm compound: 0.8981673916180929\n",
      "2018-11-26 18:20:23,277 DEBUG Layer 32: Lognorm compound: 0.9061964485380385\n",
      "2018-11-26 18:20:23,279 DEBUG Layer 36: Lognorm compound: 0.9295148452123007\n",
      "2018-11-26 18:20:23,282 DEBUG Layer 39: Lognorm compound: 0.9188066654735141\n",
      "2018-11-26 18:20:23,284 DEBUG Layer 42: Lognorm compound: 0.8787641790178087\n",
      "2018-11-26 18:20:23,287 DEBUG Layer 47: Lognorm: 1.6797510385513306\n",
      "2018-11-26 18:20:23,289 DEBUG Layer 50: Lognorm: 1.5978648662567139\n",
      "2018-11-26 18:20:23,293 DEBUG Layer 53: Lognorm: 1.5973176956176758\n",
      "2018-11-26 18:20:23,295 INFO LogNorm: min: 0.28816333413124084, max: 1.6797510385513306, avg: 0.770097553730011\n",
      "2018-11-26 18:20:23,297 INFO LogNorm compound: min: 0.35032408436139423, max: 1.6797510385513306, avg: 0.9220763058574111\n",
      "2018-11-26 18:20:23,300 DEBUG Layer 5: Alpha compound: 2.7281008948532723\n",
      "2018-11-26 18:20:23,303 DEBUG Layer 9: Alpha compound: 1.664892467685746\n",
      "2018-11-26 18:20:23,305 DEBUG Layer 12: Alpha compound: 2.957884709552109\n",
      "2018-11-26 18:20:23,307 DEBUG Layer 16: Alpha compound: 2.8817836613584893\n",
      "2018-11-26 18:20:23,310 DEBUG Layer 19: Alpha compound: 2.510523615366611\n",
      "2018-11-26 18:20:23,314 DEBUG Layer 22: Alpha compound: 3.0628973061367457\n",
      "2018-11-26 18:20:23,316 DEBUG Layer 26: Alpha compound: 2.968723401401661\n",
      "2018-11-26 18:20:23,318 DEBUG Layer 29: Alpha compound: 3.159634858997025\n",
      "2018-11-26 18:20:23,321 DEBUG Layer 32: Alpha compound: 3.3588807615980105\n",
      "2018-11-26 18:20:23,323 DEBUG Layer 36: Alpha compound: 3.942469778701105\n",
      "2018-11-26 18:20:23,326 DEBUG Layer 39: Alpha compound: 3.6326176562609294\n",
      "2018-11-26 18:20:23,329 DEBUG Layer 42: Alpha compound: 4.570108894583561\n",
      "2018-11-26 18:20:23,332 DEBUG Layer 47: Alpha: 2.052113319532734\n",
      "2018-11-26 18:20:23,333 DEBUG Layer 50: Alpha: 1.9682979761943988\n",
      "2018-11-26 18:20:23,336 DEBUG Layer 53: Alpha: 3.03143324402249\n",
      "2018-11-26 18:20:23,338 INFO Alpha: min: 1.5416898601966809, max: 5.677348485791719, avg: 3.0990856450288917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 18:20:23,342 INFO Alpha compound: min: 1.664892467685746, max: 4.570108894583561, avg: 2.966024169749659\n",
      "2018-11-26 18:20:23,344 DEBUG Layer 5: Alpha Weighted compound: 0.4815457367715123\n",
      "2018-11-26 18:20:23,346 DEBUG Layer 9: Alpha Weighted compound: 0.7099303638041259\n",
      "2018-11-26 18:20:23,351 DEBUG Layer 12: Alpha Weighted compound: 0.13886882344499363\n",
      "2018-11-26 18:20:23,354 DEBUG Layer 16: Alpha Weighted compound: 0.5406667088047536\n",
      "2018-11-26 18:20:23,356 DEBUG Layer 19: Alpha Weighted compound: 0.31269518520213324\n",
      "2018-11-26 18:20:23,359 DEBUG Layer 22: Alpha Weighted compound: 0.3889661370360851\n",
      "2018-11-26 18:20:23,362 DEBUG Layer 26: Alpha Weighted compound: 0.7548285489507651\n",
      "2018-11-26 18:20:23,364 DEBUG Layer 29: Alpha Weighted compound: 1.099820158739301\n",
      "2018-11-26 18:20:23,367 DEBUG Layer 32: Alpha Weighted compound: 1.7856443904470944\n",
      "2018-11-26 18:20:23,371 DEBUG Layer 36: Alpha Weighted compound: 1.1490744097179673\n",
      "2018-11-26 18:20:23,377 DEBUG Layer 39: Alpha Weighted compound: 2.326887952072043\n",
      "2018-11-26 18:20:23,379 DEBUG Layer 42: Alpha Weighted compound: 2.419896653625561\n",
      "2018-11-26 18:20:23,382 DEBUG Layer 47: Alpha Weigthed: 2.6839501052667027\n",
      "2018-11-26 18:20:23,384 DEBUG Layer 50: Alpha Weigthed: 3.2161213513487383\n",
      "2018-11-26 18:20:23,386 DEBUG Layer 53: Alpha Weigthed: 5.226975027068021\n",
      "2018-11-26 18:20:23,392 INFO Alpha Weighted: min: -0.14159613714904265, max: 5.226975027068021, avg: 1.0820402892002745\n",
      "2018-11-26 18:20:23,397 INFO Alpha Weighted compound: min: 0.13886882344499363, max: 5.226975027068021, avg: 1.5490581034866533\n"
     ]
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.vgg16_bn(pretrained=True)\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "results = watcher.analyze(compute_alphas=True)\n",
    "\n",
    "data.append({\"name\": \"vgg16bntorch\", \"summary\": watcher.get_summary()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T02:41:49.040272Z",
     "start_time": "2018-11-27T02:20:23.743586Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 18:20:30,539 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 18:20:30,542 INFO Analyzing model\n",
      "2018-11-26 18:20:30,547 INFO Layer 1: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 18:20:30,550 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 18:20:30,553 INFO Layer 2: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): ReLU(inplace)\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU(inplace)\n",
      "  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU(inplace)\n",
      "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (12): ReLU(inplace)\n",
      "  (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (14): ReLU(inplace)\n",
      "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (17): ReLU(inplace)\n",
      "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (19): ReLU(inplace)\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 18:20:30,558 INFO Layer 2: Skipping (Layer not supported)\n",
      "2018-11-26 18:20:30,562 INFO Layer 3: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:20:30,568 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:20:30,572 INFO Layer 3: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:20:30,575 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:20:30,579 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:20:30,585 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:20:30,590 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:20:30,595 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:20:30,599 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:20:30,602 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:20:30,605 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:20:30,607 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:20:30,610 INFO Layer 4: ReLU(inplace)\n",
      "2018-11-26 18:20:30,613 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 18:20:30,621 INFO Layer 5: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 18:20:30,626 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 18:20:30,628 INFO Layer 6: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:20:30,637 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:20:30,639 INFO Layer 6: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:20:30,644 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:20:31,133 INFO     Weight matrix 1/9 (64,128): Alpha: 1.6501382770775943, Alpha Weighted: 1.0766481037887519, D: 0.16948541888647117\n",
      "2018-11-26 18:20:31,137 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.7435316443443298\n",
      "2018-11-26 18:20:31,142 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:20:31,587 INFO     Weight matrix 2/9 (64,128): Alpha: 1.5729750131445848, Alpha Weighted: 1.1663846304163914, D: 0.17973842750311175\n",
      "2018-11-26 18:20:31,591 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.7791202068328857\n",
      "2018-11-26 18:20:31,594 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:20:32,050 INFO     Weight matrix 3/9 (64,128): Alpha: 1.4121039504790391, Alpha Weighted: 0.8954579004653346, D: 0.19428108503595737\n",
      "2018-11-26 18:20:32,053 INFO     Weight matrix 3/9 (64,128): Alpha 1.4121039504790391 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:20:32,056 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.7536869049072266\n",
      "2018-11-26 18:20:32,059 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:20:32,493 INFO     Weight matrix 4/9 (64,128): Alpha: 1.4345913027003299, Alpha Weighted: 0.9448696774806342, D: 0.18133941433239287\n",
      "2018-11-26 18:20:32,495 INFO     Weight matrix 4/9 (64,128): Alpha 1.4345913027003299 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:20:32,499 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.7681989669799805\n",
      "2018-11-26 18:20:32,502 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:20:32,957 INFO     Weight matrix 5/9 (64,128): Alpha: 1.618499097955453, Alpha Weighted: 1.5610026505187182, D: 0.1623259162046009\n",
      "2018-11-26 18:20:32,961 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.8472697138786316\n",
      "2018-11-26 18:20:32,964 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:20:33,412 INFO     Weight matrix 6/9 (64,128): Alpha: 1.3854856815241523, Alpha Weighted: 1.0132790887261636, D: 0.18905124095354037\n",
      "2018-11-26 18:20:33,414 INFO     Weight matrix 6/9 (64,128): Alpha 1.3854856815241523 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:20:33,420 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.7852299809455872\n",
      "2018-11-26 18:20:33,424 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:20:33,863 INFO     Weight matrix 7/9 (64,128): Alpha: 1.569204287744134, Alpha Weighted: 0.9040590765965885, D: 0.18198363054134498\n",
      "2018-11-26 18:20:33,867 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.7200042009353638\n",
      "2018-11-26 18:20:33,869 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:20:34,314 INFO     Weight matrix 8/9 (64,128): Alpha: 1.4466120457359575, Alpha Weighted: 1.0071455523713326, D: 0.1815803043396445\n",
      "2018-11-26 18:20:34,316 INFO     Weight matrix 8/9 (64,128): Alpha 1.4466120457359575 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:20:34,321 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.7804905772209167\n",
      "2018-11-26 18:20:34,324 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:20:34,777 INFO     Weight matrix 9/9 (64,128): Alpha: 1.6136188649159218, Alpha Weighted: 1.0025028039906874, D: 0.17297146920538053\n",
      "2018-11-26 18:20:34,781 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.7450646758079529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 18:20:34,783 INFO Layer 7: ReLU(inplace)\n",
      "2018-11-26 18:20:34,785 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 18:20:34,788 INFO Layer 8: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 18:20:34,795 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 18:20:34,801 INFO Layer 9: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:20:34,810 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:20:34,812 INFO Layer 9: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:20:34,816 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:20:35,824 INFO     Weight matrix 1/9 (128,256): Alpha: 2.682211407006033, Alpha Weighted: 1.1110499237387716, D: 0.15839192109291017\n",
      "2018-11-26 18:20:35,829 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.7695422768592834\n",
      "2018-11-26 18:20:35,832 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:20:36,824 INFO     Weight matrix 2/9 (128,256): Alpha: 1.624575541168831, Alpha Weighted: 0.984971913982178, D: 0.15038349531670658\n",
      "2018-11-26 18:20:36,827 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.8349188566207886\n",
      "2018-11-26 18:20:36,830 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:20:37,825 INFO     Weight matrix 3/9 (128,256): Alpha: 1.7481679222487294, Alpha Weighted: 0.7086755610270317, D: 0.15976233422592823\n",
      "2018-11-26 18:20:37,828 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.7710186839103699\n",
      "2018-11-26 18:20:37,831 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:20:38,832 INFO     Weight matrix 4/9 (128,256): Alpha: 2.5760761533690415, Alpha Weighted: 1.6520568886432534, D: 0.1331333429941114\n",
      "2018-11-26 18:20:38,837 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.8396487832069397\n",
      "2018-11-26 18:20:38,841 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:20:39,833 INFO     Weight matrix 5/9 (128,256): Alpha: 2.533727366357981, Alpha Weighted: 2.241522152097174, D: 0.1260398277024164\n",
      "2018-11-26 18:20:39,838 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.9509152770042419\n",
      "2018-11-26 18:20:39,841 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:20:40,859 INFO     Weight matrix 6/9 (128,256): Alpha: 1.6150834846735778, Alpha Weighted: 1.0727976671879713, D: 0.12912547936004531\n",
      "2018-11-26 18:20:40,862 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.8459222912788391\n",
      "2018-11-26 18:20:40,865 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:20:41,876 INFO     Weight matrix 7/9 (128,256): Alpha: 1.6649289890160561, Alpha Weighted: 0.6363945630295984, D: 0.15493782240951948\n",
      "2018-11-26 18:20:41,879 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.769291341304779\n",
      "2018-11-26 18:20:41,884 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:20:42,889 INFO     Weight matrix 8/9 (128,256): Alpha: 1.6911656312843695, Alpha Weighted: 1.020692965175946, D: 0.13113787530768883\n",
      "2018-11-26 18:20:42,893 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.8332030773162842\n",
      "2018-11-26 18:20:42,897 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:20:43,905 INFO     Weight matrix 9/9 (128,256): Alpha: 2.0503678706616313, Alpha Weighted: 0.8569681256199276, D: 0.14425799900587544\n",
      "2018-11-26 18:20:43,908 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.7771602272987366\n",
      "2018-11-26 18:20:43,912 INFO Layer 10: ReLU(inplace)\n",
      "2018-11-26 18:20:43,915 INFO Layer 10: Skipping (Layer not supported)\n",
      "2018-11-26 18:20:43,919 INFO Layer 11: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:20:43,930 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:20:43,932 INFO Layer 11: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:20:43,935 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:20:46,400 INFO     Weight matrix 1/9 (256,256): Alpha: 2.2103685446241137, Alpha Weighted: 0.8721202008061498, D: 0.12885915651960533\n",
      "2018-11-26 18:20:46,405 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.8579453229904175\n",
      "2018-11-26 18:20:46,410 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:20:48,873 INFO     Weight matrix 2/9 (256,256): Alpha: 2.0252637250206416, Alpha Weighted: 1.0256377100677299, D: 0.12252819174340557\n",
      "2018-11-26 18:20:48,878 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.8855762481689453\n",
      "2018-11-26 18:20:48,881 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:20:51,342 INFO     Weight matrix 3/9 (256,256): Alpha: 2.0484478817871095, Alpha Weighted: 0.8159194240963691, D: 0.12204156291064844\n",
      "2018-11-26 18:20:51,347 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.8663251399993896\n",
      "2018-11-26 18:20:51,350 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:20:53,786 INFO     Weight matrix 4/9 (256,256): Alpha: 2.6582698201793162, Alpha Weighted: 1.3211438834431082, D: 0.12169919267658397\n",
      "2018-11-26 18:20:53,791 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.8791447281837463\n",
      "2018-11-26 18:20:53,794 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:20:56,269 INFO     Weight matrix 5/9 (256,256): Alpha: 1.80045361683568, Alpha Weighted: 1.3681396518985667, D: 0.11590061764212117\n",
      "2018-11-26 18:20:56,274 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.9453065395355225\n",
      "2018-11-26 18:20:56,277 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:20:58,731 INFO     Weight matrix 6/9 (256,256): Alpha: 2.0425179990684748, Alpha Weighted: 1.1107898221155852, D: 0.1237446365572557\n",
      "2018-11-26 18:20:58,734 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.886420488357544\n",
      "2018-11-26 18:20:58,738 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:21:01,207 INFO     Weight matrix 7/9 (256,256): Alpha: 2.604096789214418, Alpha Weighted: 1.0384152774430735, D: 0.12428418827194665\n",
      "2018-11-26 18:21:01,212 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.8589674830436707\n",
      "2018-11-26 18:21:01,217 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:21:03,647 INFO     Weight matrix 8/9 (256,256): Alpha: 1.974426187742051, Alpha Weighted: 0.9784457988600769, D: 0.12141249164484802\n",
      "2018-11-26 18:21:03,651 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.8895105123519897\n",
      "2018-11-26 18:21:03,654 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:21:06,090 INFO     Weight matrix 9/9 (256,256): Alpha: 2.0731958622076387, Alpha Weighted: 0.8033694269240823, D: 0.13215291968367504\n",
      "2018-11-26 18:21:06,094 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.8611611127853394\n",
      "2018-11-26 18:21:06,097 INFO Layer 12: ReLU(inplace)\n",
      "2018-11-26 18:21:06,102 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 18:21:06,104 INFO Layer 13: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 18:21:06,107 INFO Layer 13: Skipping (Layer not supported)\n",
      "2018-11-26 18:21:06,109 INFO Layer 14: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:21:06,132 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:21:06,135 INFO Layer 14: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:21:06,138 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:21:08,672 INFO     Weight matrix 1/9 (256,512): Alpha: 2.6517221926740246, Alpha Weighted: 1.2570211280999037, D: 0.10811361598539998\n",
      "2018-11-26 18:21:08,677 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.9264131188392639\n",
      "2018-11-26 18:21:08,680 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:21:11,193 INFO     Weight matrix 2/9 (256,512): Alpha: 2.168115236956596, Alpha Weighted: 1.2167389540956297, D: 0.12371985885919029\n",
      "2018-11-26 18:21:11,197 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.9532338976860046\n",
      "2018-11-26 18:21:11,200 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:21:13,704 INFO     Weight matrix 3/9 (256,512): Alpha: 2.6890834415941622, Alpha Weighted: 1.2802716588252028, D: 0.09975489509022295\n",
      "2018-11-26 18:21:13,709 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.9262917041778564\n",
      "2018-11-26 18:21:13,712 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:21:16,227 INFO     Weight matrix 4/9 (256,512): Alpha: 2.05571903033187, Alpha Weighted: 1.2611985718572283, D: 0.11025199350743697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 18:21:16,232 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.9493745565414429\n",
      "2018-11-26 18:21:16,235 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:21:18,721 INFO     Weight matrix 5/9 (256,512): Alpha: 3.8241533596937587, Alpha Weighted: 3.2637560530217025, D: 0.09906489422422304\n",
      "2018-11-26 18:21:18,724 INFO     Weight matrix 5/9 (256,512): Alpha 3.8241533596937587 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:21:18,729 INFO     Weight matrix 5/9 (256,512): Lognorm: 1.0106232166290283\n",
      "2018-11-26 18:21:18,732 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:21:21,290 INFO     Weight matrix 6/9 (256,512): Alpha: 2.841660949785283, Alpha Weighted: 1.7285448401474826, D: 0.10146026051677032\n",
      "2018-11-26 18:21:21,295 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.9507067203521729\n",
      "2018-11-26 18:21:21,297 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:21:23,816 INFO     Weight matrix 7/9 (256,512): Alpha: 2.5426618067263176, Alpha Weighted: 1.1927627254327484, D: 0.11033037759688885\n",
      "2018-11-26 18:21:23,820 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.9216506481170654\n",
      "2018-11-26 18:21:23,825 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:21:26,501 INFO     Weight matrix 8/9 (256,512): Alpha: 2.8994876906762146, Alpha Weighted: 1.6334750171091756, D: 0.11620842040762192\n",
      "2018-11-26 18:21:26,507 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.9460030794143677\n",
      "2018-11-26 18:21:26,510 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:21:29,060 INFO     Weight matrix 9/9 (256,512): Alpha: 2.2671621440449634, Alpha Weighted: 1.1108181220288662, D: 0.11398776995328902\n",
      "2018-11-26 18:21:29,065 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.922294020652771\n",
      "2018-11-26 18:21:29,067 INFO Layer 15: ReLU(inplace)\n",
      "2018-11-26 18:21:29,070 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 18:21:29,074 INFO Layer 16: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:21:29,114 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:21:29,117 INFO Layer 16: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:21:29,120 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:21:36,102 INFO     Weight matrix 1/9 (512,512): Alpha: 3.149648444782752, Alpha Weighted: 2.028055370333752, D: 0.05121052971449114\n",
      "2018-11-26 18:21:36,107 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9826978445053101\n",
      "2018-11-26 18:21:36,109 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:21:42,920 INFO     Weight matrix 2/9 (512,512): Alpha: 3.517971256356241, Alpha Weighted: 2.726141626150599, D: 0.06635113801870962\n",
      "2018-11-26 18:21:42,923 INFO     Weight matrix 2/9 (512,512): Alpha 3.517971256356241 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:21:42,930 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9950791001319885\n",
      "2018-11-26 18:21:42,933 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:21:49,807 INFO     Weight matrix 3/9 (512,512): Alpha: 3.147035933794287, Alpha Weighted: 1.989780656565079, D: 0.053711562073911256\n",
      "2018-11-26 18:21:49,812 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9823008179664612\n",
      "2018-11-26 18:21:49,815 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:21:56,629 INFO     Weight matrix 4/9 (512,512): Alpha: 2.7469966097522645, Alpha Weighted: 2.139474129042325, D: 0.057414464204918914\n",
      "2018-11-26 18:21:56,634 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9806457757949829\n",
      "2018-11-26 18:21:56,636 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:22:03,501 INFO     Weight matrix 5/9 (512,512): Alpha: 2.4074207884563013, Alpha Weighted: 2.3368142570363637, D: 0.062304336683778716\n",
      "2018-11-26 18:22:03,507 INFO     Weight matrix 5/9 (512,512): Lognorm: 1.0240429639816284\n",
      "2018-11-26 18:22:03,510 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:22:10,336 INFO     Weight matrix 6/9 (512,512): Alpha: 3.3026568899558133, Alpha Weighted: 2.52994138893387, D: 0.05006987529712492\n",
      "2018-11-26 18:22:10,340 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9784256815910339\n",
      "2018-11-26 18:22:10,345 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:22:17,174 INFO     Weight matrix 7/9 (512,512): Alpha: 3.1959287997262376, Alpha Weighted: 1.9390570677876782, D: 0.0521771204407705\n",
      "2018-11-26 18:22:17,179 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9802641868591309\n",
      "2018-11-26 18:22:17,184 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:22:23,961 INFO     Weight matrix 8/9 (512,512): Alpha: 3.3540205382605977, Alpha Weighted: 2.674930185352635, D: 0.04651014293096384\n",
      "2018-11-26 18:22:23,966 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9925370812416077\n",
      "2018-11-26 18:22:23,968 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:22:30,858 INFO     Weight matrix 9/9 (512,512): Alpha: 2.9671914919820344, Alpha Weighted: 1.8252346990679236, D: 0.060972734290955954\n",
      "2018-11-26 18:22:30,863 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9784339070320129\n",
      "2018-11-26 18:22:30,866 INFO Layer 17: ReLU(inplace)\n",
      "2018-11-26 18:22:30,869 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 18:22:30,872 INFO Layer 18: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 18:22:30,874 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 18:22:30,877 INFO Layer 19: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:22:30,907 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:22:30,909 INFO Layer 19: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:22:30,912 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:22:37,605 INFO     Weight matrix 1/9 (512,512): Alpha: 2.7750607841399937, Alpha Weighted: 1.4194219254810037, D: 0.08158043468159282\n",
      "2018-11-26 18:22:37,610 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9942262768745422\n",
      "2018-11-26 18:22:37,613 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:22:44,445 INFO     Weight matrix 2/9 (512,512): Alpha: 3.650769544994363, Alpha Weighted: 2.2269250836955736, D: 0.07941522306194615\n",
      "2018-11-26 18:22:44,448 INFO     Weight matrix 2/9 (512,512): Alpha 3.650769544994363 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:22:44,454 INFO     Weight matrix 2/9 (512,512): Lognorm: 1.0120388269424438\n",
      "2018-11-26 18:22:44,460 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:22:51,285 INFO     Weight matrix 3/9 (512,512): Alpha: 3.171843534895438, Alpha Weighted: 1.7129869021903819, D: 0.0755639941067181\n",
      "2018-11-26 18:22:51,290 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9953451752662659\n",
      "2018-11-26 18:22:51,292 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:22:58,084 INFO     Weight matrix 4/9 (512,512): Alpha: 3.87588443682989, Alpha Weighted: 2.381272818757222, D: 0.07539007513859203\n",
      "2018-11-26 18:22:58,087 INFO     Weight matrix 4/9 (512,512): Alpha 3.87588443682989 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:22:58,093 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9894785284996033\n",
      "2018-11-26 18:22:58,096 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:23:04,991 INFO     Weight matrix 5/9 (512,512): Alpha: 2.2345622437509394, Alpha Weighted: 1.8784371173129792, D: 0.07883945914071538\n",
      "2018-11-26 18:23:04,996 INFO     Weight matrix 5/9 (512,512): Lognorm: 1.0499871969223022\n",
      "2018-11-26 18:23:04,999 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:23:11,813 INFO     Weight matrix 6/9 (512,512): Alpha: 3.202316954098326, Alpha Weighted: 2.0257139671622237, D: 0.07163807372296888\n",
      "2018-11-26 18:23:11,817 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9896095991134644\n",
      "2018-11-26 18:23:11,820 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:23:18,583 INFO     Weight matrix 7/9 (512,512): Alpha: 2.8866015053848253, Alpha Weighted: 1.5256257328856722, D: 0.07947093609658534\n",
      "2018-11-26 18:23:18,588 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9956439733505249\n",
      "2018-11-26 18:23:18,590 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:23:25,386 INFO     Weight matrix 8/9 (512,512): Alpha: 2.9933223636238315, Alpha Weighted: 1.8340164191018828, D: 0.07260375621779336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 18:23:25,391 INFO     Weight matrix 8/9 (512,512): Lognorm: 1.0118615627288818\n",
      "2018-11-26 18:23:25,394 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:23:32,237 INFO     Weight matrix 9/9 (512,512): Alpha: 2.9316370599462, Alpha Weighted: 1.5953364374907442, D: 0.07331770935442683\n",
      "2018-11-26 18:23:32,242 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9950817823410034\n",
      "2018-11-26 18:23:32,244 INFO Layer 20: ReLU(inplace)\n",
      "2018-11-26 18:23:32,248 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 18:23:32,250 INFO Layer 21: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:23:32,272 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:23:32,275 INFO Layer 21: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:23:32,280 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:23:39,051 INFO     Weight matrix 1/9 (512,512): Alpha: 3.717479130641067, Alpha Weighted: 3.191591011040469, D: 0.039757321197883666\n",
      "2018-11-26 18:23:39,054 INFO     Weight matrix 1/9 (512,512): Alpha 3.717479130641067 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:23:39,060 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9724318981170654\n",
      "2018-11-26 18:23:39,063 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:23:45,884 INFO     Weight matrix 2/9 (512,512): Alpha: 3.6541366175090566, Alpha Weighted: 3.6434751354474875, D: 0.047044615903778286\n",
      "2018-11-26 18:23:45,887 INFO     Weight matrix 2/9 (512,512): Alpha 3.6541366175090566 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:23:45,893 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9977350234985352\n",
      "2018-11-26 18:23:45,895 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:23:52,722 INFO     Weight matrix 3/9 (512,512): Alpha: 3.7384648793118513, Alpha Weighted: 3.356184191626195, D: 0.03906638874613838\n",
      "2018-11-26 18:23:52,725 INFO     Weight matrix 3/9 (512,512): Alpha 3.7384648793118513 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:23:52,731 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.976440966129303\n",
      "2018-11-26 18:23:52,735 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:23:59,573 INFO     Weight matrix 4/9 (512,512): Alpha: 3.5153689145490628, Alpha Weighted: 3.2881336328788806, D: 0.029411764705883137\n",
      "2018-11-26 18:23:59,576 INFO     Weight matrix 4/9 (512,512): Alpha 3.5153689145490628 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:23:59,582 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9728533625602722\n",
      "2018-11-26 18:23:59,585 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:24:06,444 INFO     Weight matrix 5/9 (512,512): Alpha: 2.775348758200126, Alpha Weighted: 2.9837607551188086, D: 0.05535790579831745\n",
      "2018-11-26 18:24:06,448 INFO     Weight matrix 5/9 (512,512): Lognorm: 1.0238560438156128\n",
      "2018-11-26 18:24:06,451 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:24:13,260 INFO     Weight matrix 6/9 (512,512): Alpha: 3.437669806215007, Alpha Weighted: 3.236645447138899, D: 0.034924266366572754\n",
      "2018-11-26 18:24:13,265 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9753591418266296\n",
      "2018-11-26 18:24:13,268 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:24:20,262 INFO     Weight matrix 7/9 (512,512): Alpha: 3.7856382945120965, Alpha Weighted: 3.2028353085013985, D: 0.031727598200308\n",
      "2018-11-26 18:24:20,265 INFO     Weight matrix 7/9 (512,512): Alpha 3.7856382945120965 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:24:20,272 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9722591638565063\n",
      "2018-11-26 18:24:20,276 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:24:27,045 INFO     Weight matrix 8/9 (512,512): Alpha: 3.4097196918112664, Alpha Weighted: 3.3248430105161244, D: 0.04401247989259427\n",
      "2018-11-26 18:24:27,050 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9990035891532898\n",
      "2018-11-26 18:24:27,053 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:24:33,945 INFO     Weight matrix 9/9 (512,512): Alpha: 3.6552989325888867, Alpha Weighted: 3.110289701589598, D: 0.03151356443991926\n",
      "2018-11-26 18:24:33,947 INFO     Weight matrix 9/9 (512,512): Alpha 3.6552989325888867 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:24:33,953 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9731558561325073\n",
      "2018-11-26 18:24:33,956 INFO Layer 22: ReLU(inplace)\n",
      "2018-11-26 18:24:33,961 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 18:24:33,965 INFO Layer 23: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 18:24:33,968 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 18:24:33,970 INFO Layer 24: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 18:24:33,973 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 18:24:33,975 INFO Layer 25: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 18:24:36,094 INFO Layer 25: Analyzing 1 weight matrices...\n",
      "2018-11-26 18:24:36,097 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 18:35:39,401 INFO     Weight matrix 1/1 (4096,25088): Alpha: 2.3250658695260125, Alpha Weighted: 3.5838109726122194, D: 0.03256355213231643\n",
      "2018-11-26 18:35:39,435 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.7588783502578735\n",
      "2018-11-26 18:35:39,525 INFO Layer 26: ReLU(inplace)\n",
      "2018-11-26 18:35:39,619 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 18:35:39,627 INFO Layer 27: Dropout(p=0.5)\n",
      "2018-11-26 18:35:39,630 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 18:35:39,632 INFO Layer 28: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 18:35:39,754 INFO Layer 28: Analyzing 1 weight matrices...\n",
      "2018-11-26 18:35:39,757 INFO     Weight matrix 1/1 (4096,4096): Analyzing ...\n",
      "2018-11-26 18:41:22,742 INFO     Weight matrix 1/1 (4096,4096): Alpha: 2.167513240441732, Alpha Weighted: 3.8585285306915598, D: 0.030891387850316532\n",
      "2018-11-26 18:41:22,751 INFO     Weight matrix 1/1 (4096,4096): Lognorm: 1.6416341066360474\n",
      "2018-11-26 18:41:22,778 INFO Layer 29: ReLU(inplace)\n",
      "2018-11-26 18:41:22,804 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 18:41:22,806 INFO Layer 30: Dropout(p=0.5)\n",
      "2018-11-26 18:41:22,809 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 18:41:22,812 INFO Layer 31: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 18:41:22,854 INFO Layer 31: Analyzing 1 weight matrices...\n",
      "2018-11-26 18:41:22,856 INFO     Weight matrix 1/1 (1000,4096): Analyzing ...\n",
      "2018-11-26 18:41:48,667 INFO     Weight matrix 1/1 (1000,4096): Alpha: 2.8256530237886066, Alpha Weighted: 4.999372607286661, D: 0.03977324302285401\n",
      "2018-11-26 18:41:48,672 INFO     Weight matrix 1/1 (1000,4096): Lognorm: 1.5924100875854492\n",
      "2018-11-26 18:41:48,696 INFO ### Printing results ###\n",
      "2018-11-26 18:41:48,699 DEBUG Layer 5: Lognorm compound: 0.7691774302058749\n",
      "2018-11-26 18:41:48,702 DEBUG Layer 8: Lognorm compound: 0.8212912016444736\n",
      "2018-11-26 18:41:48,704 DEBUG Layer 10: Lognorm compound: 0.8811508417129517\n",
      "2018-11-26 18:41:48,707 DEBUG Layer 13: Lognorm compound: 0.9451767736011081\n",
      "2018-11-26 18:41:48,709 DEBUG Layer 15: Lognorm compound: 0.9882697065671285\n",
      "2018-11-26 18:41:48,711 DEBUG Layer 18: Lognorm compound: 1.0036969913376703\n",
      "2018-11-26 18:41:48,714 DEBUG Layer 20: Lognorm compound: 0.9847883383433024\n",
      "2018-11-26 18:41:48,716 DEBUG Layer 24: Lognorm: 1.7588783502578735\n",
      "2018-11-26 18:41:48,719 DEBUG Layer 27: Lognorm: 1.6416341066360474\n",
      "2018-11-26 18:41:48,722 DEBUG Layer 30: Lognorm: 1.5924100875854492\n",
      "2018-11-26 18:41:48,726 INFO LogNorm: min: 0.7200042009353638, max: 1.7588783502578735, avg: 0.9474982619285583\n",
      "2018-11-26 18:41:48,728 INFO LogNorm compound: min: 0.7691774302058749, max: 1.7588783502578735, avg: 1.138647382789188\n",
      "2018-11-26 18:41:48,732 DEBUG Layer 5: Alpha compound: 1.5225809468085738\n",
      "2018-11-26 18:41:48,734 DEBUG Layer 8: Alpha compound: 2.020700485087361\n",
      "2018-11-26 18:41:48,737 DEBUG Layer 10: Alpha compound: 2.1596711585199384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 18:41:48,739 DEBUG Layer 13: Alpha compound: 2.6599739836092433\n",
      "2018-11-26 18:41:48,742 DEBUG Layer 15: Alpha compound: 3.0876523058962815\n",
      "2018-11-26 18:41:48,745 DEBUG Layer 18: Alpha compound: 3.080222047518201\n",
      "2018-11-26 18:41:48,747 DEBUG Layer 20: Alpha compound: 3.521013891704269\n",
      "2018-11-26 18:41:48,750 DEBUG Layer 24: Alpha: 2.3250658695260125\n",
      "2018-11-26 18:41:48,753 DEBUG Layer 27: Alpha: 2.167513240441732\n",
      "2018-11-26 18:41:48,755 DEBUG Layer 30: Alpha: 2.8256530237886066\n",
      "2018-11-26 18:41:48,758 INFO Alpha: min: 1.3854856815241523, max: 3.87588443682989, avg: 2.5724934167583515\n",
      "2018-11-26 18:41:48,761 INFO Alpha compound: min: 1.5225809468085738, max: 3.521013891704269, avg: 2.537004695290022\n",
      "2018-11-26 18:41:48,764 DEBUG Layer 5: Alpha Weighted compound: 1.0634832760394002\n",
      "2018-11-26 18:41:48,768 DEBUG Layer 8: Alpha Weighted compound: 1.1427921956113167\n",
      "2018-11-26 18:41:48,770 DEBUG Layer 10: Alpha Weighted compound: 1.0371090217394157\n",
      "2018-11-26 18:41:48,773 DEBUG Layer 13: Alpha Weighted compound: 1.5493985634019931\n",
      "2018-11-26 18:41:48,777 DEBUG Layer 15: Alpha Weighted compound: 2.2432699311411364\n",
      "2018-11-26 18:41:48,779 DEBUG Layer 18: Alpha Weighted compound: 1.8444151560086313\n",
      "2018-11-26 18:41:48,782 DEBUG Layer 20: Alpha Weighted compound: 3.2597509104286515\n",
      "2018-11-26 18:41:48,787 DEBUG Layer 24: Alpha Weigthed: 3.5838109726122194\n",
      "2018-11-26 18:41:48,793 DEBUG Layer 27: Alpha Weigthed: 3.8585285306915598\n",
      "2018-11-26 18:41:48,797 DEBUG Layer 30: Alpha Weigthed: 4.999372607286661\n",
      "2018-11-26 18:41:48,799 INFO Alpha Weighted: min: 0.6363945630295984, max: 4.999372607286661, avg: 1.8439952060594749\n",
      "2018-11-26 18:41:48,802 INFO Alpha Weighted compound: min: 1.0371090217394157, max: 4.999372607286661, avg: 2.4581931164960986\n"
     ]
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.vgg11(pretrained=True)\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "results = watcher.analyze(compute_alphas=True)\n",
    "\n",
    "data.append({\"name\": \"vgg11torch\", \"summary\": watcher.get_summary()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:03:24.910198Z",
     "start_time": "2018-11-27T02:41:49.047241Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 18:41:55,751 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 18:41:55,754 INFO Analyzing model\n",
      "2018-11-26 18:41:55,757 INFO Layer 1: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace)\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): ReLU(inplace)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 18:41:55,759 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 18:41:55,763 INFO Layer 2: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ReLU(inplace)\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): ReLU(inplace)\n",
      "  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (13): ReLU(inplace)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): ReLU(inplace)\n",
      "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (20): ReLU(inplace)\n",
      "  (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (24): ReLU(inplace)\n",
      "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (27): ReLU(inplace)\n",
      "  (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 18:41:55,766 INFO Layer 2: Skipping (Layer not supported)\n",
      "2018-11-26 18:41:55,769 INFO Layer 3: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:41:55,773 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:41:55,774 INFO Layer 3: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:41:55,777 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:41:55,780 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:41:55,783 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:41:55,787 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:41:55,793 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:41:55,797 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:41:55,802 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:41:55,805 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:41:55,808 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 18:41:55,812 INFO Layer 4: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 18:41:55,815 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 18:41:55,818 INFO Layer 5: ReLU(inplace)\n",
      "2018-11-26 18:41:55,820 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 18:41:55,823 INFO Layer 6: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 18:41:55,954 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 18:41:55,958 INFO Layer 7: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:41:55,962 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:41:55,964 INFO Layer 7: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:41:55,967 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:41:56,369 INFO     Weight matrix 1/9 (64,128): Alpha: 1.6496957456422598, Alpha Weighted: 0.5947317011500954, D: 0.20626953809225157\n",
      "2018-11-26 18:41:56,372 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.5997806191444397\n",
      "2018-11-26 18:41:56,375 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:41:56,744 INFO     Weight matrix 2/9 (64,128): Alpha: 1.5135118063674884, Alpha Weighted: 0.806305749102268, D: 0.23009813034916904\n",
      "2018-11-26 18:41:56,748 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.6721765995025635\n",
      "2018-11-26 18:41:56,751 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:41:57,112 INFO     Weight matrix 3/9 (64,128): Alpha: 1.6653278215299951, Alpha Weighted: 0.5977157526353419, D: 0.2209023954719921\n",
      "2018-11-26 18:41:57,115 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.6062731146812439\n",
      "2018-11-26 18:41:57,118 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:41:57,466 INFO     Weight matrix 4/9 (64,128): Alpha: 1.7353059768279364, Alpha Weighted: 0.9808296413762294, D: 0.22664934316417418\n",
      "2018-11-26 18:41:57,469 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.6845961809158325\n",
      "2018-11-26 18:41:57,473 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:41:57,837 INFO     Weight matrix 5/9 (64,128): Alpha: 1.3312675874883295, Alpha Weighted: 1.0279249103896457, D: 0.2326199294950903\n",
      "2018-11-26 18:41:57,839 INFO     Weight matrix 5/9 (64,128): Alpha 1.3312675874883295 is in the danger zone (1.5,3.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 18:41:57,844 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.7663372755050659\n",
      "2018-11-26 18:41:57,847 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:41:58,212 INFO     Weight matrix 6/9 (64,128): Alpha: 1.3956646587397088, Alpha Weighted: 0.6589629825741868, D: 0.24556455827769613\n",
      "2018-11-26 18:41:58,215 INFO     Weight matrix 6/9 (64,128): Alpha 1.3956646587397088 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:41:58,219 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.6790146827697754\n",
      "2018-11-26 18:41:58,222 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:41:58,572 INFO     Weight matrix 7/9 (64,128): Alpha: 1.7195690051012653, Alpha Weighted: 0.6645154375610195, D: 0.18926289983584743\n",
      "2018-11-26 18:41:58,574 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.5993328094482422\n",
      "2018-11-26 18:41:58,581 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:41:58,942 INFO     Weight matrix 8/9 (64,128): Alpha: 1.836242467570802, Alpha Weighted: 1.0274902446687846, D: 0.2227667123707997\n",
      "2018-11-26 18:41:58,945 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.6673287749290466\n",
      "2018-11-26 18:41:58,948 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 18:41:59,317 INFO     Weight matrix 9/9 (64,128): Alpha: 2.1316326145787774, Alpha Weighted: 0.7780607265814438, D: 0.24408139094546888\n",
      "2018-11-26 18:41:59,322 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.6020925045013428\n",
      "2018-11-26 18:41:59,324 INFO Layer 8: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 18:41:59,327 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 18:41:59,330 INFO Layer 9: ReLU(inplace)\n",
      "2018-11-26 18:41:59,334 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 18:41:59,336 INFO Layer 10: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 18:41:59,338 INFO Layer 10: Skipping (Layer not supported)\n",
      "2018-11-26 18:41:59,341 INFO Layer 11: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:41:59,348 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:41:59,350 INFO Layer 11: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:41:59,354 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:42:00,411 INFO     Weight matrix 1/9 (128,256): Alpha: 2.238046629527916, Alpha Weighted: 1.0142093247706725, D: 0.10909762311508908\n",
      "2018-11-26 18:42:00,416 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.7035576105117798\n",
      "2018-11-26 18:42:00,418 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:42:01,442 INFO     Weight matrix 2/9 (128,256): Alpha: 1.7563880935228895, Alpha Weighted: 0.8394058714084498, D: 0.13504888565738954\n",
      "2018-11-26 18:42:01,447 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.7586631178855896\n",
      "2018-11-26 18:42:01,451 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:42:02,436 INFO     Weight matrix 3/9 (128,256): Alpha: 2.229832394597416, Alpha Weighted: 1.0593367754194072, D: 0.09628677587291234\n",
      "2018-11-26 18:42:02,441 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.6992807388305664\n",
      "2018-11-26 18:42:02,443 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:42:03,444 INFO     Weight matrix 4/9 (128,256): Alpha: 1.9745366689034338, Alpha Weighted: 0.9191998337716678, D: 0.1372015892589844\n",
      "2018-11-26 18:42:03,447 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.7612313032150269\n",
      "2018-11-26 18:42:03,452 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:42:04,435 INFO     Weight matrix 5/9 (128,256): Alpha: 2.8687626770298014, Alpha Weighted: 2.0244380578966132, D: 0.11077787242093917\n",
      "2018-11-26 18:42:04,438 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.8638467788696289\n",
      "2018-11-26 18:42:04,443 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:42:05,424 INFO     Weight matrix 6/9 (128,256): Alpha: 1.6140792143445528, Alpha Weighted: 0.706090195097394, D: 0.14066260650547052\n",
      "2018-11-26 18:42:05,429 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.7619961500167847\n",
      "2018-11-26 18:42:05,431 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:42:06,406 INFO     Weight matrix 7/9 (128,256): Alpha: 2.0247996005104323, Alpha Weighted: 0.8544546718868856, D: 0.11699064901932654\n",
      "2018-11-26 18:42:06,412 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.6964058876037598\n",
      "2018-11-26 18:42:06,416 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:42:07,391 INFO     Weight matrix 8/9 (128,256): Alpha: 1.9798945719813577, Alpha Weighted: 0.9343266776650887, D: 0.12884448311407254\n",
      "2018-11-26 18:42:07,394 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.755610466003418\n",
      "2018-11-26 18:42:07,398 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 18:42:08,369 INFO     Weight matrix 9/9 (128,256): Alpha: 2.139073704759788, Alpha Weighted: 0.9990548541212684, D: 0.10477107838590394\n",
      "2018-11-26 18:42:08,373 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.6986998915672302\n",
      "2018-11-26 18:42:08,377 INFO Layer 12: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 18:42:08,381 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 18:42:08,384 INFO Layer 13: ReLU(inplace)\n",
      "2018-11-26 18:42:08,386 INFO Layer 13: Skipping (Layer not supported)\n",
      "2018-11-26 18:42:08,389 INFO Layer 14: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:42:08,398 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:42:08,400 INFO Layer 14: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:42:08,403 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:42:10,825 INFO     Weight matrix 1/9 (256,256): Alpha: 2.1099516770625915, Alpha Weighted: 0.3695310119993883, D: 0.14019934786805022\n",
      "2018-11-26 18:42:10,830 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7819792628288269\n",
      "2018-11-26 18:42:10,834 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:42:13,249 INFO     Weight matrix 2/9 (256,256): Alpha: 2.035438832624266, Alpha Weighted: 0.5793953027943746, D: 0.1297485802155534\n",
      "2018-11-26 18:42:13,253 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.8153413534164429\n",
      "2018-11-26 18:42:13,258 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:42:15,661 INFO     Weight matrix 3/9 (256,256): Alpha: 2.2584270196724097, Alpha Weighted: 0.4197145819750078, D: 0.12950270137680098\n",
      "2018-11-26 18:42:15,666 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.781470537185669\n",
      "2018-11-26 18:42:15,669 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:42:18,050 INFO     Weight matrix 4/9 (256,256): Alpha: 1.8870318130078412, Alpha Weighted: 0.4640333641964341, D: 0.14037330787297508\n",
      "2018-11-26 18:42:18,055 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.8162485361099243\n",
      "2018-11-26 18:42:18,058 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:42:20,466 INFO     Weight matrix 5/9 (256,256): Alpha: 4.426796167746652, Alpha Weighted: 2.2788759337027216, D: 0.12898363996584916\n",
      "2018-11-26 18:42:20,469 INFO     Weight matrix 5/9 (256,256): Alpha 4.426796167746652 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:42:20,473 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8796184062957764\n",
      "2018-11-26 18:42:20,477 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:42:22,873 INFO     Weight matrix 6/9 (256,256): Alpha: 1.9802216846008944, Alpha Weighted: 0.500991229488712, D: 0.1360063084982408\n",
      "2018-11-26 18:42:22,878 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.8149921298027039\n",
      "2018-11-26 18:42:22,881 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:42:25,262 INFO     Weight matrix 7/9 (256,256): Alpha: 2.2316968955671186, Alpha Weighted: 0.30176647632390513, D: 0.14395217344166256\n",
      "2018-11-26 18:42:25,266 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.7732064127922058\n",
      "2018-11-26 18:42:25,269 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:42:27,680 INFO     Weight matrix 8/9 (256,256): Alpha: 2.0924369897290545, Alpha Weighted: 0.5409067682409202, D: 0.13138489016913835\n",
      "2018-11-26 18:42:27,684 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.8121046423912048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 18:42:27,688 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 18:42:30,139 INFO     Weight matrix 9/9 (256,256): Alpha: 2.29185994252126, Alpha Weighted: 0.34461455256572004, D: 0.12595510499948837\n",
      "2018-11-26 18:42:30,144 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7764164805412292\n",
      "2018-11-26 18:42:30,147 INFO Layer 15: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 18:42:30,149 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 18:42:30,151 INFO Layer 16: ReLU(inplace)\n",
      "2018-11-26 18:42:30,153 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 18:42:30,156 INFO Layer 17: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 18:42:30,159 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 18:42:30,161 INFO Layer 18: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:42:30,202 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:42:30,204 INFO Layer 18: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:42:30,207 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:42:32,763 INFO     Weight matrix 1/9 (256,512): Alpha: 2.6050254445874996, Alpha Weighted: 1.135166020621109, D: 0.09174582315715446\n",
      "2018-11-26 18:42:32,767 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.8869200348854065\n",
      "2018-11-26 18:42:32,770 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:42:35,305 INFO     Weight matrix 2/9 (256,512): Alpha: 3.1158529899615575, Alpha Weighted: 1.4450045111295022, D: 0.11584374022084354\n",
      "2018-11-26 18:42:35,311 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.9086707830429077\n",
      "2018-11-26 18:42:35,313 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:42:37,839 INFO     Weight matrix 3/9 (256,512): Alpha: 2.6308645002318776, Alpha Weighted: 1.1658520365132061, D: 0.08596221528298442\n",
      "2018-11-26 18:42:37,844 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.8812524080276489\n",
      "2018-11-26 18:42:37,847 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:42:40,322 INFO     Weight matrix 4/9 (256,512): Alpha: 3.167499679125847, Alpha Weighted: 1.5579714025333327, D: 0.09014502057935336\n",
      "2018-11-26 18:42:40,326 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.9096864461898804\n",
      "2018-11-26 18:42:40,329 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:42:42,868 INFO     Weight matrix 5/9 (256,512): Alpha: 5.2298727236158875, Alpha Weighted: 3.393250607528101, D: 0.07692307692307654\n",
      "2018-11-26 18:42:42,871 INFO     Weight matrix 5/9 (256,512): Alpha 5.2298727236158875 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:42:42,876 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.9789407253265381\n",
      "2018-11-26 18:42:42,880 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:42:45,401 INFO     Weight matrix 6/9 (256,512): Alpha: 3.115656210624684, Alpha Weighted: 1.5973102800070977, D: 0.10252450956358486\n",
      "2018-11-26 18:42:45,405 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.9049524068832397\n",
      "2018-11-26 18:42:45,408 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:42:47,966 INFO     Weight matrix 7/9 (256,512): Alpha: 2.7417277450789443, Alpha Weighted: 1.0893031544901328, D: 0.09379007935205114\n",
      "2018-11-26 18:42:47,971 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.8766897320747375\n",
      "2018-11-26 18:42:47,975 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:42:50,528 INFO     Weight matrix 8/9 (256,512): Alpha: 1.8605935623604024, Alpha Weighted: 0.8242125406714254, D: 0.12543086141276294\n",
      "2018-11-26 18:42:50,533 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.900371253490448\n",
      "2018-11-26 18:42:50,538 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 18:42:53,078 INFO     Weight matrix 9/9 (256,512): Alpha: 2.78997825142606, Alpha Weighted: 1.1148498637718536, D: 0.08640552216063468\n",
      "2018-11-26 18:42:53,082 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.8750525712966919\n",
      "2018-11-26 18:42:53,086 INFO Layer 19: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 18:42:53,089 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 18:42:53,092 INFO Layer 20: ReLU(inplace)\n",
      "2018-11-26 18:42:53,094 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 18:42:53,098 INFO Layer 21: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:42:53,153 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:42:53,156 INFO Layer 21: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:42:53,159 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:43:00,007 INFO     Weight matrix 1/9 (512,512): Alpha: 3.0293691662799795, Alpha Weighted: 1.6880483255688827, D: 0.053581359820267516\n",
      "2018-11-26 18:43:00,011 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9539146423339844\n",
      "2018-11-26 18:43:00,014 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:43:06,818 INFO     Weight matrix 2/9 (512,512): Alpha: 3.0352890046081606, Alpha Weighted: 1.9228023339381137, D: 0.05115044496221777\n",
      "2018-11-26 18:43:06,822 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9731206893920898\n",
      "2018-11-26 18:43:06,825 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:43:13,696 INFO     Weight matrix 3/9 (512,512): Alpha: 3.0955262281597853, Alpha Weighted: 1.635024574229082, D: 0.05235830271769226\n",
      "2018-11-26 18:43:13,702 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9524585604667664\n",
      "2018-11-26 18:43:13,705 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:43:20,495 INFO     Weight matrix 4/9 (512,512): Alpha: 2.969842913545677, Alpha Weighted: 1.826422265261206, D: 0.04534118855677055\n",
      "2018-11-26 18:43:20,500 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9488738179206848\n",
      "2018-11-26 18:43:20,503 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:43:27,251 INFO     Weight matrix 5/9 (512,512): Alpha: 2.5565835829521504, Alpha Weighted: 2.0543491508983354, D: 0.06418607762692297\n",
      "2018-11-26 18:43:27,256 INFO     Weight matrix 5/9 (512,512): Lognorm: 1.0101155042648315\n",
      "2018-11-26 18:43:27,259 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:43:34,056 INFO     Weight matrix 6/9 (512,512): Alpha: 2.9265569433837575, Alpha Weighted: 1.744485626851562, D: 0.04083240862758997\n",
      "2018-11-26 18:43:34,061 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9482314586639404\n",
      "2018-11-26 18:43:34,063 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:43:41,652 INFO     Weight matrix 7/9 (512,512): Alpha: 2.9748519737523327, Alpha Weighted: 1.5614615580081483, D: 0.05407893227381949\n",
      "2018-11-26 18:43:41,657 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9488359093666077\n",
      "2018-11-26 18:43:41,659 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:43:48,465 INFO     Weight matrix 8/9 (512,512): Alpha: 2.7472579930260705, Alpha Weighted: 1.7068451419174122, D: 0.0629531173862048\n",
      "2018-11-26 18:43:48,471 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9688199758529663\n",
      "2018-11-26 18:43:48,474 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:43:55,444 INFO     Weight matrix 9/9 (512,512): Alpha: 3.0522174651055742, Alpha Weighted: 1.582988729766575, D: 0.05180648639361507\n",
      "2018-11-26 18:43:55,449 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9502391219139099\n",
      "2018-11-26 18:43:55,453 INFO Layer 22: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 18:43:55,456 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 18:43:55,459 INFO Layer 23: ReLU(inplace)\n",
      "2018-11-26 18:43:55,463 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 18:43:55,466 INFO Layer 24: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 18:43:55,469 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 18:43:55,472 INFO Layer 25: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:43:55,505 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:43:55,508 INFO Layer 25: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:43:55,511 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 18:44:02,503 INFO     Weight matrix 1/9 (512,512): Alpha: 3.1242297900358884, Alpha Weighted: 1.8265825604404415, D: 0.04512156557412983\n",
      "2018-11-26 18:44:02,508 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9648700952529907\n",
      "2018-11-26 18:44:02,511 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:44:09,316 INFO     Weight matrix 2/9 (512,512): Alpha: 3.779795966164989, Alpha Weighted: 2.332576526073516, D: 0.05379862954314185\n",
      "2018-11-26 18:44:09,319 INFO     Weight matrix 2/9 (512,512): Alpha 3.779795966164989 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:44:09,326 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9860300421714783\n",
      "2018-11-26 18:44:09,330 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:44:16,766 INFO     Weight matrix 3/9 (512,512): Alpha: 3.2247214906035238, Alpha Weighted: 1.925477036191842, D: 0.05040348653936233\n",
      "2018-11-26 18:44:16,772 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9573399424552917\n",
      "2018-11-26 18:44:16,776 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:44:26,902 INFO     Weight matrix 4/9 (512,512): Alpha: 2.851700133106074, Alpha Weighted: 1.6630587624151343, D: 0.06350649075959991\n",
      "2018-11-26 18:44:26,908 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9474667310714722\n",
      "2018-11-26 18:44:26,911 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:44:34,292 INFO     Weight matrix 5/9 (512,512): Alpha: 4.237682409637152, Alpha Weighted: 3.2802384258113775, D: 0.0833333333333357\n",
      "2018-11-26 18:44:34,295 INFO     Weight matrix 5/9 (512,512): Alpha 4.237682409637152 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:44:34,301 INFO     Weight matrix 5/9 (512,512): Lognorm: 1.0349721908569336\n",
      "2018-11-26 18:44:34,305 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:44:41,277 INFO     Weight matrix 6/9 (512,512): Alpha: 3.144809653135139, Alpha Weighted: 1.8261228608635034, D: 0.061519732835985275\n",
      "2018-11-26 18:44:41,282 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9431076645851135\n",
      "2018-11-26 18:44:41,285 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:44:48,073 INFO     Weight matrix 7/9 (512,512): Alpha: 3.243561933779321, Alpha Weighted: 1.7288896318972926, D: 0.056108627801535804\n",
      "2018-11-26 18:44:48,080 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9533668160438538\n",
      "2018-11-26 18:44:48,083 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:44:54,914 INFO     Weight matrix 8/9 (512,512): Alpha: 3.1156502672960777, Alpha Weighted: 1.7564668694648304, D: 0.06768834313416006\n",
      "2018-11-26 18:44:54,918 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9739605784416199\n",
      "2018-11-26 18:44:54,921 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:45:01,760 INFO     Weight matrix 9/9 (512,512): Alpha: 3.453802494008219, Alpha Weighted: 1.8736739202139003, D: 0.05097980972363621\n",
      "2018-11-26 18:45:01,765 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9512231945991516\n",
      "2018-11-26 18:45:01,770 INFO Layer 26: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 18:45:01,773 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 18:45:01,776 INFO Layer 27: ReLU(inplace)\n",
      "2018-11-26 18:45:01,779 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 18:45:01,782 INFO Layer 28: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 18:45:01,808 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 18:45:01,810 INFO Layer 28: Analyzing 9 weight matrices...\n",
      "2018-11-26 18:45:01,813 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:45:08,610 INFO     Weight matrix 1/9 (512,512): Alpha: 4.214724621371685, Alpha Weighted: 2.077802340663227, D: 0.02891389272857947\n",
      "2018-11-26 18:45:08,612 INFO     Weight matrix 1/9 (512,512): Alpha 4.214724621371685 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:45:08,619 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.928318202495575\n",
      "2018-11-26 18:45:08,622 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:45:15,396 INFO     Weight matrix 2/9 (512,512): Alpha: 3.534355079048777, Alpha Weighted: 3.3412922861611385, D: 0.029151668837946176\n",
      "2018-11-26 18:45:15,399 INFO     Weight matrix 2/9 (512,512): Alpha 3.534355079048777 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:45:15,405 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9594849944114685\n",
      "2018-11-26 18:45:15,408 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:45:22,305 INFO     Weight matrix 3/9 (512,512): Alpha: 4.1385596206462925, Alpha Weighted: 2.271031809308851, D: 0.029396401794459737\n",
      "2018-11-26 18:45:22,308 INFO     Weight matrix 3/9 (512,512): Alpha 4.1385596206462925 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:45:22,313 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9286727905273438\n",
      "2018-11-26 18:45:22,316 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:45:29,122 INFO     Weight matrix 4/9 (512,512): Alpha: 3.8220012891009274, Alpha Weighted: 2.9760308646225564, D: 0.03630540213128597\n",
      "2018-11-26 18:45:29,125 INFO     Weight matrix 4/9 (512,512): Alpha 3.8220012891009274 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:45:29,130 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9315294623374939\n",
      "2018-11-26 18:45:29,133 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:45:35,964 INFO     Weight matrix 5/9 (512,512): Alpha: 3.0441395582219934, Alpha Weighted: 4.068342794170803, D: 0.03042315719971722\n",
      "2018-11-26 18:45:35,969 INFO     Weight matrix 5/9 (512,512): Lognorm: 1.0024770498275757\n",
      "2018-11-26 18:45:35,971 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:45:42,823 INFO     Weight matrix 6/9 (512,512): Alpha: 4.141311823900328, Alpha Weighted: 2.2916542696334106, D: 0.04194696418960164\n",
      "2018-11-26 18:45:42,825 INFO     Weight matrix 6/9 (512,512): Alpha 4.141311823900328 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:45:42,831 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.916519284248352\n",
      "2018-11-26 18:45:42,833 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:45:49,731 INFO     Weight matrix 7/9 (512,512): Alpha: 4.193637200523539, Alpha Weighted: 2.280572132961001, D: 0.05024361268881228\n",
      "2018-11-26 18:45:49,734 INFO     Weight matrix 7/9 (512,512): Alpha 4.193637200523539 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:45:49,740 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9274625182151794\n",
      "2018-11-26 18:45:49,743 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:45:56,580 INFO     Weight matrix 8/9 (512,512): Alpha: 4.020103015814161, Alpha Weighted: 2.685584975715784, D: 0.04514204195680238\n",
      "2018-11-26 18:45:56,582 INFO     Weight matrix 8/9 (512,512): Alpha 4.020103015814161 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:45:56,588 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.939814567565918\n",
      "2018-11-26 18:45:56,591 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 18:46:03,540 INFO     Weight matrix 9/9 (512,512): Alpha: 4.2367454406180824, Alpha Weighted: 2.3160678741949323, D: 0.048156930565705025\n",
      "2018-11-26 18:46:03,542 INFO     Weight matrix 9/9 (512,512): Alpha 4.2367454406180824 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 18:46:03,549 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9211285710334778\n",
      "2018-11-26 18:46:03,551 INFO Layer 29: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 18:46:03,554 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 18:46:03,556 INFO Layer 30: ReLU(inplace)\n",
      "2018-11-26 18:46:03,558 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 18:46:03,560 INFO Layer 31: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 18:46:03,563 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 18:46:03,566 INFO Layer 32: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 18:46:03,570 INFO Layer 32: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 18:46:03,572 INFO Layer 33: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 18:46:06,097 INFO Layer 33: Analyzing 1 weight matrices...\n",
      "2018-11-26 18:46:06,100 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 18:57:33,790 INFO     Weight matrix 1/1 (4096,25088): Alpha: 2.0711253209312703, Alpha Weighted: 2.9148889629022654, D: 0.031060068766342153\n",
      "2018-11-26 18:57:33,825 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.727738857269287\n",
      "2018-11-26 18:57:33,917 INFO Layer 34: ReLU(inplace)\n",
      "2018-11-26 18:57:34,014 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 18:57:34,016 INFO Layer 35: Dropout(p=0.5)\n",
      "2018-11-26 18:57:34,018 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 18:57:34,021 INFO Layer 36: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 18:57:34,127 INFO Layer 36: Analyzing 1 weight matrices...\n",
      "2018-11-26 18:57:34,130 INFO     Weight matrix 1/1 (4096,4096): Analyzing ...\n",
      "2018-11-26 19:02:59,847 INFO     Weight matrix 1/1 (4096,4096): Alpha: 1.9503550671633674, Alpha Weighted: 3.346947789255583, D: 0.033581967076122154\n",
      "2018-11-26 19:02:59,856 INFO     Weight matrix 1/1 (4096,4096): Lognorm: 1.630968689918518\n",
      "2018-11-26 19:02:59,887 INFO Layer 37: ReLU(inplace)\n",
      "2018-11-26 19:02:59,909 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 19:02:59,912 INFO Layer 38: Dropout(p=0.5)\n",
      "2018-11-26 19:02:59,914 INFO Layer 38: Skipping (Layer not supported)\n",
      "2018-11-26 19:02:59,916 INFO Layer 39: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 19:02:59,948 INFO Layer 39: Analyzing 1 weight matrices...\n",
      "2018-11-26 19:02:59,951 INFO     Weight matrix 1/1 (1000,4096): Analyzing ...\n",
      "2018-11-26 19:03:24,519 INFO     Weight matrix 1/1 (1000,4096): Alpha: 2.9947162679826507, Alpha Weighted: 5.329177232276711, D: 0.033901706814122634\n",
      "2018-11-26 19:03:24,524 INFO     Weight matrix 1/1 (1000,4096): Lognorm: 1.625905156135559\n",
      "2018-11-26 19:03:24,549 INFO ### Printing results ###\n",
      "2018-11-26 19:03:24,552 DEBUG Layer 6: Lognorm compound: 0.6529925068219503\n",
      "2018-11-26 19:03:24,556 DEBUG Layer 10: Lognorm compound: 0.7443657716115316\n",
      "2018-11-26 19:03:24,560 DEBUG Layer 13: Lognorm compound: 0.8057086401515536\n",
      "2018-11-26 19:03:24,562 DEBUG Layer 17: Lognorm compound: 0.9025040401352776\n",
      "2018-11-26 19:03:24,566 DEBUG Layer 20: Lognorm compound: 0.961623297797309\n",
      "2018-11-26 19:03:24,568 DEBUG Layer 24: Lognorm compound: 0.9680374728308784\n",
      "2018-11-26 19:03:24,572 DEBUG Layer 27: Lognorm compound: 0.9394897156291537\n",
      "2018-11-26 19:03:24,574 DEBUG Layer 32: Lognorm: 1.727738857269287\n",
      "2018-11-26 19:03:24,578 DEBUG Layer 35: Lognorm: 1.630968689918518\n",
      "2018-11-26 19:03:24,580 DEBUG Layer 38: Lognorm: 1.625905156135559\n",
      "2018-11-26 19:03:24,584 INFO LogNorm: min: 0.5993328094482422, max: 1.727738857269287, avg: 0.8902592062950134\n",
      "2018-11-26 19:03:24,589 INFO LogNorm compound: min: 0.6529925068219503, max: 1.727738857269287, avg: 1.0959334148301019\n",
      "2018-11-26 19:03:24,593 DEBUG Layer 6: Alpha compound: 1.6642464093162848\n",
      "2018-11-26 19:03:24,597 DEBUG Layer 10: Alpha compound: 2.0917126172419542\n",
      "2018-11-26 19:03:24,601 DEBUG Layer 13: Alpha compound: 2.368206780281343\n",
      "2018-11-26 19:03:24,606 DEBUG Layer 17: Alpha compound: 3.028563456334751\n",
      "2018-11-26 19:03:24,608 DEBUG Layer 20: Alpha compound: 2.931943918979277\n",
      "2018-11-26 19:03:24,611 DEBUG Layer 24: Alpha compound: 3.352883793085154\n",
      "2018-11-26 19:03:24,614 DEBUG Layer 27: Alpha compound: 3.9272864054717536\n",
      "2018-11-26 19:03:24,616 DEBUG Layer 32: Alpha: 2.0711253209312703\n",
      "2018-11-26 19:03:24,619 DEBUG Layer 35: Alpha: 1.9503550671633674\n",
      "2018-11-26 19:03:24,621 DEBUG Layer 38: Alpha: 2.9947162679826507\n",
      "2018-11-26 19:03:24,624 INFO Alpha: min: 1.3312675874883295, max: 5.2298727236158875, avg: 2.7469664709465444\n",
      "2018-11-26 19:03:24,627 INFO Alpha compound: min: 1.6642464093162848, max: 3.9272864054717536, avg: 2.6381040036787806\n",
      "2018-11-26 19:03:24,630 DEBUG Layer 6: Alpha Weighted compound: 0.7929485717821129\n",
      "2018-11-26 19:03:24,635 DEBUG Layer 10: Alpha Weighted compound: 1.038946251337494\n",
      "2018-11-26 19:03:24,640 DEBUG Layer 13: Alpha Weighted compound: 0.6444254690319094\n",
      "2018-11-26 19:03:24,645 DEBUG Layer 17: Alpha Weighted compound: 1.4803244908073063\n",
      "2018-11-26 19:03:24,648 DEBUG Layer 20: Alpha Weighted compound: 1.7469364118265909\n",
      "2018-11-26 19:03:24,652 DEBUG Layer 24: Alpha Weighted compound: 2.0236762881524264\n",
      "2018-11-26 19:03:24,654 DEBUG Layer 27: Alpha Weighted compound: 2.700931038603523\n",
      "2018-11-26 19:03:24,660 DEBUG Layer 32: Alpha Weigthed: 2.9148889629022654\n",
      "2018-11-26 19:03:24,662 DEBUG Layer 35: Alpha Weigthed: 3.346947789255583\n",
      "2018-11-26 19:03:24,666 DEBUG Layer 38: Alpha Weigthed: 5.329177232276711\n",
      "2018-11-26 19:03:24,668 INFO Alpha Weighted: min: 0.30176647632390513, max: 5.329177232276711, avg: 1.5976471314894973\n",
      "2018-11-26 19:03:24,671 INFO Alpha Weighted compound: min: 0.6444254690319094, max: 5.329177232276711, avg: 2.201920250597592\n"
     ]
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.vgg11_bn(pretrained=True)\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "results = watcher.analyze(compute_alphas=True)\n",
    "\n",
    "data.append({\"name\": \"vgg11bntorch\", \"summary\": watcher.get_summary()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:25:10.923598Z",
     "start_time": "2018-11-27T03:03:24.920786Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:03:31,591 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 19:03:31,594 INFO Analyzing model\n",
      "2018-11-26 19:03:31,598 INFO Layer 1: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): ReLU(inplace)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): ReLU(inplace)\n",
      "    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 19:03:31,600 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 19:03:31,604 INFO Layer 2: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (16): ReLU(inplace)\n",
      "  (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace)\n",
      "  (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (21): ReLU(inplace)\n",
      "  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (23): ReLU(inplace)\n",
      "  (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 19:03:31,607 INFO Layer 2: Skipping (Layer not supported)\n",
      "2018-11-26 19:03:31,609 INFO Layer 3: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:03:31,612 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:03:31,615 INFO Layer 3: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:03:31,618 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:03:31,621 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:03:31,623 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:03:31,627 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:03:31,630 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:03:31,633 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:03:31,635 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:03:31,638 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:03:31,642 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:03:31,645 INFO Layer 4: ReLU(inplace)\n",
      "2018-11-26 19:03:31,647 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 19:03:31,649 INFO Layer 5: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:03:31,652 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:03:31,654 INFO Layer 5: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:03:31,657 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:03:32,294 INFO     Weight matrix 1/9 (64,64): Alpha: 1.998570664005624, Alpha Weighted: 0.530849783720195, D: 0.18598398449575027\n",
      "2018-11-26 19:03:32,297 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.555422306060791\n",
      "2018-11-26 19:03:32,300 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:03:32,757 INFO     Weight matrix 2/9 (64,64): Alpha: 1.5227656643676322, Alpha Weighted: 0.7031174869890701, D: 0.15918352804560132\n",
      "2018-11-26 19:03:32,762 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.5787814259529114\n",
      "2018-11-26 19:03:32,766 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:03:33,212 INFO     Weight matrix 3/9 (64,64): Alpha: 2.1369657470537424, Alpha Weighted: 0.6382029023227483, D: 0.16491792098667757\n",
      "2018-11-26 19:03:33,215 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.53458172082901\n",
      "2018-11-26 19:03:33,218 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:03:33,669 INFO     Weight matrix 4/9 (64,64): Alpha: 1.4775758885544734, Alpha Weighted: 0.6623070046116852, D: 0.16073584637340266\n",
      "2018-11-26 19:03:33,672 INFO     Weight matrix 4/9 (64,64): Alpha 1.4775758885544734 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:03:33,677 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.5797208547592163\n",
      "2018-11-26 19:03:33,680 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:03:34,133 INFO     Weight matrix 5/9 (64,64): Alpha: 1.5488980269177948, Alpha Weighted: 0.8708143972205923, D: 0.1493816582439298\n",
      "2018-11-26 19:03:34,136 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.626145601272583\n",
      "2018-11-26 19:03:34,138 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:03:34,589 INFO     Weight matrix 6/9 (64,64): Alpha: 1.552251767488616, Alpha Weighted: 0.621202706146811, D: 0.16765244910266897\n",
      "2018-11-26 19:03:34,592 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.5915738940238953\n",
      "2018-11-26 19:03:34,597 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:03:35,030 INFO     Weight matrix 7/9 (64,64): Alpha: 1.4229915864997174, Alpha Weighted: 0.4182557101962185, D: 0.19553249696330566\n",
      "2018-11-26 19:03:35,033 INFO     Weight matrix 7/9 (64,64): Alpha 1.4229915864997174 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:03:35,037 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.5425663590431213\n",
      "2018-11-26 19:03:35,039 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:03:35,491 INFO     Weight matrix 8/9 (64,64): Alpha: 1.4870415637488288, Alpha Weighted: 0.6945968402271283, D: 0.16496928966711832\n",
      "2018-11-26 19:03:35,493 INFO     Weight matrix 8/9 (64,64): Alpha 1.4870415637488288 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:03:35,496 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.5852140784263611\n",
      "2018-11-26 19:03:35,499 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:03:35,946 INFO     Weight matrix 9/9 (64,64): Alpha: 1.4267628978821798, Alpha Weighted: 0.3745428047958965, D: 0.20325877753223764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:03:35,949 INFO     Weight matrix 9/9 (64,64): Alpha 1.4267628978821798 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:03:35,952 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.5504339933395386\n",
      "2018-11-26 19:03:35,956 INFO Layer 6: ReLU(inplace)\n",
      "2018-11-26 19:03:35,960 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 19:03:35,962 INFO Layer 7: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:03:35,964 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 19:03:35,967 INFO Layer 8: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:03:35,972 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:03:35,974 INFO Layer 8: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:03:35,977 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:03:36,445 INFO     Weight matrix 1/9 (64,128): Alpha: 1.8107391581066166, Alpha Weighted: 0.7929710955117995, D: 0.14500309931430655\n",
      "2018-11-26 19:03:36,455 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.6680006384849548\n",
      "2018-11-26 19:03:36,458 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:03:36,890 INFO     Weight matrix 2/9 (64,128): Alpha: 1.7729935906609484, Alpha Weighted: 1.044640883996178, D: 0.1453438269649604\n",
      "2018-11-26 19:03:36,894 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.7057045102119446\n",
      "2018-11-26 19:03:36,897 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:03:37,342 INFO     Weight matrix 3/9 (64,128): Alpha: 1.811471779196968, Alpha Weighted: 0.805938165828245, D: 0.15762444780382928\n",
      "2018-11-26 19:03:37,345 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.6612639427185059\n",
      "2018-11-26 19:03:37,347 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:03:37,791 INFO     Weight matrix 4/9 (64,128): Alpha: 1.7804243850511114, Alpha Weighted: 0.9158584845391363, D: 0.155751260135927\n",
      "2018-11-26 19:03:37,796 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.6933040618896484\n",
      "2018-11-26 19:03:37,799 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:03:38,249 INFO     Weight matrix 5/9 (64,128): Alpha: 1.7223669803109436, Alpha Weighted: 1.2801292605605652, D: 0.14315049564268978\n",
      "2018-11-26 19:03:38,254 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.7414924502372742\n",
      "2018-11-26 19:03:38,256 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:03:38,707 INFO     Weight matrix 6/9 (64,128): Alpha: 1.7330246689158657, Alpha Weighted: 0.9110644503633423, D: 0.14202299140443875\n",
      "2018-11-26 19:03:38,710 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.6887338161468506\n",
      "2018-11-26 19:03:38,715 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:03:39,159 INFO     Weight matrix 7/9 (64,128): Alpha: 1.812909550734491, Alpha Weighted: 1.0364915677262332, D: 0.1380979955484541\n",
      "2018-11-26 19:03:39,164 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.6727420091629028\n",
      "2018-11-26 19:03:39,167 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:03:39,611 INFO     Weight matrix 8/9 (64,128): Alpha: 1.7591478629806345, Alpha Weighted: 0.9669425938617835, D: 0.13934794038801884\n",
      "2018-11-26 19:03:39,617 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.6912813782691956\n",
      "2018-11-26 19:03:39,621 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:03:40,067 INFO     Weight matrix 9/9 (64,128): Alpha: 1.8891456168166523, Alpha Weighted: 0.8229428761873807, D: 0.16650142557586867\n",
      "2018-11-26 19:03:40,071 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.6467894315719604\n",
      "2018-11-26 19:03:40,074 INFO Layer 9: ReLU(inplace)\n",
      "2018-11-26 19:03:40,077 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 19:03:40,081 INFO Layer 10: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:03:40,088 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:03:40,090 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:03:40,092 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:03:41,107 INFO     Weight matrix 1/9 (128,128): Alpha: 1.857021824240698, Alpha Weighted: 0.425034828817708, D: 0.15544370594369072\n",
      "2018-11-26 19:03:41,111 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.7174193859100342\n",
      "2018-11-26 19:03:41,116 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:03:42,137 INFO     Weight matrix 2/9 (128,128): Alpha: 1.9010924680505537, Alpha Weighted: 0.6002309722302438, D: 0.1509027468748837\n",
      "2018-11-26 19:03:42,143 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.7336912751197815\n",
      "2018-11-26 19:03:42,146 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:03:43,137 INFO     Weight matrix 3/9 (128,128): Alpha: 3.6536136233634573, Alpha Weighted: 1.0583687919406108, D: 0.15350961810128722\n",
      "2018-11-26 19:03:43,139 INFO     Weight matrix 3/9 (128,128): Alpha 3.6536136233634573 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:03:43,145 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.7086058855056763\n",
      "2018-11-26 19:03:43,149 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:03:44,145 INFO     Weight matrix 4/9 (128,128): Alpha: 1.726248752520473, Alpha Weighted: 0.42188705731147536, D: 0.17243243344900272\n",
      "2018-11-26 19:03:44,148 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.7316402196884155\n",
      "2018-11-26 19:03:44,151 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:03:45,139 INFO     Weight matrix 5/9 (128,128): Alpha: 4.822057822997586, Alpha Weighted: 2.2655184285306964, D: 0.14172972976977982\n",
      "2018-11-26 19:03:45,141 INFO     Weight matrix 5/9 (128,128): Alpha 4.822057822997586 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:03:45,147 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.7713156938552856\n",
      "2018-11-26 19:03:45,151 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:03:46,142 INFO     Weight matrix 6/9 (128,128): Alpha: 2.0045945509134526, Alpha Weighted: 0.5872486110176838, D: 0.16553413858855975\n",
      "2018-11-26 19:03:46,145 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.7348038554191589\n",
      "2018-11-26 19:03:46,148 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:03:47,152 INFO     Weight matrix 7/9 (128,128): Alpha: 1.9531349944986998, Alpha Weighted: 0.509380582994308, D: 0.1566485100885634\n",
      "2018-11-26 19:03:47,156 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.7069422006607056\n",
      "2018-11-26 19:03:47,160 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:03:48,166 INFO     Weight matrix 8/9 (128,128): Alpha: 1.9591050122513294, Alpha Weighted: 0.43972489976150203, D: 0.1639783601965067\n",
      "2018-11-26 19:03:48,169 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.7316706776618958\n",
      "2018-11-26 19:03:48,174 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:03:49,186 INFO     Weight matrix 9/9 (128,128): Alpha: 1.8342968770764423, Alpha Weighted: 0.4627399558526968, D: 0.163558750872412\n",
      "2018-11-26 19:03:49,189 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.7158021926879883\n",
      "2018-11-26 19:03:49,191 INFO Layer 11: ReLU(inplace)\n",
      "2018-11-26 19:03:49,194 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 19:03:49,196 INFO Layer 12: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:03:49,200 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 19:03:49,203 INFO Layer 13: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:03:49,216 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:03:49,219 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:03:49,221 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:03:50,249 INFO     Weight matrix 1/9 (128,256): Alpha: 2.5156248867302464, Alpha Weighted: 1.0518307454393476, D: 0.10143106752935549\n",
      "2018-11-26 19:03:50,253 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.767629086971283\n",
      "2018-11-26 19:03:50,255 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:03:51,258 INFO     Weight matrix 2/9 (128,256): Alpha: 2.4514543446591115, Alpha Weighted: 1.3212487891031406, D: 0.1168162632430787\n",
      "2018-11-26 19:03:51,263 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.8146148920059204\n",
      "2018-11-26 19:03:51,266 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:03:52,272 INFO     Weight matrix 3/9 (128,256): Alpha: 3.0291402205796247, Alpha Weighted: 1.185343531539956, D: 0.1295865824051723\n",
      "2018-11-26 19:03:52,276 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.7666121125221252\n",
      "2018-11-26 19:03:52,280 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:03:53,286 INFO     Weight matrix 4/9 (128,256): Alpha: 2.839263050930465, Alpha Weighted: 1.5765674557968563, D: 0.10860353360842062\n",
      "2018-11-26 19:03:53,289 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.814735472202301\n",
      "2018-11-26 19:03:53,293 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:03:54,296 INFO     Weight matrix 5/9 (128,256): Alpha: 4.882613555143458, Alpha Weighted: 3.6244372535271627, D: 0.14285714285714257\n",
      "2018-11-26 19:03:54,298 INFO     Weight matrix 5/9 (128,256): Alpha 4.882613555143458 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:03:54,303 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.8988584280014038\n",
      "2018-11-26 19:03:54,308 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:03:55,345 INFO     Weight matrix 6/9 (128,256): Alpha: 2.6335163253046927, Alpha Weighted: 1.3063939958172333, D: 0.10870746680877441\n",
      "2018-11-26 19:03:55,350 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.8094183802604675\n",
      "2018-11-26 19:03:55,354 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:03:56,346 INFO     Weight matrix 7/9 (128,256): Alpha: 2.6176190774645054, Alpha Weighted: 0.9261299306873547, D: 0.11393675945220083\n",
      "2018-11-26 19:03:56,350 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.7631824016571045\n",
      "2018-11-26 19:03:56,352 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:03:57,361 INFO     Weight matrix 8/9 (128,256): Alpha: 2.5869481342025766, Alpha Weighted: 1.432440905112883, D: 0.13113951746313557\n",
      "2018-11-26 19:03:57,364 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.8044846057891846\n",
      "2018-11-26 19:03:57,367 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:03:58,380 INFO     Weight matrix 9/9 (128,256): Alpha: 3.147342412427119, Alpha Weighted: 1.1551266722874272, D: 0.11083793021614208\n",
      "2018-11-26 19:03:58,383 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.7636407613754272\n",
      "2018-11-26 19:03:58,386 INFO Layer 14: ReLU(inplace)\n",
      "2018-11-26 19:03:58,389 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 19:03:58,397 INFO Layer 15: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:03:58,403 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:03:58,406 INFO Layer 15: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:03:58,409 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:04:00,935 INFO     Weight matrix 1/9 (256,256): Alpha: 2.4906046251345, Alpha Weighted: 0.8338415997824618, D: 0.11926825491193044\n",
      "2018-11-26 19:04:00,938 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.8347761034965515\n",
      "2018-11-26 19:04:00,941 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:04:03,413 INFO     Weight matrix 2/9 (256,256): Alpha: 2.7464403040382743, Alpha Weighted: 1.3198179882559176, D: 0.09733453678389647\n",
      "2018-11-26 19:04:03,418 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.8510901927947998\n",
      "2018-11-26 19:04:03,421 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:04:05,872 INFO     Weight matrix 3/9 (256,256): Alpha: 3.072085929988806, Alpha Weighted: 1.0791197839053435, D: 0.09978870899758263\n",
      "2018-11-26 19:04:05,876 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.8321912288665771\n",
      "2018-11-26 19:04:05,879 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:04:08,339 INFO     Weight matrix 4/9 (256,256): Alpha: 3.0443380554167154, Alpha Weighted: 1.5885945147063367, D: 0.09122426156495661\n",
      "2018-11-26 19:04:08,344 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.8481708765029907\n",
      "2018-11-26 19:04:08,347 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:04:10,785 INFO     Weight matrix 5/9 (256,256): Alpha: 3.4238350142256535, Alpha Weighted: 2.4744267880806934, D: 0.0695713823413896\n",
      "2018-11-26 19:04:10,789 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.9025205969810486\n",
      "2018-11-26 19:04:10,793 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:04:13,235 INFO     Weight matrix 6/9 (256,256): Alpha: 3.193372791081828, Alpha Weighted: 1.5467966075750401, D: 0.08670600754625446\n",
      "2018-11-26 19:04:13,240 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.8415446281433105\n",
      "2018-11-26 19:04:13,244 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:04:15,706 INFO     Weight matrix 7/9 (256,256): Alpha: 2.579755863321081, Alpha Weighted: 0.8874102145279272, D: 0.1090272209363119\n",
      "2018-11-26 19:04:15,710 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.8381807804107666\n",
      "2018-11-26 19:04:15,713 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:04:18,156 INFO     Weight matrix 8/9 (256,256): Alpha: 3.0865112217989927, Alpha Weighted: 1.5002501371223573, D: 0.10738557243873847\n",
      "2018-11-26 19:04:18,162 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.8552940487861633\n",
      "2018-11-26 19:04:18,166 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:04:20,625 INFO     Weight matrix 9/9 (256,256): Alpha: 2.755471004041125, Alpha Weighted: 1.0248423392573844, D: 0.09561998405218597\n",
      "2018-11-26 19:04:20,630 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.835618257522583\n",
      "2018-11-26 19:04:20,632 INFO Layer 16: ReLU(inplace)\n",
      "2018-11-26 19:04:20,635 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 19:04:20,638 INFO Layer 17: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:04:20,640 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 19:04:20,643 INFO Layer 18: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:04:20,665 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:04:20,668 INFO Layer 18: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:04:20,673 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:04:23,206 INFO     Weight matrix 1/9 (256,512): Alpha: 2.339917930309967, Alpha Weighted: 1.009131880796214, D: 0.11919398522401647\n",
      "2018-11-26 19:04:23,210 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.916579008102417\n",
      "2018-11-26 19:04:23,213 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:04:25,728 INFO     Weight matrix 2/9 (256,512): Alpha: 2.032216579380863, Alpha Weighted: 1.0873141729533315, D: 0.11662816432166045\n",
      "2018-11-26 19:04:25,733 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.9380613565444946\n",
      "2018-11-26 19:04:25,735 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:04:28,251 INFO     Weight matrix 3/9 (256,512): Alpha: 2.7086153301028544, Alpha Weighted: 1.2600772536026814, D: 0.1019246621822858\n",
      "2018-11-26 19:04:28,256 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.9178951382637024\n",
      "2018-11-26 19:04:28,259 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:04:30,794 INFO     Weight matrix 4/9 (256,512): Alpha: 2.174964020570722, Alpha Weighted: 1.161320290849224, D: 0.11920918316382945\n",
      "2018-11-26 19:04:30,798 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.9282858967781067\n",
      "2018-11-26 19:04:30,803 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:04:33,320 INFO     Weight matrix 5/9 (256,512): Alpha: 3.9444760346696213, Alpha Weighted: 3.0363939658899466, D: 0.07692307692307654\n",
      "2018-11-26 19:04:33,324 INFO     Weight matrix 5/9 (256,512): Alpha 3.9444760346696213 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:04:33,328 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.980600893497467\n",
      "2018-11-26 19:04:33,333 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:04:35,838 INFO     Weight matrix 6/9 (256,512): Alpha: 3.02538715817979, Alpha Weighted: 1.620448234078988, D: 0.10638341952272412\n",
      "2018-11-26 19:04:35,843 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.9300090670585632\n",
      "2018-11-26 19:04:35,846 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:04:38,361 INFO     Weight matrix 7/9 (256,512): Alpha: 2.300735751499256, Alpha Weighted: 0.9941742434462486, D: 0.11341556343066883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:04:38,365 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.912216305732727\n",
      "2018-11-26 19:04:38,368 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:04:40,881 INFO     Weight matrix 8/9 (256,512): Alpha: 1.99463932524016, Alpha Weighted: 1.0130028875335417, D: 0.11187604704230997\n",
      "2018-11-26 19:04:40,886 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.9304941892623901\n",
      "2018-11-26 19:04:40,888 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:04:43,476 INFO     Weight matrix 9/9 (256,512): Alpha: 2.9786914525067956, Alpha Weighted: 1.2181638356411233, D: 0.11800487808964932\n",
      "2018-11-26 19:04:43,481 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.9159024953842163\n",
      "2018-11-26 19:04:43,484 INFO Layer 19: ReLU(inplace)\n",
      "2018-11-26 19:04:43,486 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 19:04:43,489 INFO Layer 20: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:04:43,530 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:04:43,534 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:04:43,538 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:04:50,379 INFO     Weight matrix 1/9 (512,512): Alpha: 3.1574253594106056, Alpha Weighted: 1.9596712725157928, D: 0.050044028846678024\n",
      "2018-11-26 19:04:50,385 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9726711511611938\n",
      "2018-11-26 19:04:50,387 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:04:57,137 INFO     Weight matrix 2/9 (512,512): Alpha: 3.2358628450124893, Alpha Weighted: 2.5448675711163093, D: 0.05400369384466541\n",
      "2018-11-26 19:04:57,144 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9830425977706909\n",
      "2018-11-26 19:04:57,146 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:05:04,013 INFO     Weight matrix 3/9 (512,512): Alpha: 3.1313311051938024, Alpha Weighted: 2.0400351101536427, D: 0.057331288030629146\n",
      "2018-11-26 19:05:04,019 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9723473787307739\n",
      "2018-11-26 19:05:04,022 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:05:10,814 INFO     Weight matrix 4/9 (512,512): Alpha: 3.281372338156815, Alpha Weighted: 2.531530616805721, D: 0.04870571973965976\n",
      "2018-11-26 19:05:10,820 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9659870266914368\n",
      "2018-11-26 19:05:10,822 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:05:17,572 INFO     Weight matrix 5/9 (512,512): Alpha: 2.4800022955675987, Alpha Weighted: 2.3742321581050447, D: 0.05283513392870548\n",
      "2018-11-26 19:05:17,578 INFO     Weight matrix 5/9 (512,512): Lognorm: 1.0074034929275513\n",
      "2018-11-26 19:05:17,580 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:05:24,647 INFO     Weight matrix 6/9 (512,512): Alpha: 3.4296636575022426, Alpha Weighted: 2.6592319455855478, D: 0.059154428057884734\n",
      "2018-11-26 19:05:24,653 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9684156179428101\n",
      "2018-11-26 19:05:24,656 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:05:31,517 INFO     Weight matrix 7/9 (512,512): Alpha: 3.1932026148577344, Alpha Weighted: 1.883564833443438, D: 0.05601894755580483\n",
      "2018-11-26 19:05:31,523 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9694008231163025\n",
      "2018-11-26 19:05:31,525 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:05:38,299 INFO     Weight matrix 8/9 (512,512): Alpha: 3.496983590863533, Alpha Weighted: 2.705354195612984, D: 0.05143901556148148\n",
      "2018-11-26 19:05:38,306 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9819566607475281\n",
      "2018-11-26 19:05:38,309 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:05:45,105 INFO     Weight matrix 9/9 (512,512): Alpha: 3.1909101247012703, Alpha Weighted: 2.0102218210258775, D: 0.06184968495577309\n",
      "2018-11-26 19:05:45,110 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9707570672035217\n",
      "2018-11-26 19:05:45,114 INFO Layer 21: ReLU(inplace)\n",
      "2018-11-26 19:05:45,116 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 19:05:45,119 INFO Layer 22: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:05:45,121 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 19:05:45,124 INFO Layer 23: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:05:45,158 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:05:45,160 INFO Layer 23: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:05:45,166 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:05:51,899 INFO     Weight matrix 1/9 (512,512): Alpha: 3.196733739836226, Alpha Weighted: 1.7552681330202178, D: 0.05404477229713711\n",
      "2018-11-26 19:05:51,904 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9932413101196289\n",
      "2018-11-26 19:05:51,906 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:05:58,700 INFO     Weight matrix 2/9 (512,512): Alpha: 3.5868737023586177, Alpha Weighted: 2.14683567652037, D: 0.08012751452133982\n",
      "2018-11-26 19:05:58,703 INFO     Weight matrix 2/9 (512,512): Alpha 3.5868737023586177 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:05:58,712 INFO     Weight matrix 2/9 (512,512): Lognorm: 1.0082613229751587\n",
      "2018-11-26 19:05:58,716 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:06:05,525 INFO     Weight matrix 3/9 (512,512): Alpha: 3.0779280608493913, Alpha Weighted: 1.5116604063006436, D: 0.06272098692759698\n",
      "2018-11-26 19:06:05,530 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9908903241157532\n",
      "2018-11-26 19:06:05,533 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:06:12,316 INFO     Weight matrix 4/9 (512,512): Alpha: 3.787069271709847, Alpha Weighted: 2.4100673496858604, D: 0.0587585396603828\n",
      "2018-11-26 19:06:12,319 INFO     Weight matrix 4/9 (512,512): Alpha 3.787069271709847 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:06:12,326 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9824333190917969\n",
      "2018-11-26 19:06:12,331 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:06:19,100 INFO     Weight matrix 5/9 (512,512): Alpha: 2.319693639785208, Alpha Weighted: 1.867079771142883, D: 0.0818171542155135\n",
      "2018-11-26 19:06:19,105 INFO     Weight matrix 5/9 (512,512): Lognorm: 1.0340931415557861\n",
      "2018-11-26 19:06:19,108 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:06:25,983 INFO     Weight matrix 6/9 (512,512): Alpha: 3.1356612634987844, Alpha Weighted: 1.9764205185284478, D: 0.06750604937958321\n",
      "2018-11-26 19:06:25,988 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.978428065776825\n",
      "2018-11-26 19:06:25,991 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:06:32,764 INFO     Weight matrix 7/9 (512,512): Alpha: 2.8788719645761622, Alpha Weighted: 1.4185083608758213, D: 0.0726446575371571\n",
      "2018-11-26 19:06:32,769 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9884415864944458\n",
      "2018-11-26 19:06:32,772 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:06:39,558 INFO     Weight matrix 8/9 (512,512): Alpha: 3.083953785768405, Alpha Weighted: 1.7792873625746028, D: 0.06842043059169217\n",
      "2018-11-26 19:06:39,566 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9988676309585571\n",
      "2018-11-26 19:06:39,570 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:06:46,411 INFO     Weight matrix 9/9 (512,512): Alpha: 3.1636280930768503, Alpha Weighted: 1.4732429602904558, D: 0.07122945133543168\n",
      "2018-11-26 19:06:46,416 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9857199788093567\n",
      "2018-11-26 19:06:46,420 INFO Layer 24: ReLU(inplace)\n",
      "2018-11-26 19:06:46,423 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 19:06:46,425 INFO Layer 25: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:06:46,447 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:06:46,450 INFO Layer 25: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:06:46,452 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:06:53,267 INFO     Weight matrix 1/9 (512,512): Alpha: 3.746898109358497, Alpha Weighted: 3.2115992895495378, D: 0.03318221862300841\n",
      "2018-11-26 19:06:53,270 INFO     Weight matrix 1/9 (512,512): Alpha 3.746898109358497 is in the danger zone (1.5,3.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:06:53,275 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9672555327415466\n",
      "2018-11-26 19:06:53,278 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:07:00,097 INFO     Weight matrix 2/9 (512,512): Alpha: 3.7153286971936295, Alpha Weighted: 3.584336534947725, D: 0.03767292731170885\n",
      "2018-11-26 19:07:00,100 INFO     Weight matrix 2/9 (512,512): Alpha 3.7153286971936295 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:07:00,106 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9875938892364502\n",
      "2018-11-26 19:07:00,109 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:07:06,938 INFO     Weight matrix 3/9 (512,512): Alpha: 3.792769604079513, Alpha Weighted: 3.1733260891374964, D: 0.05495193274179738\n",
      "2018-11-26 19:07:06,940 INFO     Weight matrix 3/9 (512,512): Alpha 3.792769604079513 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:07:06,947 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9652755856513977\n",
      "2018-11-26 19:07:06,950 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:07:13,745 INFO     Weight matrix 4/9 (512,512): Alpha: 3.5677502484381334, Alpha Weighted: 3.301719060886122, D: 0.03672893623488621\n",
      "2018-11-26 19:07:13,747 INFO     Weight matrix 4/9 (512,512): Alpha 3.5677502484381334 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:07:13,754 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9651980400085449\n",
      "2018-11-26 19:07:13,756 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:07:20,548 INFO     Weight matrix 5/9 (512,512): Alpha: 3.356121834129881, Alpha Weighted: 3.4856728303563425, D: 0.0554478793067531\n",
      "2018-11-26 19:07:20,553 INFO     Weight matrix 5/9 (512,512): Lognorm: 1.0066924095153809\n",
      "2018-11-26 19:07:20,556 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:07:27,343 INFO     Weight matrix 6/9 (512,512): Alpha: 3.6291944874989768, Alpha Weighted: 3.2481839415696476, D: 0.0335045880489282\n",
      "2018-11-26 19:07:27,345 INFO     Weight matrix 6/9 (512,512): Alpha 3.6291944874989768 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:07:27,352 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.961090624332428\n",
      "2018-11-26 19:07:27,355 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:07:34,298 INFO     Weight matrix 7/9 (512,512): Alpha: 3.7556019418021256, Alpha Weighted: 3.1718675417434925, D: 0.03545482701274405\n",
      "2018-11-26 19:07:34,300 INFO     Weight matrix 7/9 (512,512): Alpha 3.7556019418021256 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:07:34,306 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9657158255577087\n",
      "2018-11-26 19:07:34,309 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:07:41,094 INFO     Weight matrix 8/9 (512,512): Alpha: 3.5600657464589944, Alpha Weighted: 3.402794859057395, D: 0.02702702702702775\n",
      "2018-11-26 19:07:41,097 INFO     Weight matrix 8/9 (512,512): Alpha 3.5600657464589944 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:07:41,102 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.98719322681427\n",
      "2018-11-26 19:07:41,105 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:07:47,916 INFO     Weight matrix 9/9 (512,512): Alpha: 3.764431036029029, Alpha Weighted: 3.1703166893208596, D: 0.043015348008528465\n",
      "2018-11-26 19:07:47,918 INFO     Weight matrix 9/9 (512,512): Alpha 3.764431036029029 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:07:47,924 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9637725353240967\n",
      "2018-11-26 19:07:47,927 INFO Layer 26: ReLU(inplace)\n",
      "2018-11-26 19:07:47,930 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 19:07:47,932 INFO Layer 27: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:07:47,935 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 19:07:47,937 INFO Layer 28: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 19:07:47,939 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 19:07:47,941 INFO Layer 29: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 19:07:50,006 INFO Layer 29: Analyzing 1 weight matrices...\n",
      "2018-11-26 19:07:50,009 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 19:19:05,941 INFO     Weight matrix 1/1 (4096,25088): Alpha: 2.3381179186205445, Alpha Weighted: 3.6368449398863656, D: 0.032738671140593145\n",
      "2018-11-26 19:19:05,978 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.7561616897583008\n",
      "2018-11-26 19:19:06,078 INFO Layer 30: ReLU(inplace)\n",
      "2018-11-26 19:19:06,165 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 19:19:06,168 INFO Layer 31: Dropout(p=0.5)\n",
      "2018-11-26 19:19:06,170 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 19:19:06,173 INFO Layer 32: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 19:19:06,282 INFO Layer 32: Analyzing 1 weight matrices...\n",
      "2018-11-26 19:19:06,285 INFO     Weight matrix 1/1 (4096,4096): Analyzing ...\n",
      "2018-11-26 19:24:45,661 INFO     Weight matrix 1/1 (4096,4096): Alpha: 2.186125045615918, Alpha Weighted: 3.8836099385354177, D: 0.030526520259220424\n",
      "2018-11-26 19:24:45,671 INFO     Weight matrix 1/1 (4096,4096): Lognorm: 1.6374969482421875\n",
      "2018-11-26 19:24:45,694 INFO Layer 33: ReLU(inplace)\n",
      "2018-11-26 19:24:45,718 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 19:24:45,721 INFO Layer 34: Dropout(p=0.5)\n",
      "2018-11-26 19:24:45,723 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 19:24:45,726 INFO Layer 35: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 19:24:45,758 INFO Layer 35: Analyzing 1 weight matrices...\n",
      "2018-11-26 19:24:45,761 INFO     Weight matrix 1/1 (1000,4096): Analyzing ...\n",
      "2018-11-26 19:25:10,543 INFO     Weight matrix 1/1 (1000,4096): Alpha: 2.7221354270741758, Alpha Weighted: 4.799174762674009, D: 0.036928045208094784\n",
      "2018-11-26 19:25:10,551 INFO     Weight matrix 1/1 (1000,4096): Lognorm: 1.5858654975891113\n",
      "2018-11-26 19:25:10,575 INFO ### Printing results ###\n",
      "2018-11-26 19:25:10,578 DEBUG Layer 4: Lognorm compound: 0.5716044704119364\n",
      "2018-11-26 19:25:10,581 DEBUG Layer 7: Lognorm compound: 0.685479137632582\n",
      "2018-11-26 19:25:10,584 DEBUG Layer 9: Lognorm compound: 0.7279879318343269\n",
      "2018-11-26 19:25:10,587 DEBUG Layer 12: Lognorm compound: 0.8003529045316908\n",
      "2018-11-26 19:25:10,589 DEBUG Layer 14: Lognorm compound: 0.8488207459449768\n",
      "2018-11-26 19:25:10,592 DEBUG Layer 17: Lognorm compound: 0.9300049278471205\n",
      "2018-11-26 19:25:10,594 DEBUG Layer 19: Lognorm compound: 0.9768868684768677\n",
      "2018-11-26 19:25:10,597 DEBUG Layer 22: Lognorm compound: 0.9955974088774787\n",
      "2018-11-26 19:25:10,602 DEBUG Layer 24: Lognorm compound: 0.9744208521313138\n",
      "2018-11-26 19:25:10,606 DEBUG Layer 28: Lognorm: 1.7561616897583008\n",
      "2018-11-26 19:25:10,608 DEBUG Layer 31: Lognorm: 1.6374969482421875\n",
      "2018-11-26 19:25:10,611 DEBUG Layer 34: Lognorm: 1.5858654975891113\n",
      "2018-11-26 19:25:10,613 INFO LogNorm: min: 0.53458172082901, max: 1.7561616897583008, avg: 0.8640468120574951\n",
      "2018-11-26 19:25:10,616 INFO LogNorm compound: min: 0.5716044704119364, max: 1.7561616897583008, avg: 1.040889948606491\n",
      "2018-11-26 19:25:10,620 DEBUG Layer 4: Alpha compound: 1.6193137562798454\n",
      "2018-11-26 19:25:10,623 DEBUG Layer 7: Alpha compound: 1.7880248436415813\n",
      "2018-11-26 19:25:10,625 DEBUG Layer 9: Alpha compound: 2.4123517695458547\n",
      "2018-11-26 19:25:10,628 DEBUG Layer 12: Alpha compound: 2.9670580008268663\n",
      "2018-11-26 19:25:10,630 DEBUG Layer 14: Alpha compound: 2.9324905343385534\n",
      "2018-11-26 19:25:10,633 DEBUG Layer 17: Alpha compound: 2.6110715091622256\n",
      "2018-11-26 19:25:10,635 DEBUG Layer 19: Alpha compound: 3.1774171034740104\n",
      "2018-11-26 19:25:10,641 DEBUG Layer 22: Alpha compound: 3.136712613495499\n",
      "2018-11-26 19:25:10,643 DEBUG Layer 24: Alpha compound: 3.654240189443198\n",
      "2018-11-26 19:25:10,645 DEBUG Layer 28: Alpha: 2.3381179186205445\n",
      "2018-11-26 19:25:10,647 DEBUG Layer 31: Alpha: 2.186125045615918\n",
      "2018-11-26 19:25:10,649 DEBUG Layer 34: Alpha: 2.7221354270741758\n",
      "2018-11-26 19:25:10,652 INFO Alpha: min: 1.4229915864997174, max: 4.882613555143458, avg: 2.6896964437283257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:25:10,655 INFO Alpha compound: min: 1.6193137562798454, max: 3.654240189443198, avg: 2.6287548926265223\n",
      "2018-11-26 19:25:10,657 DEBUG Layer 4: Alpha Weighted compound: 0.6126544040255939\n",
      "2018-11-26 19:25:10,660 DEBUG Layer 7: Alpha Weighted compound: 0.9529977087305181\n",
      "2018-11-26 19:25:10,662 DEBUG Layer 9: Alpha Weighted compound: 0.7522371253841027\n",
      "2018-11-26 19:25:10,664 DEBUG Layer 12: Alpha Weighted compound: 1.5088354754790398\n",
      "2018-11-26 19:25:10,667 DEBUG Layer 14: Alpha Weighted compound: 1.3616777748014957\n",
      "2018-11-26 19:25:10,673 DEBUG Layer 17: Alpha Weighted compound: 1.377780751643478\n",
      "2018-11-26 19:25:10,675 DEBUG Layer 19: Alpha Weighted compound: 2.3009677249293734\n",
      "2018-11-26 19:25:10,678 DEBUG Layer 22: Alpha Weighted compound: 1.815374504326589\n",
      "2018-11-26 19:25:10,681 DEBUG Layer 24: Alpha Weighted compound: 3.3055352040631796\n",
      "2018-11-26 19:25:10,684 DEBUG Layer 28: Alpha Weigthed: 3.6368449398863656\n",
      "2018-11-26 19:25:10,686 DEBUG Layer 31: Alpha Weigthed: 3.8836099385354177\n",
      "2018-11-26 19:25:10,690 DEBUG Layer 34: Alpha Weigthed: 4.799174762674009\n",
      "2018-11-26 19:25:10,694 INFO Alpha Weighted: min: 0.3745428047958965, max: 4.799174762674009, avg: 1.6453830440660253\n",
      "2018-11-26 19:25:10,696 INFO Alpha Weighted compound: min: 0.6126544040255939, max: 4.799174762674009, avg: 2.192307526206597\n"
     ]
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.vgg13(pretrained=True)\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "results = watcher.analyze(compute_alphas=True)\n",
    "\n",
    "data.append({\"name\": \"vgg13torch\", \"summary\": watcher.get_summary()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:46:39.123171Z",
     "start_time": "2018-11-27T03:25:10.929984Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:25:17,583 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 19:25:17,586 INFO Analyzing model\n",
      "2018-11-26 19:25:17,589 INFO Layer 1: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (23): ReLU(inplace)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): ReLU(inplace)\n",
      "    (31): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (33): ReLU(inplace)\n",
      "    (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 19:25:17,592 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:17,595 INFO Layer 2: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace)\n",
      "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace)\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU(inplace)\n",
      "  (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU(inplace)\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (16): ReLU(inplace)\n",
      "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (19): ReLU(inplace)\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (23): ReLU(inplace)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (26): ReLU(inplace)\n",
      "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (30): ReLU(inplace)\n",
      "  (31): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (33): ReLU(inplace)\n",
      "  (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 19:25:17,597 INFO Layer 2: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:17,599 INFO Layer 3: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:25:17,602 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:25:17,604 INFO Layer 3: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:25:17,608 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:25:17,611 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:25:17,614 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:25:17,617 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:25:17,752 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:25:17,755 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:25:17,757 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:25:17,759 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:25:17,762 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:25:17,765 INFO Layer 4: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 19:25:17,767 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:17,770 INFO Layer 5: ReLU(inplace)\n",
      "2018-11-26 19:25:17,773 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:17,775 INFO Layer 6: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:25:17,779 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:25:17,781 INFO Layer 6: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:25:17,784 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:25:18,287 INFO     Weight matrix 1/9 (64,64): Alpha: 1.5857116107935703, Alpha Weighted: 0.14409320123545785, D: 0.21408412654279574\n",
      "2018-11-26 19:25:18,290 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.3236437141895294\n",
      "2018-11-26 19:25:18,293 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:25:18,621 INFO     Weight matrix 2/9 (64,64): Alpha: 2.302359162359691, Alpha Weighted: 0.708629497779994, D: 0.23375388623241322\n",
      "2018-11-26 19:25:18,623 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.42646071314811707\n",
      "2018-11-26 19:25:18,626 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:25:18,945 INFO     Weight matrix 3/9 (64,64): Alpha: 1.539537263296173, Alpha Weighted: 0.09612662556461819, D: 0.23468191132558736\n",
      "2018-11-26 19:25:18,949 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.34800300002098083\n",
      "2018-11-26 19:25:18,951 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:25:19,273 INFO     Weight matrix 4/9 (64,64): Alpha: 3.142630549986738, Alpha Weighted: 0.631012075396832, D: 0.21102727039678454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:25:19,276 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.3956087827682495\n",
      "2018-11-26 19:25:19,279 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:25:19,578 INFO     Weight matrix 5/9 (64,64): Alpha: 3.798671263192149, Alpha Weighted: 1.6685441343673661, D: 0.2000000000000005\n",
      "2018-11-26 19:25:19,581 INFO     Weight matrix 5/9 (64,64): Alpha 3.798671263192149 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:25:19,583 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.4901217222213745\n",
      "2018-11-26 19:25:19,586 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:25:19,914 INFO     Weight matrix 6/9 (64,64): Alpha: 3.6086532275323564, Alpha Weighted: 0.9686894793658604, D: 0.1666666666666673\n",
      "2018-11-26 19:25:19,916 INFO     Weight matrix 6/9 (64,64): Alpha 3.6086532275323564 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:25:19,919 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.406570702791214\n",
      "2018-11-26 19:25:19,921 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:25:20,267 INFO     Weight matrix 7/9 (64,64): Alpha: 1.5424065897984374, Alpha Weighted: -0.0502193424989187, D: 0.24750514062646833\n",
      "2018-11-26 19:25:20,270 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.343167245388031\n",
      "2018-11-26 19:25:20,273 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:25:20,595 INFO     Weight matrix 8/9 (64,64): Alpha: 1.984170470616145, Alpha Weighted: 0.5012683092356816, D: 0.23682796720431798\n",
      "2018-11-26 19:25:20,598 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.40822649002075195\n",
      "2018-11-26 19:25:20,600 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:25:20,928 INFO     Weight matrix 9/9 (64,64): Alpha: 5.100962350298197, Alpha Weighted: 0.13447541766774113, D: 0.2500000000000009\n",
      "2018-11-26 19:25:20,931 INFO     Weight matrix 9/9 (64,64): Alpha 5.100962350298197 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:25:20,935 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.3379751741886139\n",
      "2018-11-26 19:25:20,938 INFO Layer 7: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 19:25:20,941 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:20,943 INFO Layer 8: ReLU(inplace)\n",
      "2018-11-26 19:25:20,945 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:20,948 INFO Layer 9: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:25:20,951 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:20,953 INFO Layer 10: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:25:20,957 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:25:20,960 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:25:20,963 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:25:21,407 INFO     Weight matrix 1/9 (64,128): Alpha: 1.9736492211698495, Alpha Weighted: 1.1632016662949192, D: 0.09291567776067666\n",
      "2018-11-26 19:25:21,411 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.5718109607696533\n",
      "2018-11-26 19:25:21,413 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:25:21,862 INFO     Weight matrix 2/9 (64,128): Alpha: 1.7716095654128075, Alpha Weighted: 0.9778279280663574, D: 0.1505953056075966\n",
      "2018-11-26 19:25:21,866 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.6119271516799927\n",
      "2018-11-26 19:25:21,868 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:25:22,305 INFO     Weight matrix 3/9 (64,128): Alpha: 2.0631861062840606, Alpha Weighted: 1.1018443919001504, D: 0.11452220658323653\n",
      "2018-11-26 19:25:22,309 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.5712844729423523\n",
      "2018-11-26 19:25:22,312 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:25:22,731 INFO     Weight matrix 4/9 (64,128): Alpha: 1.6305710964421931, Alpha Weighted: 0.7369311380610115, D: 0.13843417792092283\n",
      "2018-11-26 19:25:22,734 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.6082833409309387\n",
      "2018-11-26 19:25:22,737 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:25:23,154 INFO     Weight matrix 5/9 (64,128): Alpha: 1.877471475074063, Alpha Weighted: 1.0708473970127135, D: 0.1716734073712396\n",
      "2018-11-26 19:25:23,157 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.6536932587623596\n",
      "2018-11-26 19:25:23,160 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:25:23,589 INFO     Weight matrix 6/9 (64,128): Alpha: 1.6791195607959608, Alpha Weighted: 0.8388907233706452, D: 0.13418722844289643\n",
      "2018-11-26 19:25:23,594 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.6041015386581421\n",
      "2018-11-26 19:25:23,598 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:25:24,034 INFO     Weight matrix 7/9 (64,128): Alpha: 1.9568468385160056, Alpha Weighted: 0.9325236056418899, D: 0.14153213485359395\n",
      "2018-11-26 19:25:24,038 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.5662127137184143\n",
      "2018-11-26 19:25:24,040 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:25:24,466 INFO     Weight matrix 8/9 (64,128): Alpha: 1.7056952130264353, Alpha Weighted: 0.7917654515974596, D: 0.15206440231617668\n",
      "2018-11-26 19:25:24,470 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.6104803085327148\n",
      "2018-11-26 19:25:24,473 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:25:24,912 INFO     Weight matrix 9/9 (64,128): Alpha: 2.023740768993087, Alpha Weighted: 1.077871203652848, D: 0.09910398678131704\n",
      "2018-11-26 19:25:24,917 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.5680310130119324\n",
      "2018-11-26 19:25:24,919 INFO Layer 11: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 19:25:24,921 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:24,924 INFO Layer 12: ReLU(inplace)\n",
      "2018-11-26 19:25:24,926 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:24,928 INFO Layer 13: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:25:24,935 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:25:24,939 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:25:24,943 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:25:25,763 INFO     Weight matrix 1/9 (128,128): Alpha: 2.473928873212663, Alpha Weighted: 0.2560973346190226, D: 0.14863717401058663\n",
      "2018-11-26 19:25:25,767 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.5798072814941406\n",
      "2018-11-26 19:25:25,770 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:25:26,545 INFO     Weight matrix 2/9 (128,128): Alpha: 1.816940253133723, Alpha Weighted: 0.2813211801308035, D: 0.17681231303968659\n",
      "2018-11-26 19:25:26,550 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.6210896372795105\n",
      "2018-11-26 19:25:26,552 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:25:27,362 INFO     Weight matrix 3/9 (128,128): Alpha: 3.26209099095639, Alpha Weighted: 0.2768403052636063, D: 0.1437725566491097\n",
      "2018-11-26 19:25:27,365 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.5861191153526306\n",
      "2018-11-26 19:25:27,368 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:25:28,165 INFO     Weight matrix 4/9 (128,128): Alpha: 7.42748716716912, Alpha Weighted: 1.035805465820521, D: 0.1818554118261258\n",
      "2018-11-26 19:25:28,167 INFO     Weight matrix 4/9 (128,128): Alpha 7.42748716716912 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:25:28,170 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.6276276707649231\n",
      "2018-11-26 19:25:28,174 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:25:28,963 INFO     Weight matrix 5/9 (128,128): Alpha: 2.347539200837576, Alpha Weighted: 0.747634314845567, D: 0.19465044759456673\n",
      "2018-11-26 19:25:28,967 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.6993218064308167\n",
      "2018-11-26 19:25:28,972 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:25:29,775 INFO     Weight matrix 6/9 (128,128): Alpha: 3.1300679731191647, Alpha Weighted: 0.653084789245094, D: 0.17426578540387883\n",
      "2018-11-26 19:25:29,780 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.6377673745155334\n",
      "2018-11-26 19:25:29,788 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:25:30,597 INFO     Weight matrix 7/9 (128,128): Alpha: 1.9127083315698314, Alpha Weighted: 0.22189975449224628, D: 0.16835904147423042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:25:30,601 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.5919578075408936\n",
      "2018-11-26 19:25:30,606 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:25:31,398 INFO     Weight matrix 8/9 (128,128): Alpha: 1.8429060993594053, Alpha Weighted: 0.3038894578452014, D: 0.17912364500891137\n",
      "2018-11-26 19:25:31,402 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.6258042454719543\n",
      "2018-11-26 19:25:31,405 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:25:32,223 INFO     Weight matrix 9/9 (128,128): Alpha: 2.3716396254137377, Alpha Weighted: 0.3051554591828908, D: 0.16727410197559517\n",
      "2018-11-26 19:25:32,228 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.5891520380973816\n",
      "2018-11-26 19:25:32,234 INFO Layer 14: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 19:25:32,238 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:32,241 INFO Layer 15: ReLU(inplace)\n",
      "2018-11-26 19:25:32,245 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:32,248 INFO Layer 16: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:25:32,255 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:32,262 INFO Layer 17: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:25:32,270 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:25:32,274 INFO Layer 17: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:25:32,279 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:25:33,328 INFO     Weight matrix 1/9 (128,256): Alpha: 2.087727243819672, Alpha Weighted: 0.4652111809021847, D: 0.14054883863586498\n",
      "2018-11-26 19:25:33,332 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.6993683576583862\n",
      "2018-11-26 19:25:33,337 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:25:34,339 INFO     Weight matrix 2/9 (128,256): Alpha: 3.031325082547182, Alpha Weighted: 1.2081935250920686, D: 0.1307839338133755\n",
      "2018-11-26 19:25:34,342 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.7449001669883728\n",
      "2018-11-26 19:25:34,344 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:25:35,373 INFO     Weight matrix 3/9 (128,256): Alpha: 2.1675841528267394, Alpha Weighted: 0.4208797140868403, D: 0.1419768991919585\n",
      "2018-11-26 19:25:35,378 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.7071148753166199\n",
      "2018-11-26 19:25:35,380 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:25:36,391 INFO     Weight matrix 4/9 (128,256): Alpha: 2.768618529081694, Alpha Weighted: 1.1451792506560012, D: 0.13621476477274175\n",
      "2018-11-26 19:25:36,395 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.7437664270401001\n",
      "2018-11-26 19:25:36,397 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:25:37,406 INFO     Weight matrix 5/9 (128,256): Alpha: 3.3110006679505677, Alpha Weighted: 1.7307005449352684, D: 0.15055935151974376\n",
      "2018-11-26 19:25:37,410 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.8226166367530823\n",
      "2018-11-26 19:25:37,415 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:25:38,440 INFO     Weight matrix 6/9 (128,256): Alpha: 2.8807213385264303, Alpha Weighted: 1.2807483200306182, D: 0.14892288588928515\n",
      "2018-11-26 19:25:38,445 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.7481269836425781\n",
      "2018-11-26 19:25:38,448 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:25:39,480 INFO     Weight matrix 7/9 (128,256): Alpha: 2.501286868828294, Alpha Weighted: 0.5733141592914353, D: 0.14079436427138792\n",
      "2018-11-26 19:25:39,485 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.7054877281188965\n",
      "2018-11-26 19:25:39,488 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:25:40,499 INFO     Weight matrix 8/9 (128,256): Alpha: 2.573545003746826, Alpha Weighted: 0.9894294128275075, D: 0.1343888749751978\n",
      "2018-11-26 19:25:40,504 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.7367128133773804\n",
      "2018-11-26 19:25:40,506 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:25:41,520 INFO     Weight matrix 9/9 (128,256): Alpha: 2.1019959398028583, Alpha Weighted: 0.5304346714824111, D: 0.12442167989877229\n",
      "2018-11-26 19:25:41,524 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.7037714719772339\n",
      "2018-11-26 19:25:41,526 INFO Layer 18: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 19:25:41,529 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:41,534 INFO Layer 19: ReLU(inplace)\n",
      "2018-11-26 19:25:41,537 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 19:25:41,539 INFO Layer 20: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:25:41,549 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:25:41,551 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:25:41,553 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:25:43,966 INFO     Weight matrix 1/9 (256,256): Alpha: 2.9961451200637876, Alpha Weighted: 0.7166362906078226, D: 0.10329279247062462\n",
      "2018-11-26 19:25:43,970 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7758408188819885\n",
      "2018-11-26 19:25:43,973 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:25:46,358 INFO     Weight matrix 2/9 (256,256): Alpha: 4.0800395075358695, Alpha Weighted: 0.9983813496192699, D: 0.1052433453617242\n",
      "2018-11-26 19:25:46,360 INFO     Weight matrix 2/9 (256,256): Alpha 4.0800395075358695 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:25:46,367 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7917833924293518\n",
      "2018-11-26 19:25:46,371 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:25:48,766 INFO     Weight matrix 3/9 (256,256): Alpha: 3.2035870824615085, Alpha Weighted: 0.6633381602380553, D: 0.12629782440518167\n",
      "2018-11-26 19:25:48,771 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.7754475474357605\n",
      "2018-11-26 19:25:48,773 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:25:51,128 INFO     Weight matrix 4/9 (256,256): Alpha: 2.7691564433377334, Alpha Weighted: 0.6287905071032375, D: 0.13948876683937061\n",
      "2018-11-26 19:25:51,133 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.792868971824646\n",
      "2018-11-26 19:25:51,136 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:25:53,522 INFO     Weight matrix 5/9 (256,256): Alpha: 3.4021814259548084, Alpha Weighted: 1.7649045700683552, D: 0.08972497780733091\n",
      "2018-11-26 19:25:53,527 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8511083126068115\n",
      "2018-11-26 19:25:53,530 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:25:55,918 INFO     Weight matrix 6/9 (256,256): Alpha: 3.7705505631407594, Alpha Weighted: 0.8850616906487632, D: 0.12624830381404184\n",
      "2018-11-26 19:25:55,920 INFO     Weight matrix 6/9 (256,256): Alpha 3.7705505631407594 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:25:55,924 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7916189432144165\n",
      "2018-11-26 19:25:55,927 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:25:58,319 INFO     Weight matrix 7/9 (256,256): Alpha: 2.5777291056027667, Alpha Weighted: 0.5140578958173041, D: 0.11841186708866963\n",
      "2018-11-26 19:25:58,323 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.773457944393158\n",
      "2018-11-26 19:25:58,327 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:26:00,700 INFO     Weight matrix 8/9 (256,256): Alpha: 2.9914631198725967, Alpha Weighted: 0.6602291370139831, D: 0.14272879184194542\n",
      "2018-11-26 19:26:00,705 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7922695279121399\n",
      "2018-11-26 19:26:00,707 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:26:03,077 INFO     Weight matrix 9/9 (256,256): Alpha: 2.419798207947503, Alpha Weighted: 0.4274390063006023, D: 0.12143165686640356\n",
      "2018-11-26 19:26:03,082 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7736714482307434\n",
      "2018-11-26 19:26:03,084 INFO Layer 21: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 19:26:03,088 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 19:26:03,090 INFO Layer 22: ReLU(inplace)\n",
      "2018-11-26 19:26:03,093 INFO Layer 22: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:26:03,095 INFO Layer 23: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:26:03,097 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 19:26:03,100 INFO Layer 24: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:26:03,129 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:26:03,132 INFO Layer 24: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:26:03,135 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:26:05,651 INFO     Weight matrix 1/9 (256,512): Alpha: 2.4419669431976114, Alpha Weighted: 0.9690392467448189, D: 0.1037714550392358\n",
      "2018-11-26 19:26:05,655 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.8797587752342224\n",
      "2018-11-26 19:26:05,660 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:26:08,191 INFO     Weight matrix 2/9 (256,512): Alpha: 2.893036362454042, Alpha Weighted: 1.1253398404307005, D: 0.12193898199298692\n",
      "2018-11-26 19:26:08,195 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.8948659896850586\n",
      "2018-11-26 19:26:08,198 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:26:10,663 INFO     Weight matrix 3/9 (256,512): Alpha: 2.7743207700900108, Alpha Weighted: 1.0589984462749031, D: 0.09526811097133203\n",
      "2018-11-26 19:26:10,668 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.8786860704421997\n",
      "2018-11-26 19:26:10,670 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:26:13,148 INFO     Weight matrix 4/9 (256,512): Alpha: 3.781576581304724, Alpha Weighted: 1.6576864091339345, D: 0.094891764418913\n",
      "2018-11-26 19:26:13,151 INFO     Weight matrix 4/9 (256,512): Alpha 3.781576581304724 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:26:13,155 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.8890255093574524\n",
      "2018-11-26 19:26:13,158 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:26:15,614 INFO     Weight matrix 5/9 (256,512): Alpha: 3.041303733674345, Alpha Weighted: 1.6626164006009065, D: 0.12162705494876164\n",
      "2018-11-26 19:26:15,618 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.9578632116317749\n",
      "2018-11-26 19:26:15,622 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:26:18,122 INFO     Weight matrix 6/9 (256,512): Alpha: 3.396272054846913, Alpha Weighted: 1.4660271920811054, D: 0.10486384280081074\n",
      "2018-11-26 19:26:18,126 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.8886378407478333\n",
      "2018-11-26 19:26:18,129 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:26:20,672 INFO     Weight matrix 7/9 (256,512): Alpha: 2.9769499656511296, Alpha Weighted: 0.9939506414467625, D: 0.10574799915773231\n",
      "2018-11-26 19:26:20,677 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.8736560344696045\n",
      "2018-11-26 19:26:20,679 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:26:23,185 INFO     Weight matrix 8/9 (256,512): Alpha: 2.7776513658715722, Alpha Weighted: 1.0348493932810263, D: 0.10627796225324276\n",
      "2018-11-26 19:26:23,190 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.8868027925491333\n",
      "2018-11-26 19:26:23,193 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:26:25,790 INFO     Weight matrix 9/9 (256,512): Alpha: 3.030269462957883, Alpha Weighted: 1.0039278827982807, D: 0.09817476085807975\n",
      "2018-11-26 19:26:25,796 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.870478630065918\n",
      "2018-11-26 19:26:25,799 INFO Layer 25: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 19:26:25,802 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 19:26:25,806 INFO Layer 26: ReLU(inplace)\n",
      "2018-11-26 19:26:25,809 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 19:26:25,813 INFO Layer 27: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:26:25,869 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:26:25,872 INFO Layer 27: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:26:25,875 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:26:32,815 INFO     Weight matrix 1/9 (512,512): Alpha: 3.1111483372920463, Alpha Weighted: 1.6278660369814255, D: 0.05239689237812728\n",
      "2018-11-26 19:26:32,820 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.946273922920227\n",
      "2018-11-26 19:26:32,822 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:26:39,617 INFO     Weight matrix 2/9 (512,512): Alpha: 3.1319253860479694, Alpha Weighted: 1.9004706804568392, D: 0.04857033142934858\n",
      "2018-11-26 19:26:39,624 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9639781713485718\n",
      "2018-11-26 19:26:39,627 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:26:46,462 INFO     Weight matrix 3/9 (512,512): Alpha: 3.167165690259662, Alpha Weighted: 1.6671417452861694, D: 0.043628121042690426\n",
      "2018-11-26 19:26:46,467 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9453173279762268\n",
      "2018-11-26 19:26:46,469 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:26:53,304 INFO     Weight matrix 4/9 (512,512): Alpha: 3.2005266506419345, Alpha Weighted: 1.8508393784788808, D: 0.045610142634009754\n",
      "2018-11-26 19:26:53,308 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9365218877792358\n",
      "2018-11-26 19:26:53,311 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:27:00,051 INFO     Weight matrix 5/9 (512,512): Alpha: 2.3615123429449976, Alpha Weighted: 1.8347370438872896, D: 0.06848154452317418\n",
      "2018-11-26 19:27:00,056 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9972933530807495\n",
      "2018-11-26 19:27:00,060 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:27:06,854 INFO     Weight matrix 6/9 (512,512): Alpha: 3.0111477666252964, Alpha Weighted: 1.7557954796918283, D: 0.04813271653490028\n",
      "2018-11-26 19:27:06,859 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9331393241882324\n",
      "2018-11-26 19:27:06,861 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:27:13,686 INFO     Weight matrix 7/9 (512,512): Alpha: 3.106014304532139, Alpha Weighted: 1.6179451015369684, D: 0.05554749964550332\n",
      "2018-11-26 19:27:13,691 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.944365382194519\n",
      "2018-11-26 19:27:13,694 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:27:20,504 INFO     Weight matrix 8/9 (512,512): Alpha: 3.14640102944829, Alpha Weighted: 1.9300516593021952, D: 0.053014241323750155\n",
      "2018-11-26 19:27:20,511 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9600167870521545\n",
      "2018-11-26 19:27:20,515 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:27:27,332 INFO     Weight matrix 9/9 (512,512): Alpha: 3.053814061733982, Alpha Weighted: 1.5769806001016502, D: 0.04725928786914052\n",
      "2018-11-26 19:27:27,336 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9409239888191223\n",
      "2018-11-26 19:27:27,339 INFO Layer 28: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 19:27:27,347 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 19:27:27,350 INFO Layer 29: ReLU(inplace)\n",
      "2018-11-26 19:27:27,353 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 19:27:27,356 INFO Layer 30: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:27:27,358 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 19:27:27,364 INFO Layer 31: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:27:27,396 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:27:27,398 INFO Layer 31: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:27:27,401 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:27:34,270 INFO     Weight matrix 1/9 (512,512): Alpha: 3.087738679472986, Alpha Weighted: 1.7348450918859568, D: 0.057170064184919156\n",
      "2018-11-26 19:27:34,275 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9505980610847473\n",
      "2018-11-26 19:27:34,279 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:27:41,107 INFO     Weight matrix 2/9 (512,512): Alpha: 3.364979389492455, Alpha Weighted: 1.9509661440705988, D: 0.07025012007433462\n",
      "2018-11-26 19:27:41,112 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9758748412132263\n",
      "2018-11-26 19:27:41,114 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:27:47,877 INFO     Weight matrix 3/9 (512,512): Alpha: 2.999716103891168, Alpha Weighted: 1.7242329264657952, D: 0.048272184746377955\n",
      "2018-11-26 19:27:47,882 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9526974558830261\n",
      "2018-11-26 19:27:47,885 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:27:54,717 INFO     Weight matrix 4/9 (512,512): Alpha: 3.465038849092884, Alpha Weighted: 1.9161661844894355, D: 0.06281397281292883\n",
      "2018-11-26 19:27:54,722 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9302685260772705\n",
      "2018-11-26 19:27:54,727 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:28:01,492 INFO     Weight matrix 5/9 (512,512): Alpha: 4.332186071905824, Alpha Weighted: 3.040371000768249, D: 0.08150851551262062\n",
      "2018-11-26 19:28:01,495 INFO     Weight matrix 5/9 (512,512): Alpha 4.332186071905824 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:28:01,501 INFO     Weight matrix 5/9 (512,512): Lognorm: 1.0171852111816406\n",
      "2018-11-26 19:28:01,506 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:28:08,299 INFO     Weight matrix 6/9 (512,512): Alpha: 3.7690240384394427, Alpha Weighted: 2.0602041932756663, D: 0.05271897445822879\n",
      "2018-11-26 19:28:08,302 INFO     Weight matrix 6/9 (512,512): Alpha 3.7690240384394427 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:28:08,308 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.933244526386261\n",
      "2018-11-26 19:28:08,311 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:28:15,118 INFO     Weight matrix 7/9 (512,512): Alpha: 3.3082331145566926, Alpha Weighted: 1.6588535579887738, D: 0.04612601077350986\n",
      "2018-11-26 19:28:15,123 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.943320095539093\n",
      "2018-11-26 19:28:15,125 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:28:21,932 INFO     Weight matrix 8/9 (512,512): Alpha: 3.572906366428971, Alpha Weighted: 1.96541990350681, D: 0.051195437681976874\n",
      "2018-11-26 19:28:21,935 INFO     Weight matrix 8/9 (512,512): Alpha 3.572906366428971 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:28:21,941 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9644322395324707\n",
      "2018-11-26 19:28:21,944 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:28:28,728 INFO     Weight matrix 9/9 (512,512): Alpha: 3.0903846286771213, Alpha Weighted: 1.5391359605188164, D: 0.06595139580760895\n",
      "2018-11-26 19:28:28,735 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9443145990371704\n",
      "2018-11-26 19:28:28,737 INFO Layer 32: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 19:28:28,742 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 19:28:28,745 INFO Layer 33: ReLU(inplace)\n",
      "2018-11-26 19:28:28,748 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 19:28:28,750 INFO Layer 34: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:28:28,776 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:28:28,778 INFO Layer 34: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:28:28,781 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:28:35,715 INFO     Weight matrix 1/9 (512,512): Alpha: 4.195771472770203, Alpha Weighted: 2.250176500141342, D: 0.032034982105431875\n",
      "2018-11-26 19:28:35,718 INFO     Weight matrix 1/9 (512,512): Alpha 4.195771472770203 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:28:35,723 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9236577749252319\n",
      "2018-11-26 19:28:35,726 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:28:42,514 INFO     Weight matrix 2/9 (512,512): Alpha: 3.9931596201181416, Alpha Weighted: 2.7033342580158015, D: 0.04069183462488635\n",
      "2018-11-26 19:28:42,516 INFO     Weight matrix 2/9 (512,512): Alpha 3.9931596201181416 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:28:42,525 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9383594989776611\n",
      "2018-11-26 19:28:42,529 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:28:49,375 INFO     Weight matrix 3/9 (512,512): Alpha: 4.207979825735098, Alpha Weighted: 2.115669119989002, D: 0.035174692700272625\n",
      "2018-11-26 19:28:49,377 INFO     Weight matrix 3/9 (512,512): Alpha 4.207979825735098 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:28:49,383 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9213675856590271\n",
      "2018-11-26 19:28:49,386 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:28:56,169 INFO     Weight matrix 4/9 (512,512): Alpha: 3.6866017406404246, Alpha Weighted: 3.5042969402187167, D: 0.04057391553155462\n",
      "2018-11-26 19:28:56,171 INFO     Weight matrix 4/9 (512,512): Alpha 3.6866017406404246 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:28:56,177 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.9293527603149414\n",
      "2018-11-26 19:28:56,181 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:29:02,975 INFO     Weight matrix 5/9 (512,512): Alpha: 3.3776560479134856, Alpha Weighted: 3.826575928695095, D: 0.041943100623190954\n",
      "2018-11-26 19:29:02,980 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9717129468917847\n",
      "2018-11-26 19:29:02,983 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:29:09,766 INFO     Weight matrix 6/9 (512,512): Alpha: 3.6751468609005657, Alpha Weighted: 3.488534957613018, D: 0.04237602490313397\n",
      "2018-11-26 19:29:09,769 INFO     Weight matrix 6/9 (512,512): Alpha 3.6751468609005657 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:29:09,776 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.9281011819839478\n",
      "2018-11-26 19:29:09,779 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:29:16,623 INFO     Weight matrix 7/9 (512,512): Alpha: 4.509507983347776, Alpha Weighted: 2.176589207415436, D: 0.029411764705883137\n",
      "2018-11-26 19:29:16,626 INFO     Weight matrix 7/9 (512,512): Alpha 4.509507983347776 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:29:16,631 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.917163074016571\n",
      "2018-11-26 19:29:16,634 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:29:23,522 INFO     Weight matrix 8/9 (512,512): Alpha: 4.032074807270776, Alpha Weighted: 2.534422356948812, D: 0.03955310826375458\n",
      "2018-11-26 19:29:23,525 INFO     Weight matrix 8/9 (512,512): Alpha 4.032074807270776 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:29:23,531 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9323654174804688\n",
      "2018-11-26 19:29:23,533 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:29:30,353 INFO     Weight matrix 9/9 (512,512): Alpha: 4.463214510547191, Alpha Weighted: 2.2399427204818263, D: 0.03887822748519189\n",
      "2018-11-26 19:29:30,355 INFO     Weight matrix 9/9 (512,512): Alpha 4.463214510547191 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:29:30,361 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.916167140007019\n",
      "2018-11-26 19:29:30,363 INFO Layer 35: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 19:29:30,366 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 19:29:30,369 INFO Layer 36: ReLU(inplace)\n",
      "2018-11-26 19:29:30,371 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 19:29:30,374 INFO Layer 37: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:29:30,377 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 19:29:30,380 INFO Layer 38: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 19:29:30,382 INFO Layer 38: Skipping (Layer not supported)\n",
      "2018-11-26 19:29:30,384 INFO Layer 39: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 19:29:32,430 INFO Layer 39: Analyzing 1 weight matrices...\n",
      "2018-11-26 19:29:32,433 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 19:40:37,358 INFO     Weight matrix 1/1 (4096,25088): Alpha: 2.0700351498826244, Alpha Weighted: 2.8677996698899415, D: 0.029914021402084545\n",
      "2018-11-26 19:40:37,397 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.7195112705230713\n",
      "2018-11-26 19:40:37,491 INFO Layer 40: ReLU(inplace)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:40:37,592 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 19:40:37,595 INFO Layer 41: Dropout(p=0.5)\n",
      "2018-11-26 19:40:37,597 INFO Layer 41: Skipping (Layer not supported)\n",
      "2018-11-26 19:40:37,599 INFO Layer 42: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 19:40:37,706 INFO Layer 42: Analyzing 1 weight matrices...\n",
      "2018-11-26 19:40:37,710 INFO     Weight matrix 1/1 (4096,4096): Analyzing ...\n",
      "2018-11-26 19:46:09,063 INFO     Weight matrix 1/1 (4096,4096): Alpha: 1.9519696561897777, Alpha Weighted: 3.3347151975352785, D: 0.03298496054886069\n",
      "2018-11-26 19:46:09,072 INFO     Weight matrix 1/1 (4096,4096): Lognorm: 1.624423861503601\n",
      "2018-11-26 19:46:09,105 INFO Layer 43: ReLU(inplace)\n",
      "2018-11-26 19:46:09,133 INFO Layer 43: Skipping (Layer not supported)\n",
      "2018-11-26 19:46:09,136 INFO Layer 44: Dropout(p=0.5)\n",
      "2018-11-26 19:46:09,139 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 19:46:09,142 INFO Layer 45: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 19:46:09,173 INFO Layer 45: Analyzing 1 weight matrices...\n",
      "2018-11-26 19:46:09,175 INFO     Weight matrix 1/1 (1000,4096): Analyzing ...\n",
      "2018-11-26 19:46:38,627 INFO     Weight matrix 1/1 (1000,4096): Alpha: 2.995424316788679, Alpha Weighted: 5.284962065550667, D: 0.03718661674470658\n",
      "2018-11-26 19:46:38,633 INFO     Weight matrix 1/1 (1000,4096): Lognorm: 1.6200817823410034\n",
      "2018-11-26 19:46:38,662 INFO ### Printing results ###\n",
      "2018-11-26 19:46:38,665 DEBUG Layer 5: Lognorm compound: 0.3866419494152069\n",
      "2018-11-26 19:46:38,669 DEBUG Layer 9: Lognorm compound: 0.5962027510007223\n",
      "2018-11-26 19:46:38,673 DEBUG Layer 12: Lognorm compound: 0.6176274418830872\n",
      "2018-11-26 19:46:38,676 DEBUG Layer 16: Lognorm compound: 0.7346517178747389\n",
      "2018-11-26 19:46:38,679 DEBUG Layer 19: Lognorm compound: 0.7908963229921129\n",
      "2018-11-26 19:46:38,683 DEBUG Layer 23: Lognorm compound: 0.8910860949092441\n",
      "2018-11-26 19:46:38,686 DEBUG Layer 26: Lognorm compound: 0.9519811272621155\n",
      "2018-11-26 19:46:38,691 DEBUG Layer 30: Lognorm compound: 0.9568817284372118\n",
      "2018-11-26 19:46:38,694 DEBUG Layer 33: Lognorm compound: 0.9309163755840726\n",
      "2018-11-26 19:46:38,698 DEBUG Layer 38: Lognorm: 1.7195112705230713\n",
      "2018-11-26 19:46:38,701 DEBUG Layer 41: Lognorm: 1.624423861503601\n",
      "2018-11-26 19:46:38,704 DEBUG Layer 44: Lognorm: 1.6200817823410034\n",
      "2018-11-26 19:46:38,709 INFO LogNorm: min: 0.3236437141895294, max: 1.7195112705230713, avg: 0.7937617301940918\n",
      "2018-11-26 19:46:38,713 INFO LogNorm compound: min: 0.3866419494152069, max: 1.7195112705230713, avg: 0.9850752019771822\n",
      "2018-11-26 19:46:38,716 DEBUG Layer 5: Alpha compound: 2.733900276430384\n",
      "2018-11-26 19:46:38,720 DEBUG Layer 9: Alpha compound: 1.8535433161904957\n",
      "2018-11-26 19:46:38,723 DEBUG Layer 12: Alpha compound: 2.9539231683079574\n",
      "2018-11-26 19:46:38,731 DEBUG Layer 16: Alpha compound: 2.6026449807922516\n",
      "2018-11-26 19:46:38,735 DEBUG Layer 19: Alpha compound: 3.1345167306574817\n",
      "2018-11-26 19:46:38,740 DEBUG Layer 23: Alpha compound: 3.0125941377831373\n",
      "2018-11-26 19:46:38,744 DEBUG Layer 26: Alpha compound: 3.032183952169591\n",
      "2018-11-26 19:46:38,747 DEBUG Layer 30: Alpha compound: 3.4433563602175052\n",
      "2018-11-26 19:46:38,751 DEBUG Layer 33: Alpha compound: 4.01567920769374\n",
      "2018-11-26 19:46:38,763 DEBUG Layer 38: Alpha: 2.0700351498826244\n",
      "2018-11-26 19:46:38,767 DEBUG Layer 41: Alpha: 1.9519696561897777\n",
      "2018-11-26 19:46:38,773 DEBUG Layer 44: Alpha: 2.995424316788679\n",
      "2018-11-26 19:46:38,777 INFO Alpha: min: 1.539537263296173, max: 7.42748716716912, avg: 2.9530774797029045\n",
      "2018-11-26 19:46:38,780 INFO Alpha compound: min: 1.8535433161904957, max: 4.01567920769374, avg: 2.8166476044253024\n",
      "2018-11-26 19:46:38,783 DEBUG Layer 5: Alpha Weighted compound: 0.5336243775682926\n",
      "2018-11-26 19:46:38,789 DEBUG Layer 9: Alpha Weighted compound: 0.9657448339553328\n",
      "2018-11-26 19:46:38,796 DEBUG Layer 12: Alpha Weighted compound: 0.45352534016055024\n",
      "2018-11-26 19:46:38,802 DEBUG Layer 16: Alpha Weighted compound: 0.9271211977004816\n",
      "2018-11-26 19:46:38,805 DEBUG Layer 19: Alpha Weighted compound: 0.8065376230463771\n",
      "2018-11-26 19:46:38,809 DEBUG Layer 23: Alpha Weighted compound: 1.2191594947547155\n",
      "2018-11-26 19:46:38,814 DEBUG Layer 26: Alpha Weighted compound: 1.7513141917470274\n",
      "2018-11-26 19:46:38,819 DEBUG Layer 30: Alpha Weighted compound: 1.954466106996678\n",
      "2018-11-26 19:46:38,822 DEBUG Layer 33: Alpha Weighted compound: 2.759949109946562\n",
      "2018-11-26 19:46:38,826 DEBUG Layer 38: Alpha Weigthed: 2.8677996698899415\n",
      "2018-11-26 19:46:38,829 DEBUG Layer 41: Alpha Weigthed: 3.3347151975352785\n",
      "2018-11-26 19:46:38,833 DEBUG Layer 44: Alpha Weigthed: 5.284962065550667\n",
      "2018-11-26 19:46:38,838 INFO Alpha Weighted: min: -0.0502193424989187, max: 5.284962065550667, avg: 1.355124493045953\n",
      "2018-11-26 19:46:38,841 INFO Alpha Weighted compound: min: 0.45352534016055024, max: 5.284962065550667, avg: 1.9049099340709919\n"
     ]
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.vgg13_bn(pretrained=True)\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "results = watcher.analyze(compute_alphas=True)\n",
    "\n",
    "data.append({\"name\": \"vgg13bntorch\", \"summary\": watcher.get_summary()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T04:13:35.056027Z",
     "start_time": "2018-11-27T03:46:39.133897Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:46:48,161 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 19:46:48,163 INFO Analyzing model\n",
      "2018-11-26 19:46:48,167 INFO Layer 1: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 19:46:48,170 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 19:46:48,175 INFO Layer 2: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace)\n",
      "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (17): ReLU(inplace)\n",
      "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace)\n",
      "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (24): ReLU(inplace)\n",
      "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (26): ReLU(inplace)\n",
      "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace)\n",
      "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (31): ReLU(inplace)\n",
      "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (33): ReLU(inplace)\n",
      "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (35): ReLU(inplace)\n",
      "  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 19:46:48,178 INFO Layer 2: Skipping (Layer not supported)\n",
      "2018-11-26 19:46:48,182 INFO Layer 3: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:46:48,187 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:46:48,191 INFO Layer 3: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:46:48,195 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:46:48,198 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:46:48,202 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:46:48,205 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:46:48,208 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:46:48,212 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:46:48,215 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:46:48,219 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:46:48,222 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 19:46:48,226 INFO Layer 4: ReLU(inplace)\n",
      "2018-11-26 19:46:48,229 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 19:46:48,232 INFO Layer 5: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:46:48,415 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:46:48,418 INFO Layer 5: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:46:48,422 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:46:49,139 INFO     Weight matrix 1/9 (64,64): Alpha: 1.4433520467685375, Alpha Weighted: 0.37400046097904044, D: 0.18909774048615235\n",
      "2018-11-26 19:46:49,142 INFO     Weight matrix 1/9 (64,64): Alpha 1.4433520467685375 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:46:49,147 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.5246809124946594\n",
      "2018-11-26 19:46:49,153 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:46:49,770 INFO     Weight matrix 2/9 (64,64): Alpha: 1.528030971311867, Alpha Weighted: 0.6058797957651845, D: 0.1710957801181321\n",
      "2018-11-26 19:46:49,774 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.5623267889022827\n",
      "2018-11-26 19:46:49,777 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:46:50,346 INFO     Weight matrix 3/9 (64,64): Alpha: 2.133732906777966, Alpha Weighted: 0.5358820851415669, D: 0.19530522401359107\n",
      "2018-11-26 19:46:50,349 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.5185110569000244\n",
      "2018-11-26 19:46:50,352 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:46:50,942 INFO     Weight matrix 4/9 (64,64): Alpha: 1.5175890200169748, Alpha Weighted: 0.5657870708681467, D: 0.17687644162917693\n",
      "2018-11-26 19:46:50,945 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.5506455898284912\n",
      "2018-11-26 19:46:50,949 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:46:51,489 INFO     Weight matrix 5/9 (64,64): Alpha: 1.5564280586527477, Alpha Weighted: 0.8959314289689114, D: 0.16548952750192214\n",
      "2018-11-26 19:46:51,492 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.6257965564727783\n",
      "2018-11-26 19:46:51,496 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:46:52,020 INFO     Weight matrix 6/9 (64,64): Alpha: 1.4913516068204231, Alpha Weighted: 0.6635928748809717, D: 0.15060942849528175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:46:52,023 INFO     Weight matrix 6/9 (64,64): Alpha 1.4913516068204231 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:46:52,028 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.5667096376419067\n",
      "2018-11-26 19:46:52,031 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:46:52,538 INFO     Weight matrix 7/9 (64,64): Alpha: 1.4596253723291455, Alpha Weighted: 0.25546234120250005, D: 0.19951913082225503\n",
      "2018-11-26 19:46:52,541 INFO     Weight matrix 7/9 (64,64): Alpha 1.4596253723291455 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:46:52,545 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.507559061050415\n",
      "2018-11-26 19:46:52,548 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:46:53,043 INFO     Weight matrix 8/9 (64,64): Alpha: 1.5392098605451305, Alpha Weighted: 0.6788768928589369, D: 0.1715947135981234\n",
      "2018-11-26 19:46:53,046 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.5649570226669312\n",
      "2018-11-26 19:46:53,049 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 19:46:53,575 INFO     Weight matrix 9/9 (64,64): Alpha: 1.457900585050167, Alpha Weighted: 0.4323591532121015, D: 0.17514105297038107\n",
      "2018-11-26 19:46:53,578 INFO     Weight matrix 9/9 (64,64): Alpha 1.457900585050167 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:46:53,583 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.5289150476455688\n",
      "2018-11-26 19:46:53,588 INFO Layer 6: ReLU(inplace)\n",
      "2018-11-26 19:46:53,592 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 19:46:53,595 INFO Layer 7: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:46:53,598 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 19:46:53,602 INFO Layer 8: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:46:53,609 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:46:53,615 INFO Layer 8: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:46:53,618 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:46:54,158 INFO     Weight matrix 1/9 (64,128): Alpha: 1.9480238595203367, Alpha Weighted: 0.7090820057472119, D: 0.13217526934154944\n",
      "2018-11-26 19:46:54,161 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.6073034405708313\n",
      "2018-11-26 19:46:54,165 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:46:54,676 INFO     Weight matrix 2/9 (64,128): Alpha: 1.765584529493544, Alpha Weighted: 0.8100626315891267, D: 0.15214294998587352\n",
      "2018-11-26 19:46:54,679 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.6629356145858765\n",
      "2018-11-26 19:46:54,683 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:46:55,184 INFO     Weight matrix 3/9 (64,128): Alpha: 1.746850741844208, Alpha Weighted: 0.6559594660058287, D: 0.16942885104780525\n",
      "2018-11-26 19:46:55,189 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.6105842590332031\n",
      "2018-11-26 19:46:55,191 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:46:55,684 INFO     Weight matrix 4/9 (64,128): Alpha: 1.786098677865872, Alpha Weighted: 0.7348436691556204, D: 0.15315527775835747\n",
      "2018-11-26 19:46:55,688 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.6461232900619507\n",
      "2018-11-26 19:46:55,691 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:46:56,169 INFO     Weight matrix 5/9 (64,128): Alpha: 1.7878029346166038, Alpha Weighted: 1.305773586927941, D: 0.14205524666188896\n",
      "2018-11-26 19:46:56,173 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.7240925431251526\n",
      "2018-11-26 19:46:56,176 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:46:56,668 INFO     Weight matrix 6/9 (64,128): Alpha: 1.7338403310129236, Alpha Weighted: 0.8239731100260388, D: 0.14496527821084326\n",
      "2018-11-26 19:46:56,674 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.6685253977775574\n",
      "2018-11-26 19:46:56,679 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:46:57,189 INFO     Weight matrix 7/9 (64,128): Alpha: 1.6244490084241638, Alpha Weighted: 0.5587766376407718, D: 0.1685806107245783\n",
      "2018-11-26 19:46:57,194 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.5926670432090759\n",
      "2018-11-26 19:46:57,197 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:46:57,708 INFO     Weight matrix 8/9 (64,128): Alpha: 1.730681122506987, Alpha Weighted: 0.6888092332393896, D: 0.15668146375170877\n",
      "2018-11-26 19:46:57,712 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.649208664894104\n",
      "2018-11-26 19:46:57,715 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 19:46:58,207 INFO     Weight matrix 9/9 (64,128): Alpha: 1.8133168218198183, Alpha Weighted: 0.6154359885607584, D: 0.15667685600902193\n",
      "2018-11-26 19:46:58,210 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.6012813448905945\n",
      "2018-11-26 19:46:58,214 INFO Layer 9: ReLU(inplace)\n",
      "2018-11-26 19:46:58,217 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 19:46:58,220 INFO Layer 10: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:46:58,231 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:46:58,236 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:46:58,239 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:46:59,347 INFO     Weight matrix 1/9 (128,128): Alpha: 1.9967976232077218, Alpha Weighted: 0.42513046854519476, D: 0.1570835828457816\n",
      "2018-11-26 19:46:59,350 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.6642192006111145\n",
      "2018-11-26 19:46:59,354 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:47:00,493 INFO     Weight matrix 2/9 (128,128): Alpha: 1.7991023066099974, Alpha Weighted: 0.388447481150204, D: 0.16085117514023872\n",
      "2018-11-26 19:47:00,496 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.6979942321777344\n",
      "2018-11-26 19:47:00,499 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:47:01,610 INFO     Weight matrix 3/9 (128,128): Alpha: 1.8967231858183513, Alpha Weighted: 0.30716291496935466, D: 0.16055939647687534\n",
      "2018-11-26 19:47:01,616 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.6634766459465027\n",
      "2018-11-26 19:47:01,620 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:47:02,741 INFO     Weight matrix 4/9 (128,128): Alpha: 1.9960528166726113, Alpha Weighted: 0.4027891590599473, D: 0.17263021780907317\n",
      "2018-11-26 19:47:02,745 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.6933497190475464\n",
      "2018-11-26 19:47:02,750 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:47:03,889 INFO     Weight matrix 5/9 (128,128): Alpha: 1.7180822780212075, Alpha Weighted: 0.5963777794684845, D: 0.1695526553681827\n",
      "2018-11-26 19:47:03,894 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.7525110840797424\n",
      "2018-11-26 19:47:03,896 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:47:05,013 INFO     Weight matrix 6/9 (128,128): Alpha: 1.7889895686649337, Alpha Weighted: 0.36810295065656373, D: 0.16148107757776398\n",
      "2018-11-26 19:47:05,018 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.7028340697288513\n",
      "2018-11-26 19:47:05,022 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:47:06,175 INFO     Weight matrix 7/9 (128,128): Alpha: 1.8609072216895077, Alpha Weighted: 0.3281176042996576, D: 0.1453232371770954\n",
      "2018-11-26 19:47:06,178 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.6529442071914673\n",
      "2018-11-26 19:47:06,182 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:47:07,323 INFO     Weight matrix 8/9 (128,128): Alpha: 1.8108250870122573, Alpha Weighted: 0.4065406484887754, D: 0.15396073810596123\n",
      "2018-11-26 19:47:07,327 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.6940262317657471\n",
      "2018-11-26 19:47:07,331 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 19:47:08,490 INFO     Weight matrix 9/9 (128,128): Alpha: 1.7760511594593924, Alpha Weighted: 0.25016470582760847, D: 0.16772248207261398\n",
      "2018-11-26 19:47:08,493 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.6647165417671204\n",
      "2018-11-26 19:47:08,497 INFO Layer 11: ReLU(inplace)\n",
      "2018-11-26 19:47:08,501 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 19:47:08,505 INFO Layer 12: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:47:08,508 INFO Layer 12: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:47:08,511 INFO Layer 13: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:47:08,524 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:47:08,527 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:47:08,530 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:47:09,673 INFO     Weight matrix 1/9 (128,256): Alpha: 2.5707363461657433, Alpha Weighted: 0.32426930767246076, D: 0.14223853799907737\n",
      "2018-11-26 19:47:09,678 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.6945570111274719\n",
      "2018-11-26 19:47:09,681 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:47:10,817 INFO     Weight matrix 2/9 (128,256): Alpha: 2.5491702661830926, Alpha Weighted: 0.7963044542000137, D: 0.13031268111253336\n",
      "2018-11-26 19:47:10,820 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.7480389475822449\n",
      "2018-11-26 19:47:10,823 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:47:11,971 INFO     Weight matrix 3/9 (128,256): Alpha: 2.4131950481170166, Alpha Weighted: 0.3821806918922534, D: 0.15405428349131323\n",
      "2018-11-26 19:47:11,975 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.6934777498245239\n",
      "2018-11-26 19:47:11,978 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:47:13,131 INFO     Weight matrix 4/9 (128,256): Alpha: 2.7601963050366907, Alpha Weighted: 0.8824271158865566, D: 0.14516743130890247\n",
      "2018-11-26 19:47:13,135 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.7548373341560364\n",
      "2018-11-26 19:47:13,141 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:47:14,304 INFO     Weight matrix 5/9 (128,256): Alpha: 2.4433348902883036, Alpha Weighted: 1.5407389604152986, D: 0.1387892627908851\n",
      "2018-11-26 19:47:14,307 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.8705501556396484\n",
      "2018-11-26 19:47:14,311 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:47:15,447 INFO     Weight matrix 6/9 (128,256): Alpha: 2.7487807084132676, Alpha Weighted: 0.9089878930282542, D: 0.1515414312332441\n",
      "2018-11-26 19:47:15,451 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.7529991865158081\n",
      "2018-11-26 19:47:15,457 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:47:16,605 INFO     Weight matrix 7/9 (128,256): Alpha: 2.201394312006327, Alpha Weighted: 0.2533078506532587, D: 0.16475251591713713\n",
      "2018-11-26 19:47:16,610 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.6863210797309875\n",
      "2018-11-26 19:47:16,613 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:47:17,796 INFO     Weight matrix 8/9 (128,256): Alpha: 1.6794959107464806, Alpha Weighted: 0.5156157244706753, D: 0.1546351039048967\n",
      "2018-11-26 19:47:17,800 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.7482692003250122\n",
      "2018-11-26 19:47:17,806 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 19:47:18,998 INFO     Weight matrix 9/9 (128,256): Alpha: 2.911590883994233, Alpha Weighted: 0.27837043675169776, D: 0.1547366977097251\n",
      "2018-11-26 19:47:19,003 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.6904885172843933\n",
      "2018-11-26 19:47:19,006 INFO Layer 14: ReLU(inplace)\n",
      "2018-11-26 19:47:19,009 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 19:47:19,013 INFO Layer 15: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:47:19,035 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:47:19,038 INFO Layer 15: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:47:19,040 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:21,845 INFO     Weight matrix 1/9 (256,256): Alpha: 2.526270694874791, Alpha Weighted: 0.3412763385752823, D: 0.12212625360518536\n",
      "2018-11-26 19:47:21,850 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7491937875747681\n",
      "2018-11-26 19:47:21,854 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:24,737 INFO     Weight matrix 2/9 (256,256): Alpha: 2.0091979479373023, Alpha Weighted: 0.4320524144482032, D: 0.13071110944395747\n",
      "2018-11-26 19:47:24,742 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7718471884727478\n",
      "2018-11-26 19:47:24,745 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:28,147 INFO     Weight matrix 3/9 (256,256): Alpha: 2.228523990110248, Alpha Weighted: 0.21452579708070746, D: 0.13738267627581835\n",
      "2018-11-26 19:47:28,152 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.748981773853302\n",
      "2018-11-26 19:47:28,157 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:31,381 INFO     Weight matrix 4/9 (256,256): Alpha: 3.3502169095283456, Alpha Weighted: 0.7665525889227784, D: 0.12089214399853665\n",
      "2018-11-26 19:47:31,386 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.771720290184021\n",
      "2018-11-26 19:47:31,389 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:34,246 INFO     Weight matrix 5/9 (256,256): Alpha: 1.771555075463516, Alpha Weighted: 0.6821758210233995, D: 0.13084503221978094\n",
      "2018-11-26 19:47:34,251 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8354664444923401\n",
      "2018-11-26 19:47:34,254 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:36,981 INFO     Weight matrix 6/9 (256,256): Alpha: 3.1868460831034957, Alpha Weighted: 0.7046538935997849, D: 0.11027405886223629\n",
      "2018-11-26 19:47:36,986 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7708715200424194\n",
      "2018-11-26 19:47:36,989 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:39,767 INFO     Weight matrix 7/9 (256,256): Alpha: 2.419534317702996, Alpha Weighted: 0.30642743697728225, D: 0.13187810104330777\n",
      "2018-11-26 19:47:39,772 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.7443217039108276\n",
      "2018-11-26 19:47:39,776 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:42,523 INFO     Weight matrix 8/9 (256,256): Alpha: 5.027316766089016, Alpha Weighted: 1.2311623235456524, D: 0.12833373828128591\n",
      "2018-11-26 19:47:42,526 INFO     Weight matrix 8/9 (256,256): Alpha 5.027316766089016 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:47:42,531 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7676737904548645\n",
      "2018-11-26 19:47:42,534 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:45,231 INFO     Weight matrix 9/9 (256,256): Alpha: 2.609570119110967, Alpha Weighted: 0.34635605053822494, D: 0.13480240593702472\n",
      "2018-11-26 19:47:45,235 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7488450407981873\n",
      "2018-11-26 19:47:45,239 INFO Layer 16: ReLU(inplace)\n",
      "2018-11-26 19:47:45,242 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 19:47:45,245 INFO Layer 17: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:47:45,259 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:47:45,262 INFO Layer 17: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:47:45,265 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:48,157 INFO     Weight matrix 1/9 (256,256): Alpha: 3.1605873828336217, Alpha Weighted: 0.5854494529822111, D: 0.09937325826179755\n",
      "2018-11-26 19:47:48,162 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7488040924072266\n",
      "2018-11-26 19:47:48,166 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:50,830 INFO     Weight matrix 2/9 (256,256): Alpha: 2.1304270609987164, Alpha Weighted: 0.6128613841563403, D: 0.11096949298219816\n",
      "2018-11-26 19:47:50,835 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7721681594848633\n",
      "2018-11-26 19:47:50,837 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:53,576 INFO     Weight matrix 3/9 (256,256): Alpha: 2.997803423840402, Alpha Weighted: 0.4648181601094382, D: 0.11903691210051137\n",
      "2018-11-26 19:47:53,583 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.7476074695587158\n",
      "2018-11-26 19:47:53,587 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:56,457 INFO     Weight matrix 4/9 (256,256): Alpha: 2.548678416289066, Alpha Weighted: 0.6731126166072445, D: 0.11099494812097677\n",
      "2018-11-26 19:47:56,463 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.7677842378616333\n",
      "2018-11-26 19:47:56,467 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:47:59,121 INFO     Weight matrix 5/9 (256,256): Alpha: 1.853957853173247, Alpha Weighted: 0.8362905913984802, D: 0.1172212057922507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:47:59,125 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8333234786987305\n",
      "2018-11-26 19:47:59,128 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:48:01,816 INFO     Weight matrix 6/9 (256,256): Alpha: 3.0765007504769124, Alpha Weighted: 0.8659677907268513, D: 0.09849018588794978\n",
      "2018-11-26 19:48:01,821 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7665061354637146\n",
      "2018-11-26 19:48:01,824 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:48:04,499 INFO     Weight matrix 7/9 (256,256): Alpha: 3.2528872690153965, Alpha Weighted: 0.4013482043884029, D: 0.12544440419495329\n",
      "2018-11-26 19:48:04,503 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.745129406452179\n",
      "2018-11-26 19:48:04,508 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:48:07,137 INFO     Weight matrix 8/9 (256,256): Alpha: 2.0663080375391183, Alpha Weighted: 0.4603133002373895, D: 0.12337815016154924\n",
      "2018-11-26 19:48:07,141 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7673397064208984\n",
      "2018-11-26 19:48:07,144 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:48:09,822 INFO     Weight matrix 9/9 (256,256): Alpha: 2.703128162639186, Alpha Weighted: 0.3411089694358948, D: 0.11069928874980572\n",
      "2018-11-26 19:48:09,826 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7425023317337036\n",
      "2018-11-26 19:48:09,829 INFO Layer 18: ReLU(inplace)\n",
      "2018-11-26 19:48:09,833 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 19:48:09,836 INFO Layer 19: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:48:09,842 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:48:09,846 INFO Layer 19: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:48:09,852 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:48:12,481 INFO     Weight matrix 1/9 (256,256): Alpha: 3.081294715606633, Alpha Weighted: 0.6864334936902786, D: 0.10610647761734338\n",
      "2018-11-26 19:48:12,486 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7562655806541443\n",
      "2018-11-26 19:48:12,489 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:48:15,084 INFO     Weight matrix 2/9 (256,256): Alpha: 3.9235997119205126, Alpha Weighted: 1.5028524115535689, D: 0.08333333333333293\n",
      "2018-11-26 19:48:15,086 INFO     Weight matrix 2/9 (256,256): Alpha 3.9235997119205126 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:48:15,092 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7882983088493347\n",
      "2018-11-26 19:48:15,095 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:48:17,704 INFO     Weight matrix 3/9 (256,256): Alpha: 2.9175623147491256, Alpha Weighted: 0.5092043230718079, D: 0.0909994642022422\n",
      "2018-11-26 19:48:17,709 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.7557727098464966\n",
      "2018-11-26 19:48:17,712 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:48:20,320 INFO     Weight matrix 4/9 (256,256): Alpha: 3.7035066503060525, Alpha Weighted: 1.5531059038260473, D: 0.05555555555555536\n",
      "2018-11-26 19:48:20,325 INFO     Weight matrix 4/9 (256,256): Alpha 3.7035066503060525 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:48:20,330 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.7799181938171387\n",
      "2018-11-26 19:48:20,334 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:48:22,935 INFO     Weight matrix 5/9 (256,256): Alpha: 3.394850907422555, Alpha Weighted: 2.071731023425762, D: 0.07243287629900536\n",
      "2018-11-26 19:48:22,940 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8419984579086304\n",
      "2018-11-26 19:48:22,943 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:48:25,511 INFO     Weight matrix 6/9 (256,256): Alpha: 3.6898573231209375, Alpha Weighted: 1.3446516355432379, D: 0.08396154341015549\n",
      "2018-11-26 19:48:25,514 INFO     Weight matrix 6/9 (256,256): Alpha 3.6898573231209375 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:48:25,522 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7775861024856567\n",
      "2018-11-26 19:48:25,525 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:48:28,119 INFO     Weight matrix 7/9 (256,256): Alpha: 3.6880870757391433, Alpha Weighted: 0.8919328769211428, D: 0.07152536584464675\n",
      "2018-11-26 19:48:28,122 INFO     Weight matrix 7/9 (256,256): Alpha 3.6880870757391433 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:48:28,126 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.7540994882583618\n",
      "2018-11-26 19:48:28,130 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:48:30,760 INFO     Weight matrix 8/9 (256,256): Alpha: 3.7897442845199087, Alpha Weighted: 1.458702970741984, D: 0.10176661660121007\n",
      "2018-11-26 19:48:30,763 INFO     Weight matrix 8/9 (256,256): Alpha 3.7897442845199087 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:48:30,767 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7831012606620789\n",
      "2018-11-26 19:48:30,770 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 19:48:33,344 INFO     Weight matrix 9/9 (256,256): Alpha: 3.8115022968894507, Alpha Weighted: 0.890731984216727, D: 0.0676730219557099\n",
      "2018-11-26 19:48:33,348 INFO     Weight matrix 9/9 (256,256): Alpha 3.8115022968894507 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:48:33,354 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7492718696594238\n",
      "2018-11-26 19:48:33,358 INFO Layer 20: ReLU(inplace)\n",
      "2018-11-26 19:48:33,363 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 19:48:33,367 INFO Layer 21: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:48:33,370 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 19:48:33,373 INFO Layer 22: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:48:33,399 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:48:33,402 INFO Layer 22: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:48:33,405 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:48:36,118 INFO     Weight matrix 1/9 (256,512): Alpha: 4.004994370886633, Alpha Weighted: 1.193932485649153, D: 0.11210818715919763\n",
      "2018-11-26 19:48:36,121 INFO     Weight matrix 1/9 (256,512): Alpha 4.004994370886633 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:48:36,127 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.8389447331428528\n",
      "2018-11-26 19:48:36,129 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:48:38,744 INFO     Weight matrix 2/9 (256,512): Alpha: 3.507828589206325, Alpha Weighted: 1.1740432163032473, D: 0.1276738047680409\n",
      "2018-11-26 19:48:38,746 INFO     Weight matrix 2/9 (256,512): Alpha 3.507828589206325 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:48:38,751 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.865201473236084\n",
      "2018-11-26 19:48:38,754 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:48:41,416 INFO     Weight matrix 3/9 (256,512): Alpha: 2.2675362783831474, Alpha Weighted: 0.5747423595567609, D: 0.12880285666085572\n",
      "2018-11-26 19:48:41,421 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.8419089317321777\n",
      "2018-11-26 19:48:41,423 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:48:44,062 INFO     Weight matrix 4/9 (256,512): Alpha: 2.841487823786245, Alpha Weighted: 0.9288110817386377, D: 0.11040072445899313\n",
      "2018-11-26 19:48:44,066 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.8585543632507324\n",
      "2018-11-26 19:48:44,069 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:48:46,754 INFO     Weight matrix 5/9 (256,512): Alpha: 1.8316907753568223, Alpha Weighted: 0.8795039292698581, D: 0.1255956011392073\n",
      "2018-11-26 19:48:46,760 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.9144951105117798\n",
      "2018-11-26 19:48:46,765 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:48:49,380 INFO     Weight matrix 6/9 (256,512): Alpha: 3.1579973637379415, Alpha Weighted: 1.0899711945936337, D: 0.10946747952787272\n",
      "2018-11-26 19:48:49,385 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.8618883490562439\n",
      "2018-11-26 19:48:49,388 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:48:52,082 INFO     Weight matrix 7/9 (256,512): Alpha: 2.9757631156276645, Alpha Weighted: 0.6984061322461743, D: 0.12183839435515242\n",
      "2018-11-26 19:48:52,087 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.8374895453453064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:48:52,091 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:48:54,765 INFO     Weight matrix 8/9 (256,512): Alpha: 2.083680842765892, Alpha Weighted: 0.671274098717872, D: 0.13390608671706372\n",
      "2018-11-26 19:48:54,770 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.8614062070846558\n",
      "2018-11-26 19:48:54,772 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 19:48:57,429 INFO     Weight matrix 9/9 (256,512): Alpha: 2.8620470065389307, Alpha Weighted: 0.7635480426636064, D: 0.11329950747807682\n",
      "2018-11-26 19:48:57,434 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.8379868268966675\n",
      "2018-11-26 19:48:57,439 INFO Layer 23: ReLU(inplace)\n",
      "2018-11-26 19:48:57,441 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 19:48:57,444 INFO Layer 24: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:48:57,487 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:48:57,490 INFO Layer 24: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:48:57,495 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:49:04,706 INFO     Weight matrix 1/9 (512,512): Alpha: 3.318808377008586, Alpha Weighted: 0.8479589649231134, D: 0.06746544659013415\n",
      "2018-11-26 19:49:04,712 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.885540783405304\n",
      "2018-11-26 19:49:04,717 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:49:11,794 INFO     Weight matrix 2/9 (512,512): Alpha: 3.5266181333082565, Alpha Weighted: 1.2040854814148796, D: 0.07273967672644571\n",
      "2018-11-26 19:49:11,797 INFO     Weight matrix 2/9 (512,512): Alpha 3.5266181333082565 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:49:11,804 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.8947453498840332\n",
      "2018-11-26 19:49:11,807 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:49:18,925 INFO     Weight matrix 3/9 (512,512): Alpha: 3.3808058536936536, Alpha Weighted: 0.9120463306153062, D: 0.075029849900488\n",
      "2018-11-26 19:49:18,932 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.8855249285697937\n",
      "2018-11-26 19:49:18,936 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:49:26,132 INFO     Weight matrix 4/9 (512,512): Alpha: 3.5503299505630004, Alpha Weighted: 1.3925955549554152, D: 0.06466722483579507\n",
      "2018-11-26 19:49:26,135 INFO     Weight matrix 4/9 (512,512): Alpha 3.5503299505630004 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:49:26,141 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8803914189338684\n",
      "2018-11-26 19:49:26,144 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:49:33,259 INFO     Weight matrix 5/9 (512,512): Alpha: 2.137341361650326, Alpha Weighted: 1.1508272567481364, D: 0.08176863675283025\n",
      "2018-11-26 19:49:33,264 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9155763387680054\n",
      "2018-11-26 19:49:33,267 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:49:40,337 INFO     Weight matrix 6/9 (512,512): Alpha: 3.6594428695341157, Alpha Weighted: 1.4446939780559334, D: 0.0702192061946807\n",
      "2018-11-26 19:49:40,340 INFO     Weight matrix 6/9 (512,512): Alpha 3.6594428695341157 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:49:40,346 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8818593621253967\n",
      "2018-11-26 19:49:40,349 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:49:47,377 INFO     Weight matrix 7/9 (512,512): Alpha: 3.4482866552814913, Alpha Weighted: 1.0493311347711614, D: 0.07726517223860638\n",
      "2018-11-26 19:49:47,382 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.8830077052116394\n",
      "2018-11-26 19:49:47,384 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:49:54,501 INFO     Weight matrix 8/9 (512,512): Alpha: 3.9110210724128676, Alpha Weighted: 1.316059363876342, D: 0.07504467235689288\n",
      "2018-11-26 19:49:54,504 INFO     Weight matrix 8/9 (512,512): Alpha 3.9110210724128676 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:49:54,510 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.889390230178833\n",
      "2018-11-26 19:49:54,513 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:50:01,666 INFO     Weight matrix 9/9 (512,512): Alpha: 3.361946064898564, Alpha Weighted: 0.9517835932819577, D: 0.074539242856416\n",
      "2018-11-26 19:50:01,671 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.8831586837768555\n",
      "2018-11-26 19:50:01,674 INFO Layer 25: ReLU(inplace)\n",
      "2018-11-26 19:50:01,676 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 19:50:01,682 INFO Layer 26: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:50:01,716 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:50:01,719 INFO Layer 26: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:50:01,722 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:50:08,806 INFO     Weight matrix 1/9 (512,512): Alpha: 3.353286876410267, Alpha Weighted: 1.1383612793376634, D: 0.06301453373487953\n",
      "2018-11-26 19:50:08,810 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.8738781213760376\n",
      "2018-11-26 19:50:08,813 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:50:15,894 INFO     Weight matrix 2/9 (512,512): Alpha: 4.117047104699999, Alpha Weighted: 1.881393175655008, D: 0.06250000000000178\n",
      "2018-11-26 19:50:15,896 INFO     Weight matrix 2/9 (512,512): Alpha 4.117047104699999 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:50:15,902 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.8819280862808228\n",
      "2018-11-26 19:50:15,906 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:50:23,059 INFO     Weight matrix 3/9 (512,512): Alpha: 3.3050795230493306, Alpha Weighted: 1.133799463546647, D: 0.05263330681592593\n",
      "2018-11-26 19:50:23,064 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.8722795844078064\n",
      "2018-11-26 19:50:23,067 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:50:30,162 INFO     Weight matrix 4/9 (512,512): Alpha: 3.9073929034382373, Alpha Weighted: 1.8255545026174451, D: 0.052631578947369806\n",
      "2018-11-26 19:50:30,164 INFO     Weight matrix 4/9 (512,512): Alpha 3.9073929034382373 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:50:30,171 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8660372495651245\n",
      "2018-11-26 19:50:30,173 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:50:37,297 INFO     Weight matrix 5/9 (512,512): Alpha: 2.2525767633128675, Alpha Weighted: 1.4170515217785904, D: 0.0664340848142172\n",
      "2018-11-26 19:50:37,302 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9004011750221252\n",
      "2018-11-26 19:50:37,306 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:50:44,413 INFO     Weight matrix 6/9 (512,512): Alpha: 3.831454169699591, Alpha Weighted: 1.792565700419502, D: 0.056678062360107695\n",
      "2018-11-26 19:50:44,416 INFO     Weight matrix 6/9 (512,512): Alpha 3.831454169699591 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:50:44,424 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8636278510093689\n",
      "2018-11-26 19:50:44,428 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:50:51,552 INFO     Weight matrix 7/9 (512,512): Alpha: 3.4368495603674782, Alpha Weighted: 1.1551030546642973, D: 0.07171743511017181\n",
      "2018-11-26 19:50:51,557 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.8699209690093994\n",
      "2018-11-26 19:50:51,563 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:50:58,689 INFO     Weight matrix 8/9 (512,512): Alpha: 3.9921577192686373, Alpha Weighted: 1.7755993985215526, D: 0.06093971116033259\n",
      "2018-11-26 19:50:58,691 INFO     Weight matrix 8/9 (512,512): Alpha 3.9921577192686373 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:50:58,697 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.878058910369873\n",
      "2018-11-26 19:50:58,701 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:51:05,863 INFO     Weight matrix 9/9 (512,512): Alpha: 3.0495898364814003, Alpha Weighted: 0.9717727270156711, D: 0.06449930671050974\n",
      "2018-11-26 19:51:05,867 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.8692077994346619\n",
      "2018-11-26 19:51:05,870 INFO Layer 27: ReLU(inplace)\n",
      "2018-11-26 19:51:05,873 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 19:51:05,877 INFO Layer 28: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:51:05,900 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:51:05,903 INFO Layer 28: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:51:05,906 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:51:13,007 INFO     Weight matrix 1/9 (512,512): Alpha: 3.741849582096416, Alpha Weighted: 1.7914598532463553, D: 0.038461538461539546\n",
      "2018-11-26 19:51:13,009 INFO     Weight matrix 1/9 (512,512): Alpha 3.741849582096416 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:51:13,017 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.8688058257102966\n",
      "2018-11-26 19:51:13,019 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:51:20,172 INFO     Weight matrix 2/9 (512,512): Alpha: 3.6405340162186697, Alpha Weighted: 2.065253543931667, D: 0.04166666666666785\n",
      "2018-11-26 19:51:20,174 INFO     Weight matrix 2/9 (512,512): Alpha 3.6405340162186697 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:51:20,181 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.8818878531455994\n",
      "2018-11-26 19:51:20,185 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:51:27,436 INFO     Weight matrix 3/9 (512,512): Alpha: 3.5593046403593265, Alpha Weighted: 1.7040990590236498, D: 0.04651451016734384\n",
      "2018-11-26 19:51:27,439 INFO     Weight matrix 3/9 (512,512): Alpha 3.5593046403593265 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:51:27,445 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.8673697113990784\n",
      "2018-11-26 19:51:27,447 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:51:34,615 INFO     Weight matrix 4/9 (512,512): Alpha: 3.7095325306068525, Alpha Weighted: 2.099254853452599, D: 0.05064396505958546\n",
      "2018-11-26 19:51:34,618 INFO     Weight matrix 4/9 (512,512): Alpha 3.7095325306068525 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:51:34,624 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8652378916740417\n",
      "2018-11-26 19:51:34,627 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:51:41,688 INFO     Weight matrix 5/9 (512,512): Alpha: 2.464610993136425, Alpha Weighted: 1.768842360018078, D: 0.06632973681990667\n",
      "2018-11-26 19:51:41,693 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.8992469906806946\n",
      "2018-11-26 19:51:41,697 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:51:48,787 INFO     Weight matrix 6/9 (512,512): Alpha: 3.5829333689880647, Alpha Weighted: 2.0185679612443344, D: 0.048260354272435635\n",
      "2018-11-26 19:51:48,789 INFO     Weight matrix 6/9 (512,512): Alpha 3.5829333689880647 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:51:48,795 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8650032877922058\n",
      "2018-11-26 19:51:48,799 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:51:55,979 INFO     Weight matrix 7/9 (512,512): Alpha: 3.4904392218534923, Alpha Weighted: 1.786933120153834, D: 0.0357142857142867\n",
      "2018-11-26 19:51:55,984 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.8676639199256897\n",
      "2018-11-26 19:51:55,987 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:52:03,094 INFO     Weight matrix 8/9 (512,512): Alpha: 3.594113258378266, Alpha Weighted: 2.151796203510295, D: 0.07206198874106262\n",
      "2018-11-26 19:52:03,097 INFO     Weight matrix 8/9 (512,512): Alpha 3.594113258378266 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:52:03,103 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.8799999952316284\n",
      "2018-11-26 19:52:03,106 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:52:10,253 INFO     Weight matrix 9/9 (512,512): Alpha: 3.6299423755462032, Alpha Weighted: 1.79456138174986, D: 0.040000000000001035\n",
      "2018-11-26 19:52:10,255 INFO     Weight matrix 9/9 (512,512): Alpha 3.6299423755462032 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:52:10,263 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.8669476509094238\n",
      "2018-11-26 19:52:10,266 INFO Layer 29: ReLU(inplace)\n",
      "2018-11-26 19:52:10,269 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 19:52:10,272 INFO Layer 30: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:52:10,274 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 19:52:10,281 INFO Layer 31: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:52:10,307 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:52:10,309 INFO Layer 31: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:52:10,315 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:52:17,426 INFO     Weight matrix 1/9 (512,512): Alpha: 3.198974579678912, Alpha Weighted: 0.8508306703331692, D: 0.09028155313187852\n",
      "2018-11-26 19:52:17,432 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.911863386631012\n",
      "2018-11-26 19:52:17,435 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:52:24,671 INFO     Weight matrix 2/9 (512,512): Alpha: 4.1424157904304195, Alpha Weighted: 1.0123247940240097, D: 0.09631896043463783\n",
      "2018-11-26 19:52:24,674 INFO     Weight matrix 2/9 (512,512): Alpha 4.1424157904304195 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:52:24,682 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9174155592918396\n",
      "2018-11-26 19:52:24,687 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:52:31,783 INFO     Weight matrix 3/9 (512,512): Alpha: 3.2039593200850747, Alpha Weighted: 0.7974819818317369, D: 0.09503444312772413\n",
      "2018-11-26 19:52:31,789 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9116525650024414\n",
      "2018-11-26 19:52:31,792 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:52:38,878 INFO     Weight matrix 4/9 (512,512): Alpha: 3.1029156163495775, Alpha Weighted: 0.859890776961379, D: 0.08896861180228677\n",
      "2018-11-26 19:52:38,883 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8962352275848389\n",
      "2018-11-26 19:52:38,888 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:52:45,879 INFO     Weight matrix 5/9 (512,512): Alpha: 2.5946597803134184, Alpha Weighted: 1.0061458303209558, D: 0.09166091773945406\n",
      "2018-11-26 19:52:45,885 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9292255640029907\n",
      "2018-11-26 19:52:45,890 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:52:53,129 INFO     Weight matrix 6/9 (512,512): Alpha: 4.563688637653367, Alpha Weighted: 1.2131339790180107, D: 0.0776593662221286\n",
      "2018-11-26 19:52:53,131 INFO     Weight matrix 6/9 (512,512): Alpha 4.563688637653367 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:52:53,137 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8952121734619141\n",
      "2018-11-26 19:52:53,140 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:53:00,183 INFO     Weight matrix 7/9 (512,512): Alpha: 3.22917445579205, Alpha Weighted: 0.7257270204101354, D: 0.09290058557018\n",
      "2018-11-26 19:53:00,189 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9054318070411682\n",
      "2018-11-26 19:53:00,191 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:53:07,371 INFO     Weight matrix 8/9 (512,512): Alpha: 4.288338172260589, Alpha Weighted: 0.8980655501701306, D: 0.09448468892324124\n",
      "2018-11-26 19:53:07,374 INFO     Weight matrix 8/9 (512,512): Alpha 4.288338172260589 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:53:07,380 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9108423590660095\n",
      "2018-11-26 19:53:07,383 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:53:14,471 INFO     Weight matrix 9/9 (512,512): Alpha: 3.325810180106889, Alpha Weighted: 0.6867193698452132, D: 0.09454908964029729\n",
      "2018-11-26 19:53:14,476 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9054908752441406\n",
      "2018-11-26 19:53:14,479 INFO Layer 32: ReLU(inplace)\n",
      "2018-11-26 19:53:14,481 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 19:53:14,484 INFO Layer 33: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:53:14,506 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:53:14,509 INFO Layer 33: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:53:14,512 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:53:21,595 INFO     Weight matrix 1/9 (512,512): Alpha: 3.501239900128067, Alpha Weighted: 1.2639064969931735, D: 0.052077704593490814\n",
      "2018-11-26 19:53:21,598 INFO     Weight matrix 1/9 (512,512): Alpha 3.501239900128067 is in the danger zone (1.5,3.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:53:21,606 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9125230312347412\n",
      "2018-11-26 19:53:21,610 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:53:28,690 INFO     Weight matrix 2/9 (512,512): Alpha: 3.824897059570895, Alpha Weighted: 1.2983615414188419, D: 0.07586848057335926\n",
      "2018-11-26 19:53:28,693 INFO     Weight matrix 2/9 (512,512): Alpha 3.824897059570895 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:53:28,700 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9226411581039429\n",
      "2018-11-26 19:53:28,704 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:53:35,839 INFO     Weight matrix 3/9 (512,512): Alpha: 3.4659109024603167, Alpha Weighted: 1.1965574346864463, D: 0.06133589822710961\n",
      "2018-11-26 19:53:35,844 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.911993682384491\n",
      "2018-11-26 19:53:35,847 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:53:42,954 INFO     Weight matrix 4/9 (512,512): Alpha: 4.555807554566207, Alpha Weighted: 1.717031401555299, D: 0.06047715272914772\n",
      "2018-11-26 19:53:42,956 INFO     Weight matrix 4/9 (512,512): Alpha 4.555807554566207 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:53:42,961 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8935441374778748\n",
      "2018-11-26 19:53:42,965 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:53:50,085 INFO     Weight matrix 5/9 (512,512): Alpha: 2.5820659795931604, Alpha Weighted: 1.1287539944972076, D: 0.07642947737468442\n",
      "2018-11-26 19:53:50,091 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9250903129577637\n",
      "2018-11-26 19:53:50,095 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:53:57,108 INFO     Weight matrix 6/9 (512,512): Alpha: 4.295834440913482, Alpha Weighted: 1.5959106259766949, D: 0.06422992387236737\n",
      "2018-11-26 19:53:57,110 INFO     Weight matrix 6/9 (512,512): Alpha 4.295834440913482 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:53:57,116 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8938823938369751\n",
      "2018-11-26 19:53:57,120 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:54:04,219 INFO     Weight matrix 7/9 (512,512): Alpha: 3.2133416350843556, Alpha Weighted: 1.1566398509637195, D: 0.06734151373100272\n",
      "2018-11-26 19:54:04,224 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9073210954666138\n",
      "2018-11-26 19:54:04,226 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:54:11,264 INFO     Weight matrix 8/9 (512,512): Alpha: 3.82212498017699, Alpha Weighted: 1.2686783303906544, D: 0.07846908356138288\n",
      "2018-11-26 19:54:11,267 INFO     Weight matrix 8/9 (512,512): Alpha 3.82212498017699 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:54:11,274 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9131843447685242\n",
      "2018-11-26 19:54:11,281 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:54:18,374 INFO     Weight matrix 9/9 (512,512): Alpha: 3.277109873598976, Alpha Weighted: 1.17651300532426, D: 0.05493308405544767\n",
      "2018-11-26 19:54:18,379 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.906525194644928\n",
      "2018-11-26 19:54:18,381 INFO Layer 34: ReLU(inplace)\n",
      "2018-11-26 19:54:18,384 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 19:54:18,388 INFO Layer 35: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:54:18,412 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:54:18,415 INFO Layer 35: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:54:18,420 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:54:26,528 INFO     Weight matrix 1/9 (512,512): Alpha: 3.75592824590486, Alpha Weighted: 1.6819123193444976, D: 0.05524367572972155\n",
      "2018-11-26 19:54:26,530 INFO     Weight matrix 1/9 (512,512): Alpha 3.75592824590486 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:54:26,536 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.8957306146621704\n",
      "2018-11-26 19:54:26,540 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:54:34,009 INFO     Weight matrix 2/9 (512,512): Alpha: 4.456473912347422, Alpha Weighted: 2.2083113793781406, D: 0.07544540249873322\n",
      "2018-11-26 19:54:34,012 INFO     Weight matrix 2/9 (512,512): Alpha 4.456473912347422 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:54:34,017 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9068563580513\n",
      "2018-11-26 19:54:34,020 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:54:41,222 INFO     Weight matrix 3/9 (512,512): Alpha: 3.5575891189234268, Alpha Weighted: 1.6922766200361623, D: 0.04944205028659876\n",
      "2018-11-26 19:54:41,224 INFO     Weight matrix 3/9 (512,512): Alpha 3.5575891189234268 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:54:41,232 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.8925443291664124\n",
      "2018-11-26 19:54:41,235 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:54:48,361 INFO     Weight matrix 4/9 (512,512): Alpha: 4.145154498978875, Alpha Weighted: 1.9831188415539656, D: 0.04761904761904889\n",
      "2018-11-26 19:54:48,363 INFO     Weight matrix 4/9 (512,512): Alpha 4.145154498978875 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:54:48,369 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8806775212287903\n",
      "2018-11-26 19:54:48,372 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:54:56,571 INFO     Weight matrix 5/9 (512,512): Alpha: 2.546585081102248, Alpha Weighted: 1.3737232686833303, D: 0.06384846322642751\n",
      "2018-11-26 19:54:56,576 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9132047295570374\n",
      "2018-11-26 19:54:56,579 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:55:03,566 INFO     Weight matrix 6/9 (512,512): Alpha: 4.0853541551550965, Alpha Weighted: 2.102187042238553, D: 0.043010614012304216\n",
      "2018-11-26 19:55:03,569 INFO     Weight matrix 6/9 (512,512): Alpha 4.0853541551550965 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:55:03,577 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8782057166099548\n",
      "2018-11-26 19:55:03,581 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:55:10,399 INFO     Weight matrix 7/9 (512,512): Alpha: 3.5475118080497956, Alpha Weighted: 1.6438253313926723, D: 0.033862367560223317\n",
      "2018-11-26 19:55:10,402 INFO     Weight matrix 7/9 (512,512): Alpha 3.5475118080497956 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:55:10,407 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.8934467434883118\n",
      "2018-11-26 19:55:10,411 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:55:17,244 INFO     Weight matrix 8/9 (512,512): Alpha: 3.413974500033326, Alpha Weighted: 1.7588199011936216, D: 0.06447316260939012\n",
      "2018-11-26 19:55:17,249 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9045956134796143\n",
      "2018-11-26 19:55:17,253 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:55:24,044 INFO     Weight matrix 9/9 (512,512): Alpha: 3.570278192780703, Alpha Weighted: 1.792931595864832, D: 0.03766192324304812\n",
      "2018-11-26 19:55:24,046 INFO     Weight matrix 9/9 (512,512): Alpha 3.570278192780703 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:55:24,051 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.8923517465591431\n",
      "2018-11-26 19:55:24,055 INFO Layer 36: ReLU(inplace)\n",
      "2018-11-26 19:55:24,058 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 19:55:24,060 INFO Layer 37: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 19:55:24,084 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 19:55:24,086 INFO Layer 37: Analyzing 9 weight matrices...\n",
      "2018-11-26 19:55:24,090 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:55:30,958 INFO     Weight matrix 1/9 (512,512): Alpha: 4.235156843778798, Alpha Weighted: 2.689778686009549, D: 0.06433572059234782\n",
      "2018-11-26 19:55:30,961 INFO     Weight matrix 1/9 (512,512): Alpha 4.235156843778798 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:55:30,967 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.873379111289978\n",
      "2018-11-26 19:55:30,969 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:55:37,765 INFO     Weight matrix 2/9 (512,512): Alpha: 4.1341928356203095, Alpha Weighted: 2.6684605827716443, D: 0.07290044769114074\n",
      "2018-11-26 19:55:37,767 INFO     Weight matrix 2/9 (512,512): Alpha 4.1341928356203095 is in the danger zone (1.5,3.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 19:55:37,774 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.8897672295570374\n",
      "2018-11-26 19:55:37,777 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:55:44,606 INFO     Weight matrix 3/9 (512,512): Alpha: 4.302473496906013, Alpha Weighted: 2.580301978188108, D: 0.0696686940412331\n",
      "2018-11-26 19:55:44,609 INFO     Weight matrix 3/9 (512,512): Alpha 4.302473496906013 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:55:44,614 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.8731842041015625\n",
      "2018-11-26 19:55:44,617 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:55:51,425 INFO     Weight matrix 4/9 (512,512): Alpha: 4.463590817616467, Alpha Weighted: 2.633470310146523, D: 0.0678083782251172\n",
      "2018-11-26 19:55:51,429 INFO     Weight matrix 4/9 (512,512): Alpha 4.463590817616467 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:55:51,437 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.86763995885849\n",
      "2018-11-26 19:55:51,441 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:55:58,294 INFO     Weight matrix 5/9 (512,512): Alpha: 3.0278520564957354, Alpha Weighted: 1.8783704444657887, D: 0.06558376247302289\n",
      "2018-11-26 19:55:58,299 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.8991679549217224\n",
      "2018-11-26 19:55:58,301 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:56:05,142 INFO     Weight matrix 6/9 (512,512): Alpha: 4.379190116882187, Alpha Weighted: 2.434838554610994, D: 0.058810376219059546\n",
      "2018-11-26 19:56:05,144 INFO     Weight matrix 6/9 (512,512): Alpha 4.379190116882187 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:56:05,153 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8683586716651917\n",
      "2018-11-26 19:56:05,157 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:56:12,006 INFO     Weight matrix 7/9 (512,512): Alpha: 3.984519287788257, Alpha Weighted: 2.535557303256564, D: 0.062917818271303\n",
      "2018-11-26 19:56:12,009 INFO     Weight matrix 7/9 (512,512): Alpha 3.984519287788257 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:56:12,015 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.8718577027320862\n",
      "2018-11-26 19:56:12,020 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:56:18,809 INFO     Weight matrix 8/9 (512,512): Alpha: 4.129116725894174, Alpha Weighted: 2.5927681488573624, D: 0.05358264227810505\n",
      "2018-11-26 19:56:18,812 INFO     Weight matrix 8/9 (512,512): Alpha 4.129116725894174 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:56:18,818 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.8878435492515564\n",
      "2018-11-26 19:56:18,820 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 19:56:25,820 INFO     Weight matrix 9/9 (512,512): Alpha: 4.279781316099268, Alpha Weighted: 2.4774252694754524, D: 0.049456056699481166\n",
      "2018-11-26 19:56:25,822 INFO     Weight matrix 9/9 (512,512): Alpha 4.279781316099268 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 19:56:25,829 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.8700430393218994\n",
      "2018-11-26 19:56:25,832 INFO Layer 38: ReLU(inplace)\n",
      "2018-11-26 19:56:25,835 INFO Layer 38: Skipping (Layer not supported)\n",
      "2018-11-26 19:56:25,840 INFO Layer 39: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 19:56:25,843 INFO Layer 39: Skipping (Layer not supported)\n",
      "2018-11-26 19:56:25,846 INFO Layer 40: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 19:56:25,848 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 19:56:25,851 INFO Layer 41: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 19:56:27,921 INFO Layer 41: Analyzing 1 weight matrices...\n",
      "2018-11-26 19:56:27,924 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 20:07:27,884 INFO     Weight matrix 1/1 (4096,25088): Alpha: 2.2714985302964443, Alpha Weighted: 3.2271208361989396, D: 0.024841196673464183\n",
      "2018-11-26 20:07:27,924 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.6810033321380615\n",
      "2018-11-26 20:07:28,032 INFO Layer 42: ReLU(inplace)\n",
      "2018-11-26 20:07:28,130 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 20:07:28,132 INFO Layer 43: Dropout(p=0.5)\n",
      "2018-11-26 20:07:28,135 INFO Layer 43: Skipping (Layer not supported)\n",
      "2018-11-26 20:07:28,137 INFO Layer 44: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 20:07:28,248 INFO Layer 44: Analyzing 1 weight matrices...\n",
      "2018-11-26 20:07:28,251 INFO     Weight matrix 1/1 (4096,4096): Analyzing ...\n",
      "2018-11-26 20:13:09,586 INFO     Weight matrix 1/1 (4096,4096): Alpha: 2.1879220486952944, Alpha Weighted: 3.591570016580016, D: 0.03132573714166986\n",
      "2018-11-26 20:13:09,597 INFO     Weight matrix 1/1 (4096,4096): Lognorm: 1.5991524457931519\n",
      "2018-11-26 20:13:09,630 INFO Layer 45: ReLU(inplace)\n",
      "2018-11-26 20:13:09,654 INFO Layer 45: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:09,657 INFO Layer 46: Dropout(p=0.5)\n",
      "2018-11-26 20:13:09,660 INFO Layer 46: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:09,665 INFO Layer 47: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 20:13:09,700 INFO Layer 47: Analyzing 1 weight matrices...\n",
      "2018-11-26 20:13:09,703 INFO     Weight matrix 1/1 (1000,4096): Analyzing ...\n",
      "2018-11-26 20:13:34,624 INFO     Weight matrix 1/1 (1000,4096): Alpha: 2.0714807258587102, Alpha Weighted: 3.5702328649378576, D: 0.03703639711706991\n",
      "2018-11-26 20:13:34,628 INFO     Weight matrix 1/1 (1000,4096): Lognorm: 1.5652965307235718\n",
      "2018-11-26 20:13:34,653 INFO ### Printing results ###\n",
      "2018-11-26 20:13:34,656 DEBUG Layer 4: Lognorm compound: 0.5500112970670065\n",
      "2018-11-26 20:13:34,659 DEBUG Layer 7: Lognorm compound: 0.6403023997942606\n",
      "2018-11-26 20:13:34,661 DEBUG Layer 9: Lognorm compound: 0.6873413258128696\n",
      "2018-11-26 20:13:34,663 DEBUG Layer 12: Lognorm compound: 0.7377265757984586\n",
      "2018-11-26 20:13:34,666 DEBUG Layer 14: Lognorm compound: 0.7676579488648309\n",
      "2018-11-26 20:13:34,669 DEBUG Layer 16: Lognorm compound: 0.7656850020090739\n",
      "2018-11-26 20:13:34,671 DEBUG Layer 18: Lognorm compound: 0.776256885793474\n",
      "2018-11-26 20:13:34,674 DEBUG Layer 21: Lognorm compound: 0.8575417266951667\n",
      "2018-11-26 20:13:34,677 DEBUG Layer 23: Lognorm compound: 0.888799422317081\n",
      "2018-11-26 20:13:34,681 DEBUG Layer 25: Lognorm compound: 0.8750377496083578\n",
      "2018-11-26 20:13:34,684 DEBUG Layer 27: Lognorm compound: 0.8735736807187399\n",
      "2018-11-26 20:13:34,691 DEBUG Layer 30: Lognorm compound: 0.9092632797029283\n",
      "2018-11-26 20:13:34,694 DEBUG Layer 32: Lognorm compound: 0.9096339278750949\n",
      "2018-11-26 20:13:34,696 DEBUG Layer 34: Lognorm compound: 0.8952903747558594\n",
      "2018-11-26 20:13:34,700 DEBUG Layer 36: Lognorm compound: 0.8779157135221693\n",
      "2018-11-26 20:13:34,703 DEBUG Layer 40: Lognorm: 1.6810033321380615\n",
      "2018-11-26 20:13:34,707 DEBUG Layer 43: Lognorm: 1.5991524457931519\n",
      "2018-11-26 20:13:34,710 DEBUG Layer 46: Lognorm: 1.5652965307235718\n",
      "2018-11-26 20:13:34,712 INFO LogNorm: min: 0.507559061050415, max: 1.6810033321380615, avg: 0.8185057640075684\n",
      "2018-11-26 20:13:34,715 INFO LogNorm compound: min: 0.5500112970670065, max: 1.6810033321380615, avg: 0.9365272010550088\n",
      "2018-11-26 20:13:34,718 DEBUG Layer 4: Alpha compound: 1.5696911586969953\n",
      "2018-11-26 20:13:34,721 DEBUG Layer 7: Alpha compound: 1.770738669678273\n",
      "2018-11-26 20:13:34,723 DEBUG Layer 9: Alpha compound: 1.8492812496839979\n",
      "2018-11-26 20:13:34,726 DEBUG Layer 12: Alpha compound: 2.475321630105684\n",
      "2018-11-26 20:13:34,729 DEBUG Layer 14: Alpha compound: 2.7921146559911865\n",
      "2018-11-26 20:13:34,731 DEBUG Layer 16: Alpha compound: 2.6433642618672963\n",
      "2018-11-26 20:13:34,733 DEBUG Layer 18: Alpha compound: 3.5555561422527027\n",
      "2018-11-26 20:13:34,735 DEBUG Layer 21: Alpha compound: 2.837002907365511\n",
      "2018-11-26 20:13:34,738 DEBUG Layer 23: Alpha compound: 3.3660667042612067\n",
      "2018-11-26 20:13:34,740 DEBUG Layer 25: Alpha compound: 3.4717149396364224\n",
      "2018-11-26 20:13:34,742 DEBUG Layer 27: Alpha compound: 3.490362220798191\n",
      "2018-11-26 20:13:34,745 DEBUG Layer 30: Alpha compound: 3.5166596147411435\n",
      "2018-11-26 20:13:34,748 DEBUG Layer 32: Alpha compound: 3.6153702584547167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 20:13:34,750 DEBUG Layer 34: Alpha compound: 3.6754277236973056\n",
      "2018-11-26 20:13:34,754 DEBUG Layer 36: Alpha compound: 4.103985944120135\n",
      "2018-11-26 20:13:34,757 DEBUG Layer 40: Alpha: 2.2714985302964443\n",
      "2018-11-26 20:13:34,760 DEBUG Layer 43: Alpha: 2.1879220486952944\n",
      "2018-11-26 20:13:34,762 DEBUG Layer 46: Alpha: 2.0714807258587102\n",
      "2018-11-26 20:13:34,765 INFO Alpha: min: 1.4433520467685375, max: 5.027316766089016, avg: 2.9646726379493287\n",
      "2018-11-26 20:13:34,768 INFO Alpha compound: min: 1.5696911586969953, max: 4.103985944120135, avg: 2.847975521455623\n",
      "2018-11-26 20:13:34,772 DEBUG Layer 4: Alpha Weighted compound: 0.55641912265304\n",
      "2018-11-26 20:13:34,774 DEBUG Layer 7: Alpha Weighted compound: 0.7669684809880764\n",
      "2018-11-26 20:13:34,779 DEBUG Layer 9: Alpha Weighted compound: 0.3858704124961989\n",
      "2018-11-26 20:13:34,782 DEBUG Layer 12: Alpha Weighted compound: 0.6535780483300521\n",
      "2018-11-26 20:13:34,785 DEBUG Layer 14: Alpha Weighted compound: 0.5583536294123683\n",
      "2018-11-26 20:13:34,787 DEBUG Layer 16: Alpha Weighted compound: 0.5823633855602502\n",
      "2018-11-26 20:13:34,789 DEBUG Layer 18: Alpha Weighted compound: 1.2121496247767285\n",
      "2018-11-26 20:13:34,791 DEBUG Layer 21: Alpha Weighted compound: 0.8860258378598826\n",
      "2018-11-26 20:13:34,794 DEBUG Layer 23: Alpha Weighted compound: 1.141042406515805\n",
      "2018-11-26 20:13:34,796 DEBUG Layer 25: Alpha Weighted compound: 1.4545778692840416\n",
      "2018-11-26 20:13:34,799 DEBUG Layer 27: Alpha Weighted compound: 1.908974259592297\n",
      "2018-11-26 20:13:34,801 DEBUG Layer 30: Alpha Weighted compound: 0.8944799969905266\n",
      "2018-11-26 20:13:34,804 DEBUG Layer 32: Alpha Weighted compound: 1.3113725202006998\n",
      "2018-11-26 20:13:34,806 DEBUG Layer 34: Alpha Weighted compound: 1.8041229221873083\n",
      "2018-11-26 20:13:34,809 DEBUG Layer 36: Alpha Weighted compound: 2.4989968086424437\n",
      "2018-11-26 20:13:34,812 DEBUG Layer 40: Alpha Weigthed: 3.2271208361989396\n",
      "2018-11-26 20:13:34,816 DEBUG Layer 43: Alpha Weigthed: 3.591570016580016\n",
      "2018-11-26 20:13:34,819 DEBUG Layer 46: Alpha Weigthed: 3.5702328649378576\n",
      "2018-11-26 20:13:34,823 INFO Alpha Weighted: min: 0.21452579708070746, max: 3.591570016580016, avg: 1.1588882728052485\n",
      "2018-11-26 20:13:34,825 INFO Alpha Weighted compound: min: 0.3858704124961989, max: 3.591570016580016, avg: 1.5002343912892515\n"
     ]
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.vgg19(pretrained=True)\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "results = watcher.analyze(compute_alphas=True)\n",
    "\n",
    "data.append({\"name\": \"vgg19torch\", \"summary\": watcher.get_summary()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T04:39:18.579244Z",
     "start_time": "2018-11-27T04:13:35.065021Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 20:13:42,296 INFO \n",
      "WeightWatcher v0.1 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 20:13:42,299 INFO Analyzing model\n",
      "2018-11-26 20:13:42,303 INFO Layer 1: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace)\n",
      "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 20:13:42,306 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:42,309 INFO Layer 2: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace)\n",
      "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace)\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU(inplace)\n",
      "  (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU(inplace)\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (16): ReLU(inplace)\n",
      "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (19): ReLU(inplace)\n",
      "  (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (22): ReLU(inplace)\n",
      "  (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (25): ReLU(inplace)\n",
      "  (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (29): ReLU(inplace)\n",
      "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (32): ReLU(inplace)\n",
      "  (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (35): ReLU(inplace)\n",
      "  (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (38): ReLU(inplace)\n",
      "  (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (42): ReLU(inplace)\n",
      "  (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (45): ReLU(inplace)\n",
      "  (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (48): ReLU(inplace)\n",
      "  (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (51): ReLU(inplace)\n",
      "  (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 20:13:42,312 INFO Layer 2: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:42,318 INFO Layer 3: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:13:42,321 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:13:42,325 INFO Layer 3: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:13:42,328 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 20:13:42,331 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 20:13:42,334 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 20:13:42,338 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 20:13:42,342 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 20:13:42,346 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 20:13:42,352 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 20:13:42,354 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 20:13:42,357 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 20:13:42,361 INFO Layer 4: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:13:42,363 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:42,365 INFO Layer 5: ReLU(inplace)\n",
      "2018-11-26 20:13:42,367 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:42,369 INFO Layer 6: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:13:42,376 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:13:42,379 INFO Layer 6: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:13:42,382 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 20:13:42,864 INFO     Weight matrix 1/9 (64,64): Alpha: 3.0726811832942302, Alpha Weighted: -0.06224750327449201, D: 0.2000000000000005\n",
      "2018-11-26 20:13:42,869 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.21840748190879822\n",
      "2018-11-26 20:13:42,872 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 20:13:43,188 INFO     Weight matrix 2/9 (64,64): Alpha: 2.4106269178904016, Alpha Weighted: 0.45840411143333326, D: 0.16889785261789775\n",
      "2018-11-26 20:13:43,191 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.300492525100708\n",
      "2018-11-26 20:13:43,194 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 20:13:43,535 INFO     Weight matrix 3/9 (64,64): Alpha: 1.690531407476214, Alpha Weighted: -0.17032384687729846, D: 0.21886507099897806\n",
      "2018-11-26 20:13:43,537 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.22294633090496063\n",
      "2018-11-26 20:13:43,540 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 20:13:43,918 INFO     Weight matrix 4/9 (64,64): Alpha: 1.5286226714306121, Alpha Weighted: 0.38563668601187734, D: 0.22748990755495269\n",
      "2018-11-26 20:13:43,921 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.335318922996521\n",
      "2018-11-26 20:13:43,923 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 20:13:44,226 INFO     Weight matrix 5/9 (64,64): Alpha: 2.1879396535560645, Alpha Weighted: 1.057168260983391, D: 0.18750991043857057\n",
      "2018-11-26 20:13:44,228 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.4457348585128784\n",
      "2018-11-26 20:13:44,231 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 20:13:44,572 INFO     Weight matrix 6/9 (64,64): Alpha: 2.199505546666523, Alpha Weighted: 0.40058705001821604, D: 0.184022835482071\n",
      "2018-11-26 20:13:44,575 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.3114398717880249\n",
      "2018-11-26 20:13:44,578 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 20:13:44,937 INFO     Weight matrix 7/9 (64,64): Alpha: 2.896216425452018, Alpha Weighted: -0.036014910922478105, D: 0.21519382219987288\n",
      "2018-11-26 20:13:44,942 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.2702086865901947\n",
      "2018-11-26 20:13:44,945 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 20:13:45,302 INFO     Weight matrix 8/9 (64,64): Alpha: 1.6809749128571834, Alpha Weighted: 0.3197788161721111, D: 0.19724395769196257\n",
      "2018-11-26 20:13:45,305 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.31995895504951477\n",
      "2018-11-26 20:13:45,307 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 20:13:45,689 INFO     Weight matrix 9/9 (64,64): Alpha: 4.079719042799393, Alpha Weighted: -0.3700095154954038, D: 0.2500000000000009\n",
      "2018-11-26 20:13:45,691 INFO     Weight matrix 9/9 (64,64): Alpha 4.079719042799393 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:13:45,696 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.21745115518569946\n",
      "2018-11-26 20:13:45,698 INFO Layer 7: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:13:45,701 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:45,704 INFO Layer 8: ReLU(inplace)\n",
      "2018-11-26 20:13:45,706 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:45,709 INFO Layer 9: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 20:13:45,712 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:45,715 INFO Layer 10: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:13:45,719 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:13:45,721 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:13:45,724 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 20:13:46,160 INFO     Weight matrix 1/9 (64,128): Alpha: 1.6261398978887343, Alpha Weighted: 0.3712727539165708, D: 0.15856147620677402\n",
      "2018-11-26 20:13:46,163 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.4144156277179718\n",
      "2018-11-26 20:13:46,166 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 20:13:46,559 INFO     Weight matrix 2/9 (64,128): Alpha: 1.5927197056439097, Alpha Weighted: 0.7466424234461061, D: 0.1322532036932924\n",
      "2018-11-26 20:13:46,564 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.5095121264457703\n",
      "2018-11-26 20:13:46,567 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 20:13:46,972 INFO     Weight matrix 3/9 (64,128): Alpha: 1.9455480010941124, Alpha Weighted: 0.4809817583875681, D: 0.1354197420419856\n",
      "2018-11-26 20:13:46,977 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.41107144951820374\n",
      "2018-11-26 20:13:46,980 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 20:13:47,381 INFO     Weight matrix 4/9 (64,128): Alpha: 1.5105249374631677, Alpha Weighted: 0.6122906976735378, D: 0.15923695084095318\n",
      "2018-11-26 20:13:47,384 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.5117618441581726\n",
      "2018-11-26 20:13:47,387 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 20:13:47,787 INFO     Weight matrix 5/9 (64,128): Alpha: 1.5297252314397343, Alpha Weighted: 0.9042716099631922, D: 0.1522474155790567\n",
      "2018-11-26 20:13:47,790 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.639792263507843\n",
      "2018-11-26 20:13:47,793 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 20:13:48,208 INFO     Weight matrix 6/9 (64,128): Alpha: 1.5678715524531706, Alpha Weighted: 0.6327102646108371, D: 0.15257219684436873\n",
      "2018-11-26 20:13:48,213 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.5174331665039062\n",
      "2018-11-26 20:13:48,216 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 20:13:48,624 INFO     Weight matrix 7/9 (64,128): Alpha: 1.7362179081071523, Alpha Weighted: 0.4833022739979021, D: 0.136575722520052\n",
      "2018-11-26 20:13:48,628 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.43038251996040344\n",
      "2018-11-26 20:13:48,633 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 20:13:49,031 INFO     Weight matrix 8/9 (64,128): Alpha: 1.5917231919070334, Alpha Weighted: 0.6962408546504701, D: 0.1542117015844543\n",
      "2018-11-26 20:13:49,036 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.5156136155128479\n",
      "2018-11-26 20:13:49,041 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 20:13:49,457 INFO     Weight matrix 9/9 (64,128): Alpha: 1.8819877872605435, Alpha Weighted: 0.6364257374441226, D: 0.12140758040134259\n",
      "2018-11-26 20:13:49,462 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.43336403369903564\n",
      "2018-11-26 20:13:49,464 INFO Layer 11: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:13:49,467 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:49,469 INFO Layer 12: ReLU(inplace)\n",
      "2018-11-26 20:13:49,471 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:49,474 INFO Layer 13: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:13:49,480 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:13:49,482 INFO Layer 13: Analyzing 9 weight matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 20:13:49,485 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 20:13:50,352 INFO     Weight matrix 1/9 (128,128): Alpha: 2.0280690877636642, Alpha Weighted: -0.06711883754213469, D: 0.18823260159793875\n",
      "2018-11-26 20:13:50,355 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.45874765515327454\n",
      "2018-11-26 20:13:50,359 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 20:13:51,194 INFO     Weight matrix 2/9 (128,128): Alpha: 2.0005068502827275, Alpha Weighted: 0.18779182404494077, D: 0.18921697605667082\n",
      "2018-11-26 20:13:51,198 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.5332913398742676\n",
      "2018-11-26 20:13:51,201 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 20:13:52,107 INFO     Weight matrix 3/9 (128,128): Alpha: 2.908118711346095, Alpha Weighted: -0.37484469026724104, D: 0.17740990008854812\n",
      "2018-11-26 20:13:52,112 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.4506426155567169\n",
      "2018-11-26 20:13:52,118 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 20:13:52,976 INFO     Weight matrix 4/9 (128,128): Alpha: 1.920100498508883, Alpha Weighted: 0.17963705441368907, D: 0.20997714733918899\n",
      "2018-11-26 20:13:52,979 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.5402300357818604\n",
      "2018-11-26 20:13:52,982 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 20:13:53,822 INFO     Weight matrix 5/9 (128,128): Alpha: 2.8944534337115178, Alpha Weighted: 0.8052209021499531, D: 0.18607418558660138\n",
      "2018-11-26 20:13:53,825 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.6339673399925232\n",
      "2018-11-26 20:13:53,830 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 20:13:54,678 INFO     Weight matrix 6/9 (128,128): Alpha: 3.226443888659024, Alpha Weighted: 0.4108499924882686, D: 0.19342375040419368\n",
      "2018-11-26 20:13:54,681 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.5432183146476746\n",
      "2018-11-26 20:13:54,687 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 20:13:55,564 INFO     Weight matrix 7/9 (128,128): Alpha: 2.4050142360040967, Alpha Weighted: -0.2789080331140063, D: 0.2010500464187217\n",
      "2018-11-26 20:13:55,567 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.46046313643455505\n",
      "2018-11-26 20:13:55,570 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 20:13:56,449 INFO     Weight matrix 8/9 (128,128): Alpha: 2.9707552960741346, Alpha Weighted: 0.22039101174493883, D: 0.17739032238054753\n",
      "2018-11-26 20:13:56,454 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.5355432629585266\n",
      "2018-11-26 20:13:56,595 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 20:13:57,446 INFO     Weight matrix 9/9 (128,128): Alpha: 3.123710461044143, Alpha Weighted: -0.13521228926962495, D: 0.1909689724053213\n",
      "2018-11-26 20:13:57,449 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.4679080545902252\n",
      "2018-11-26 20:13:57,452 INFO Layer 14: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:13:57,454 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:57,457 INFO Layer 15: ReLU(inplace)\n",
      "2018-11-26 20:13:57,459 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:57,462 INFO Layer 16: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 20:13:57,465 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 20:13:57,468 INFO Layer 17: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:13:57,478 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:13:57,482 INFO Layer 17: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:13:57,484 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 20:13:58,505 INFO     Weight matrix 1/9 (128,256): Alpha: 4.879371548361345, Alpha Weighted: -0.26649973867723964, D: 0.14285714285714257\n",
      "2018-11-26 20:13:58,508 INFO     Weight matrix 1/9 (128,256): Alpha 4.879371548361345 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:13:58,514 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.5310695767402649\n",
      "2018-11-26 20:13:58,519 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 20:13:59,521 INFO     Weight matrix 2/9 (128,256): Alpha: 2.2738080833253393, Alpha Weighted: 0.15917117451420656, D: 0.18006494264819495\n",
      "2018-11-26 20:13:59,526 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.613785445690155\n",
      "2018-11-26 20:13:59,529 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 20:14:00,554 INFO     Weight matrix 3/9 (128,256): Alpha: 4.211889917190117, Alpha Weighted: 0.039601853650084264, D: 0.12103488717612165\n",
      "2018-11-26 20:14:00,556 INFO     Weight matrix 3/9 (128,256): Alpha 4.211889917190117 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:14:00,560 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.5367623567581177\n",
      "2018-11-26 20:14:00,563 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 20:14:01,562 INFO     Weight matrix 4/9 (128,256): Alpha: 2.3361061758675383, Alpha Weighted: 0.16317520099269506, D: 0.16859311398649285\n",
      "2018-11-26 20:14:01,567 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.6148995161056519\n",
      "2018-11-26 20:14:01,570 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 20:14:02,552 INFO     Weight matrix 5/9 (128,256): Alpha: 2.0687028957652736, Alpha Weighted: 0.9418127411869414, D: 0.19603400581629116\n",
      "2018-11-26 20:14:02,555 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.7892506718635559\n",
      "2018-11-26 20:14:02,559 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 20:14:03,594 INFO     Weight matrix 6/9 (128,256): Alpha: 3.218462664803351, Alpha Weighted: 0.2476569092420628, D: 0.17744769624787748\n",
      "2018-11-26 20:14:03,599 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.6199840307235718\n",
      "2018-11-26 20:14:03,602 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 20:14:04,626 INFO     Weight matrix 7/9 (128,256): Alpha: 3.2866170492523517, Alpha Weighted: -0.25703440622821655, D: 0.13841426595803163\n",
      "2018-11-26 20:14:04,630 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.5239893794059753\n",
      "2018-11-26 20:14:04,634 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 20:14:05,649 INFO     Weight matrix 8/9 (128,256): Alpha: 2.4878967518122272, Alpha Weighted: 0.25729356589235325, D: 0.18531854375394763\n",
      "2018-11-26 20:14:05,653 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.6102331280708313\n",
      "2018-11-26 20:14:05,655 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 20:14:06,650 INFO     Weight matrix 9/9 (128,256): Alpha: 3.5914272917865686, Alpha Weighted: 0.002905132465350387, D: 0.14778910907156606\n",
      "2018-11-26 20:14:06,653 INFO     Weight matrix 9/9 (128,256): Alpha 3.5914272917865686 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:14:06,658 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.5336019992828369\n",
      "2018-11-26 20:14:06,660 INFO Layer 18: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:14:06,663 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 20:14:06,666 INFO Layer 19: ReLU(inplace)\n",
      "2018-11-26 20:14:06,670 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 20:14:06,672 INFO Layer 20: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:14:06,690 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:14:06,693 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:14:06,696 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:09,018 INFO     Weight matrix 1/9 (256,256): Alpha: 2.1753589310529673, Alpha Weighted: -0.28533902086891266, D: 0.15537247203315058\n",
      "2018-11-26 20:14:09,023 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.597944974899292\n",
      "2018-11-26 20:14:09,025 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:11,308 INFO     Weight matrix 2/9 (256,256): Alpha: 2.065528863671304, Alpha Weighted: -0.03335699371197215, D: 0.15570404036802488\n",
      "2018-11-26 20:14:11,312 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6460882425308228\n",
      "2018-11-26 20:14:11,317 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:13,623 INFO     Weight matrix 3/9 (256,256): Alpha: 2.8274106070070135, Alpha Weighted: -0.2770162725501652, D: 0.15462008052557974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 20:14:13,627 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.6013931632041931\n",
      "2018-11-26 20:14:13,631 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:15,896 INFO     Weight matrix 4/9 (256,256): Alpha: 1.9950514846548504, Alpha Weighted: 0.008495457486345642, D: 0.1584042288384152\n",
      "2018-11-26 20:14:15,901 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.639593243598938\n",
      "2018-11-26 20:14:15,903 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:18,094 INFO     Weight matrix 5/9 (256,256): Alpha: 1.8127482278781142, Alpha Weighted: 0.805199224822532, D: 0.14076541701559198\n",
      "2018-11-26 20:14:18,098 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.7612729668617249\n",
      "2018-11-26 20:14:18,102 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:20,560 INFO     Weight matrix 6/9 (256,256): Alpha: 1.93477149285635, Alpha Weighted: 0.06834562652039393, D: 0.14552143178267474\n",
      "2018-11-26 20:14:20,564 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6452199816703796\n",
      "2018-11-26 20:14:20,567 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:22,882 INFO     Weight matrix 7/9 (256,256): Alpha: 2.4688747354246363, Alpha Weighted: -0.18469714011017446, D: 0.14323128958137887\n",
      "2018-11-26 20:14:22,887 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5974608659744263\n",
      "2018-11-26 20:14:22,893 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:25,280 INFO     Weight matrix 8/9 (256,256): Alpha: 1.9071004229931385, Alpha Weighted: 0.10631959341516575, D: 0.15084525274411753\n",
      "2018-11-26 20:14:25,285 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6414697170257568\n",
      "2018-11-26 20:14:25,288 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:27,593 INFO     Weight matrix 9/9 (256,256): Alpha: 2.387269182157083, Alpha Weighted: -0.3389131915749118, D: 0.15729890636929234\n",
      "2018-11-26 20:14:27,597 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6011737585067749\n",
      "2018-11-26 20:14:27,601 INFO Layer 21: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:14:27,604 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 20:14:27,606 INFO Layer 22: ReLU(inplace)\n",
      "2018-11-26 20:14:27,609 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 20:14:27,614 INFO Layer 23: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:14:27,643 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:14:27,645 INFO Layer 23: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:14:27,648 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:30,055 INFO     Weight matrix 1/9 (256,256): Alpha: 3.0976123956492603, Alpha Weighted: -0.35742173248721837, D: 0.1391014872248436\n",
      "2018-11-26 20:14:30,058 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.6036368012428284\n",
      "2018-11-26 20:14:30,062 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:32,425 INFO     Weight matrix 2/9 (256,256): Alpha: 2.3385546099427397, Alpha Weighted: 0.08320584685875375, D: 0.15100292602964943\n",
      "2018-11-26 20:14:32,430 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6581083536148071\n",
      "2018-11-26 20:14:32,432 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:34,840 INFO     Weight matrix 3/9 (256,256): Alpha: 3.2951314401876868, Alpha Weighted: -0.37013002627779545, D: 0.12911878836197221\n",
      "2018-11-26 20:14:34,843 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.603336751461029\n",
      "2018-11-26 20:14:34,848 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:37,234 INFO     Weight matrix 4/9 (256,256): Alpha: 2.493147123485361, Alpha Weighted: 0.04393431193055538, D: 0.14900053595505108\n",
      "2018-11-26 20:14:37,239 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.6571877002716064\n",
      "2018-11-26 20:14:37,241 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:39,546 INFO     Weight matrix 5/9 (256,256): Alpha: 1.7927104704077554, Alpha Weighted: 0.7036966376600489, D: 0.14470529398248583\n",
      "2018-11-26 20:14:39,551 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.7762420177459717\n",
      "2018-11-26 20:14:39,553 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:41,913 INFO     Weight matrix 6/9 (256,256): Alpha: 2.7426655406127027, Alpha Weighted: 0.12223075094118732, D: 0.13964383592878715\n",
      "2018-11-26 20:14:41,918 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6580830216407776\n",
      "2018-11-26 20:14:41,921 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:44,348 INFO     Weight matrix 7/9 (256,256): Alpha: 2.7449075154286704, Alpha Weighted: -0.3184837661840888, D: 0.13655223129751148\n",
      "2018-11-26 20:14:44,353 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.6029641628265381\n",
      "2018-11-26 20:14:44,356 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:46,978 INFO     Weight matrix 8/9 (256,256): Alpha: 2.020290298625512, Alpha Weighted: -0.002743663313588393, D: 0.15423687696021537\n",
      "2018-11-26 20:14:46,982 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6529862880706787\n",
      "2018-11-26 20:14:46,987 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:49,738 INFO     Weight matrix 9/9 (256,256): Alpha: 2.991734635747582, Alpha Weighted: -0.2976553075234264, D: 0.11579951729591931\n",
      "2018-11-26 20:14:49,742 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6026991009712219\n",
      "2018-11-26 20:14:49,746 INFO Layer 24: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:14:49,749 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 20:14:49,753 INFO Layer 25: ReLU(inplace)\n",
      "2018-11-26 20:14:49,760 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 20:14:49,763 INFO Layer 26: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:14:49,770 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:14:49,776 INFO Layer 26: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:14:49,783 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:52,476 INFO     Weight matrix 1/9 (256,256): Alpha: 3.781784780751175, Alpha Weighted: -0.2693006572481955, D: 0.11779380128729411\n",
      "2018-11-26 20:14:52,479 INFO     Weight matrix 1/9 (256,256): Alpha 3.781784780751175 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:14:52,483 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.6345688104629517\n",
      "2018-11-26 20:14:52,486 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:55,065 INFO     Weight matrix 2/9 (256,256): Alpha: 2.3977767206513048, Alpha Weighted: 0.0953327464472519, D: 0.15997487012216982\n",
      "2018-11-26 20:14:55,070 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6998108625411987\n",
      "2018-11-26 20:14:55,072 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:57,555 INFO     Weight matrix 3/9 (256,256): Alpha: 2.488175161959539, Alpha Weighted: -0.14061810886956308, D: 0.12806699912250763\n",
      "2018-11-26 20:14:57,561 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.6464446783065796\n",
      "2018-11-26 20:14:57,564 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:14:59,914 INFO     Weight matrix 4/9 (256,256): Alpha: 2.8447022448369625, Alpha Weighted: 0.2283188997888463, D: 0.12997276948698588\n",
      "2018-11-26 20:14:59,919 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.6928083896636963\n",
      "2018-11-26 20:14:59,922 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:15:02,267 INFO     Weight matrix 5/9 (256,256): Alpha: 2.2064579004292035, Alpha Weighted: 0.6326877061033156, D: 0.14800023092000997\n",
      "2018-11-26 20:15:02,273 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.7969152331352234\n",
      "2018-11-26 20:15:02,275 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:15:04,631 INFO     Weight matrix 6/9 (256,256): Alpha: 2.820409415514228, Alpha Weighted: 0.2205375593493299, D: 0.13970908328045895\n",
      "2018-11-26 20:15:04,637 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6999793648719788\n",
      "2018-11-26 20:15:04,643 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:15:07,019 INFO     Weight matrix 7/9 (256,256): Alpha: 2.648178199509183, Alpha Weighted: -0.12286412187713475, D: 0.1096947191544917\n",
      "2018-11-26 20:15:07,023 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.6383600831031799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 20:15:07,025 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:15:09,433 INFO     Weight matrix 8/9 (256,256): Alpha: 1.9999577073860686, Alpha Weighted: 0.08865452091839444, D: 0.15522692403715888\n",
      "2018-11-26 20:15:09,438 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6982215642929077\n",
      "2018-11-26 20:15:09,441 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 20:15:11,879 INFO     Weight matrix 9/9 (256,256): Alpha: 2.329495120652312, Alpha Weighted: -0.10964510986791628, D: 0.12943892634354648\n",
      "2018-11-26 20:15:11,883 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6461830735206604\n",
      "2018-11-26 20:15:11,886 INFO Layer 27: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:15:11,891 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 20:15:11,897 INFO Layer 28: ReLU(inplace)\n",
      "2018-11-26 20:15:11,902 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 20:15:11,907 INFO Layer 29: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 20:15:11,911 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 20:15:11,916 INFO Layer 30: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:15:11,943 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:15:11,947 INFO Layer 30: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:15:11,950 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 20:15:14,510 INFO     Weight matrix 1/9 (256,512): Alpha: 2.302846600449656, Alpha Weighted: 0.09335473844941328, D: 0.1301431775807872\n",
      "2018-11-26 20:15:14,515 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.7397401332855225\n",
      "2018-11-26 20:15:14,517 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 20:15:17,064 INFO     Weight matrix 2/9 (256,512): Alpha: 2.2331443488271168, Alpha Weighted: 0.45282674720491206, D: 0.12796933226489166\n",
      "2018-11-26 20:15:17,068 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.7917366027832031\n",
      "2018-11-26 20:15:17,071 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 20:15:19,656 INFO     Weight matrix 3/9 (256,512): Alpha: 2.424992813012353, Alpha Weighted: 0.04407312497277425, D: 0.12910020964885094\n",
      "2018-11-26 20:15:19,661 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.7406051158905029\n",
      "2018-11-26 20:15:19,664 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 20:15:22,188 INFO     Weight matrix 4/9 (256,512): Alpha: 2.052070246220387, Alpha Weighted: 0.5544313701749246, D: 0.12930255279557873\n",
      "2018-11-26 20:15:22,199 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.7971042394638062\n",
      "2018-11-26 20:15:22,201 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 20:15:24,743 INFO     Weight matrix 5/9 (256,512): Alpha: 3.0827593238367146, Alpha Weighted: 0.948442050615638, D: 0.1708034828084316\n",
      "2018-11-26 20:15:24,747 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.8910054564476013\n",
      "2018-11-26 20:15:24,750 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 20:15:27,272 INFO     Weight matrix 6/9 (256,512): Alpha: 2.3252567568220943, Alpha Weighted: 0.6203781245190889, D: 0.11709074644704764\n",
      "2018-11-26 20:15:27,276 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.7986612319946289\n",
      "2018-11-26 20:15:27,279 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 20:15:29,859 INFO     Weight matrix 7/9 (256,512): Alpha: 2.631724847363615, Alpha Weighted: 0.04113394095973285, D: 0.12543403246722173\n",
      "2018-11-26 20:15:29,863 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.7354503273963928\n",
      "2018-11-26 20:15:29,866 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 20:15:32,390 INFO     Weight matrix 8/9 (256,512): Alpha: 4.775273661278758, Alpha Weighted: 0.8879701595118581, D: 0.13325739643939566\n",
      "2018-11-26 20:15:32,393 INFO     Weight matrix 8/9 (256,512): Alpha 4.775273661278758 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:15:32,398 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.7900216579437256\n",
      "2018-11-26 20:15:32,401 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 20:15:34,961 INFO     Weight matrix 9/9 (256,512): Alpha: 2.435159190252935, Alpha Weighted: 0.03212384181917728, D: 0.13049610791857297\n",
      "2018-11-26 20:15:34,965 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.7358574867248535\n",
      "2018-11-26 20:15:34,968 INFO Layer 31: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:15:34,972 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 20:15:34,975 INFO Layer 32: ReLU(inplace)\n",
      "2018-11-26 20:15:34,978 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 20:15:34,980 INFO Layer 33: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:15:35,020 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:15:35,023 INFO Layer 33: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:15:35,026 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:15:41,642 INFO     Weight matrix 1/9 (512,512): Alpha: 3.3093782289668, Alpha Weighted: 0.4029253704711496, D: 0.07236242333823922\n",
      "2018-11-26 20:15:41,647 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.8281330466270447\n",
      "2018-11-26 20:15:41,650 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:15:48,192 INFO     Weight matrix 2/9 (512,512): Alpha: 3.7823491597201313, Alpha Weighted: 0.7524805273507564, D: 0.09775083553955\n",
      "2018-11-26 20:15:48,195 INFO     Weight matrix 2/9 (512,512): Alpha 3.7823491597201313 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:15:48,200 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.8468279838562012\n",
      "2018-11-26 20:15:48,202 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:15:54,793 INFO     Weight matrix 3/9 (512,512): Alpha: 3.060817676793673, Alpha Weighted: 0.36962715145049324, D: 0.08782072640880356\n",
      "2018-11-26 20:15:54,798 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.8292562961578369\n",
      "2018-11-26 20:15:54,802 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:16:01,387 INFO     Weight matrix 4/9 (512,512): Alpha: 3.5353882215267327, Alpha Weighted: 0.8675443778656814, D: 0.082799869491338\n",
      "2018-11-26 20:16:01,389 INFO     Weight matrix 4/9 (512,512): Alpha 3.5353882215267327 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:16:01,395 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8427413105964661\n",
      "2018-11-26 20:16:01,399 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:16:07,892 INFO     Weight matrix 5/9 (512,512): Alpha: 3.3273488305153607, Alpha Weighted: 1.6887199440904517, D: 0.09381593980063452\n",
      "2018-11-26 20:16:07,898 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9002412557601929\n",
      "2018-11-26 20:16:07,901 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:16:14,436 INFO     Weight matrix 6/9 (512,512): Alpha: 3.547554885215146, Alpha Weighted: 0.8744447918768999, D: 0.07716221741800999\n",
      "2018-11-26 20:16:14,438 INFO     Weight matrix 6/9 (512,512): Alpha 3.547554885215146 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:16:14,444 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8424124121665955\n",
      "2018-11-26 20:16:14,450 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:16:21,064 INFO     Weight matrix 7/9 (512,512): Alpha: 3.2774558916502916, Alpha Weighted: 0.43746650183247343, D: 0.07467239940530906\n",
      "2018-11-26 20:16:21,069 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.8275229334831238\n",
      "2018-11-26 20:16:21,072 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:16:27,737 INFO     Weight matrix 8/9 (512,512): Alpha: 3.7599422085561316, Alpha Weighted: 0.7329323219126871, D: 0.09272852358819828\n",
      "2018-11-26 20:16:27,740 INFO     Weight matrix 8/9 (512,512): Alpha 3.7599422085561316 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:16:27,746 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.8414661288261414\n",
      "2018-11-26 20:16:27,749 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:16:34,520 INFO     Weight matrix 9/9 (512,512): Alpha: 3.2065201346166474, Alpha Weighted: 0.3785389524979331, D: 0.06842749434265727\n",
      "2018-11-26 20:16:34,525 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.8275265693664551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 20:16:34,528 INFO Layer 34: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:16:34,531 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 20:16:34,533 INFO Layer 35: ReLU(inplace)\n",
      "2018-11-26 20:16:34,535 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 20:16:34,537 INFO Layer 36: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:16:34,569 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:16:34,571 INFO Layer 36: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:16:34,574 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:16:41,208 INFO     Weight matrix 1/9 (512,512): Alpha: 3.0268495240086475, Alpha Weighted: 0.6503596901753796, D: 0.061380230248669676\n",
      "2018-11-26 20:16:41,215 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.838587760925293\n",
      "2018-11-26 20:16:41,218 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:16:47,779 INFO     Weight matrix 2/9 (512,512): Alpha: 3.320010268440186, Alpha Weighted: 1.0393277365490616, D: 0.06732885752111784\n",
      "2018-11-26 20:16:47,784 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.8615943193435669\n",
      "2018-11-26 20:16:47,787 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:16:54,421 INFO     Weight matrix 3/9 (512,512): Alpha: 3.326322788286143, Alpha Weighted: 0.6386925433063951, D: 0.0590254803927831\n",
      "2018-11-26 20:16:54,427 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.8391647934913635\n",
      "2018-11-26 20:16:54,430 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:17:01,045 INFO     Weight matrix 4/9 (512,512): Alpha: 3.3914562917540922, Alpha Weighted: 0.947208690507857, D: 0.07015758270784367\n",
      "2018-11-26 20:17:01,050 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8447441458702087\n",
      "2018-11-26 20:17:01,053 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:17:07,573 INFO     Weight matrix 5/9 (512,512): Alpha: 2.2022725924486917, Alpha Weighted: 1.0684981361189012, D: 0.09307884586757537\n",
      "2018-11-26 20:17:07,578 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9156336188316345\n",
      "2018-11-26 20:17:07,581 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:17:14,266 INFO     Weight matrix 6/9 (512,512): Alpha: 3.3815660064648267, Alpha Weighted: 0.9513215175383146, D: 0.07183822558670327\n",
      "2018-11-26 20:17:14,271 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.84541916847229\n",
      "2018-11-26 20:17:14,276 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:17:20,913 INFO     Weight matrix 7/9 (512,512): Alpha: 3.3006278133166664, Alpha Weighted: 0.6301060240630968, D: 0.07182301301292793\n",
      "2018-11-26 20:17:20,918 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.8383651375770569\n",
      "2018-11-26 20:17:20,921 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:17:27,496 INFO     Weight matrix 8/9 (512,512): Alpha: 3.251007242311128, Alpha Weighted: 0.9414374880825799, D: 0.07898827362444849\n",
      "2018-11-26 20:17:27,501 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.8590995073318481\n",
      "2018-11-26 20:17:27,503 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:17:34,171 INFO     Weight matrix 9/9 (512,512): Alpha: 3.0249102731261512, Alpha Weighted: 0.5856326322819437, D: 0.06479580711745131\n",
      "2018-11-26 20:17:34,176 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.837285578250885\n",
      "2018-11-26 20:17:34,178 INFO Layer 37: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:17:34,181 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 20:17:34,184 INFO Layer 38: ReLU(inplace)\n",
      "2018-11-26 20:17:34,186 INFO Layer 38: Skipping (Layer not supported)\n",
      "2018-11-26 20:17:34,189 INFO Layer 39: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:17:34,212 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:17:34,214 INFO Layer 39: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:17:34,217 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:17:40,996 INFO     Weight matrix 1/9 (512,512): Alpha: 3.472460762781775, Alpha Weighted: 1.454804999785807, D: 0.039236601699843776\n",
      "2018-11-26 20:17:41,001 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.8519115447998047\n",
      "2018-11-26 20:17:41,004 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:17:47,775 INFO     Weight matrix 2/9 (512,512): Alpha: 3.6374867260675243, Alpha Weighted: 1.6365671823111432, D: 0.054747460260020864\n",
      "2018-11-26 20:17:47,777 INFO     Weight matrix 2/9 (512,512): Alpha 3.6374867260675243 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:17:47,787 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.8782790899276733\n",
      "2018-11-26 20:17:47,790 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:17:54,632 INFO     Weight matrix 3/9 (512,512): Alpha: 3.5577742355059154, Alpha Weighted: 1.4831498021396867, D: 0.035863927454306554\n",
      "2018-11-26 20:17:54,635 INFO     Weight matrix 3/9 (512,512): Alpha 3.5577742355059154 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:17:54,640 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.8538364171981812\n",
      "2018-11-26 20:17:54,643 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:18:01,529 INFO     Weight matrix 4/9 (512,512): Alpha: 3.431766462843779, Alpha Weighted: 1.4440242256027473, D: 0.05465687320515855\n",
      "2018-11-26 20:18:01,534 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8624846339225769\n",
      "2018-11-26 20:18:01,537 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:18:08,346 INFO     Weight matrix 5/9 (512,512): Alpha: 3.176569023457318, Alpha Weighted: 1.948823956832043, D: 0.07226106084545797\n",
      "2018-11-26 20:18:08,351 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9219802021980286\n",
      "2018-11-26 20:18:08,354 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:18:15,140 INFO     Weight matrix 6/9 (512,512): Alpha: 3.4515042772609275, Alpha Weighted: 1.4079089361851884, D: 0.04447338629672659\n",
      "2018-11-26 20:18:15,144 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8637136816978455\n",
      "2018-11-26 20:18:15,147 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:18:21,925 INFO     Weight matrix 7/9 (512,512): Alpha: 3.239650911988941, Alpha Weighted: 1.3578582435036093, D: 0.04825431786209744\n",
      "2018-11-26 20:18:21,930 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.8525280356407166\n",
      "2018-11-26 20:18:21,932 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:18:28,688 INFO     Weight matrix 8/9 (512,512): Alpha: 3.4693701878036083, Alpha Weighted: 1.516114277427115, D: 0.050589946506249484\n",
      "2018-11-26 20:18:28,693 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.8773916959762573\n",
      "2018-11-26 20:18:28,696 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:18:35,504 INFO     Weight matrix 9/9 (512,512): Alpha: 3.4434600029824445, Alpha Weighted: 1.4122242580426403, D: 0.03212492968218089\n",
      "2018-11-26 20:18:35,510 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.852595329284668\n",
      "2018-11-26 20:18:35,512 INFO Layer 40: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:18:35,515 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 20:18:35,518 INFO Layer 41: ReLU(inplace)\n",
      "2018-11-26 20:18:35,520 INFO Layer 41: Skipping (Layer not supported)\n",
      "2018-11-26 20:18:35,522 INFO Layer 42: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 20:18:35,525 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 20:18:35,527 INFO Layer 43: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:18:35,551 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:18:35,555 INFO Layer 43: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:18:35,561 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:18:42,319 INFO     Weight matrix 1/9 (512,512): Alpha: 3.6893433799755546, Alpha Weighted: 0.9246554812579549, D: 0.06473655460392569\n",
      "2018-11-26 20:18:42,321 INFO     Weight matrix 1/9 (512,512): Alpha 3.6893433799755546 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:18:42,327 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.8941722512245178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 20:18:42,330 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:18:49,119 INFO     Weight matrix 2/9 (512,512): Alpha: 4.194703758421383, Alpha Weighted: 0.5504815863089784, D: 0.11932084545841293\n",
      "2018-11-26 20:18:49,123 INFO     Weight matrix 2/9 (512,512): Alpha 4.194703758421383 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:18:49,128 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9145870208740234\n",
      "2018-11-26 20:18:49,130 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:18:55,954 INFO     Weight matrix 3/9 (512,512): Alpha: 3.771843406239012, Alpha Weighted: 0.915221623981286, D: 0.07812172313788282\n",
      "2018-11-26 20:18:55,956 INFO     Weight matrix 3/9 (512,512): Alpha 3.771843406239012 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:18:55,963 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.8948215842247009\n",
      "2018-11-26 20:18:55,966 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:19:02,800 INFO     Weight matrix 4/9 (512,512): Alpha: 3.0810643163406692, Alpha Weighted: 0.39102085983291784, D: 0.1093134601494331\n",
      "2018-11-26 20:19:02,804 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8922704458236694\n",
      "2018-11-26 20:19:02,807 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:19:09,573 INFO     Weight matrix 5/9 (512,512): Alpha: 5.644501871946448, Alpha Weighted: 2.1872585385097616, D: 0.0918376505788554\n",
      "2018-11-26 20:19:09,575 INFO     Weight matrix 5/9 (512,512): Alpha 5.644501871946448 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:19:09,582 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9613443613052368\n",
      "2018-11-26 20:19:09,585 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:19:16,381 INFO     Weight matrix 6/9 (512,512): Alpha: 3.276081897379663, Alpha Weighted: 0.4369762382312305, D: 0.1004782482235495\n",
      "2018-11-26 20:19:16,386 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8932057023048401\n",
      "2018-11-26 20:19:16,389 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:19:23,309 INFO     Weight matrix 7/9 (512,512): Alpha: 3.6117250371695495, Alpha Weighted: 0.7705644894861968, D: 0.06667739763958114\n",
      "2018-11-26 20:19:23,311 INFO     Weight matrix 7/9 (512,512): Alpha 3.6117250371695495 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:19:23,318 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.89275062084198\n",
      "2018-11-26 20:19:23,320 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:19:30,179 INFO     Weight matrix 8/9 (512,512): Alpha: 3.7689164324512574, Alpha Weighted: 0.2717378304953366, D: 0.13714516867369597\n",
      "2018-11-26 20:19:30,182 INFO     Weight matrix 8/9 (512,512): Alpha 3.7689164324512574 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:19:30,187 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.9091638326644897\n",
      "2018-11-26 20:19:30,190 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:19:36,970 INFO     Weight matrix 9/9 (512,512): Alpha: 3.3101335468234847, Alpha Weighted: 0.7447753917709965, D: 0.08210809549403852\n",
      "2018-11-26 20:19:36,974 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.8933809399604797\n",
      "2018-11-26 20:19:36,977 INFO Layer 44: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:19:36,980 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 20:19:36,983 INFO Layer 45: ReLU(inplace)\n",
      "2018-11-26 20:19:36,987 INFO Layer 45: Skipping (Layer not supported)\n",
      "2018-11-26 20:19:36,990 INFO Layer 46: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:19:37,014 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:19:37,017 INFO Layer 46: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:19:37,022 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:19:43,848 INFO     Weight matrix 1/9 (512,512): Alpha: 3.5238175599105657, Alpha Weighted: 1.1797785472868159, D: 0.04426563998502246\n",
      "2018-11-26 20:19:43,851 INFO     Weight matrix 1/9 (512,512): Alpha 3.5238175599105657 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:19:43,858 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.9061400890350342\n",
      "2018-11-26 20:19:43,861 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:19:50,659 INFO     Weight matrix 2/9 (512,512): Alpha: 4.871137286698186, Alpha Weighted: 1.2211788599333036, D: 0.07315888305371557\n",
      "2018-11-26 20:19:50,661 INFO     Weight matrix 2/9 (512,512): Alpha 4.871137286698186 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:19:50,667 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9242491126060486\n",
      "2018-11-26 20:19:50,670 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:19:57,437 INFO     Weight matrix 3/9 (512,512): Alpha: 3.619520177675394, Alpha Weighted: 1.179783668705507, D: 0.04347962823212559\n",
      "2018-11-26 20:19:57,440 INFO     Weight matrix 3/9 (512,512): Alpha 3.619520177675394 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:19:57,445 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.9057533740997314\n",
      "2018-11-26 20:19:57,448 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:20:04,404 INFO     Weight matrix 4/9 (512,512): Alpha: 3.790947989132443, Alpha Weighted: 1.0195992453045795, D: 0.07017795144240158\n",
      "2018-11-26 20:20:04,406 INFO     Weight matrix 4/9 (512,512): Alpha 3.790947989132443 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:20:04,412 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8846387267112732\n",
      "2018-11-26 20:20:04,415 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:20:11,405 INFO     Weight matrix 5/9 (512,512): Alpha: 2.9698286683302895, Alpha Weighted: 1.1155166227969617, D: 0.09648389484097197\n",
      "2018-11-26 20:20:11,413 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9462580680847168\n",
      "2018-11-26 20:20:11,416 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:20:18,254 INFO     Weight matrix 6/9 (512,512): Alpha: 4.816297121882102, Alpha Weighted: 1.2800539275764564, D: 0.07352317056445995\n",
      "2018-11-26 20:20:18,257 INFO     Weight matrix 6/9 (512,512): Alpha 4.816297121882102 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:20:18,263 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8849018812179565\n",
      "2018-11-26 20:20:18,265 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:20:25,063 INFO     Weight matrix 7/9 (512,512): Alpha: 3.596034189410229, Alpha Weighted: 1.0365195573061743, D: 0.05482868174915273\n",
      "2018-11-26 20:20:25,066 INFO     Weight matrix 7/9 (512,512): Alpha 3.596034189410229 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:20:25,072 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.9030341506004333\n",
      "2018-11-26 20:20:25,076 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:20:31,951 INFO     Weight matrix 8/9 (512,512): Alpha: 5.14803051179614, Alpha Weighted: 1.1466738222493367, D: 0.09004325730926394\n",
      "2018-11-26 20:20:31,954 INFO     Weight matrix 8/9 (512,512): Alpha 5.14803051179614 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:20:31,959 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.919834315776825\n",
      "2018-11-26 20:20:31,962 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:20:38,758 INFO     Weight matrix 9/9 (512,512): Alpha: 3.5938224739415783, Alpha Weighted: 1.0261719814156078, D: 0.0453301870740791\n",
      "2018-11-26 20:20:38,761 INFO     Weight matrix 9/9 (512,512): Alpha 3.5938224739415783 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:20:38,766 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.9031757116317749\n",
      "2018-11-26 20:20:38,769 INFO Layer 47: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:20:38,772 INFO Layer 47: Skipping (Layer not supported)\n",
      "2018-11-26 20:20:38,775 INFO Layer 48: ReLU(inplace)\n",
      "2018-11-26 20:20:38,779 INFO Layer 48: Skipping (Layer not supported)\n",
      "2018-11-26 20:20:38,782 INFO Layer 49: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:20:38,807 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:20:38,809 INFO Layer 49: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:20:38,812 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:20:45,577 INFO     Weight matrix 1/9 (512,512): Alpha: 3.7480257538833093, Alpha Weighted: 2.5031706708406403, D: 0.03286437482644233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 20:20:45,580 INFO     Weight matrix 1/9 (512,512): Alpha 3.7480257538833093 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:20:45,586 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.8841134905815125\n",
      "2018-11-26 20:20:45,589 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:20:52,484 INFO     Weight matrix 2/9 (512,512): Alpha: 3.9489191078786323, Alpha Weighted: 2.274633327215661, D: 0.05258813867288148\n",
      "2018-11-26 20:20:52,487 INFO     Weight matrix 2/9 (512,512): Alpha 3.9489191078786323 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:20:52,493 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.9033573865890503\n",
      "2018-11-26 20:20:52,498 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:20:59,283 INFO     Weight matrix 3/9 (512,512): Alpha: 3.6480512659170805, Alpha Weighted: 2.4175105089746487, D: 0.03792804500267699\n",
      "2018-11-26 20:20:59,285 INFO     Weight matrix 3/9 (512,512): Alpha 3.6480512659170805 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:20:59,291 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.8853999972343445\n",
      "2018-11-26 20:20:59,296 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:21:06,123 INFO     Weight matrix 4/9 (512,512): Alpha: 3.7319969824461925, Alpha Weighted: 2.238677758656064, D: 0.05607589668776525\n",
      "2018-11-26 20:21:06,126 INFO     Weight matrix 4/9 (512,512): Alpha 3.7319969824461925 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:21:06,132 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8653184175491333\n",
      "2018-11-26 20:21:06,135 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:21:12,948 INFO     Weight matrix 5/9 (512,512): Alpha: 4.392679994569477, Alpha Weighted: 2.0830793293592107, D: 0.07692307692307898\n",
      "2018-11-26 20:21:12,951 INFO     Weight matrix 5/9 (512,512): Alpha 4.392679994569477 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:21:12,957 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.9104549288749695\n",
      "2018-11-26 20:21:12,960 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:21:19,819 INFO     Weight matrix 6/9 (512,512): Alpha: 4.04118059914944, Alpha Weighted: 2.363295441572478, D: 0.052777580291639814\n",
      "2018-11-26 20:21:19,822 INFO     Weight matrix 6/9 (512,512): Alpha 4.04118059914944 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:21:19,828 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8665657043457031\n",
      "2018-11-26 20:21:19,831 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:21:26,749 INFO     Weight matrix 7/9 (512,512): Alpha: 3.734722690755555, Alpha Weighted: 2.464886354104601, D: 0.03697598460487095\n",
      "2018-11-26 20:21:26,752 INFO     Weight matrix 7/9 (512,512): Alpha 3.734722690755555 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:21:26,757 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.8840488791465759\n",
      "2018-11-26 20:21:26,760 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:21:33,591 INFO     Weight matrix 8/9 (512,512): Alpha: 4.117055662885388, Alpha Weighted: 2.3791166222697346, D: 0.04347826086956641\n",
      "2018-11-26 20:21:33,593 INFO     Weight matrix 8/9 (512,512): Alpha 4.117055662885388 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:21:33,599 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.902477502822876\n",
      "2018-11-26 20:21:33,602 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:21:40,408 INFO     Weight matrix 9/9 (512,512): Alpha: 3.74946221516301, Alpha Weighted: 2.4313059847226604, D: 0.03164201453574811\n",
      "2018-11-26 20:21:40,411 INFO     Weight matrix 9/9 (512,512): Alpha 3.74946221516301 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:21:40,417 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.8856053352355957\n",
      "2018-11-26 20:21:40,419 INFO Layer 50: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 20:21:40,422 INFO Layer 50: Skipping (Layer not supported)\n",
      "2018-11-26 20:21:40,425 INFO Layer 51: ReLU(inplace)\n",
      "2018-11-26 20:21:40,427 INFO Layer 51: Skipping (Layer not supported)\n",
      "2018-11-26 20:21:40,430 INFO Layer 52: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 20:21:40,456 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 20:21:40,458 INFO Layer 52: Analyzing 9 weight matrices...\n",
      "2018-11-26 20:21:40,461 INFO     Weight matrix 1/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:21:47,304 INFO     Weight matrix 1/9 (512,512): Alpha: 5.408982732611438, Alpha Weighted: 2.1255076324837856, D: 0.07914316329187976\n",
      "2018-11-26 20:21:47,307 INFO     Weight matrix 1/9 (512,512): Alpha 5.408982732611438 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:21:47,314 INFO     Weight matrix 1/9 (512,512): Lognorm: 0.8503642678260803\n",
      "2018-11-26 20:21:47,318 INFO     Weight matrix 2/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:21:54,157 INFO     Weight matrix 2/9 (512,512): Alpha: 4.390710362774749, Alpha Weighted: 3.2066651016766374, D: 0.0702489410532614\n",
      "2018-11-26 20:21:54,160 INFO     Weight matrix 2/9 (512,512): Alpha 4.390710362774749 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:21:54,165 INFO     Weight matrix 2/9 (512,512): Lognorm: 0.8610822558403015\n",
      "2018-11-26 20:21:54,168 INFO     Weight matrix 3/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:22:01,064 INFO     Weight matrix 3/9 (512,512): Alpha: 5.473857682019763, Alpha Weighted: 1.5133157013013436, D: 0.06786612506092549\n",
      "2018-11-26 20:22:01,067 INFO     Weight matrix 3/9 (512,512): Alpha 5.473857682019763 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:22:01,075 INFO     Weight matrix 3/9 (512,512): Lognorm: 0.8480332493782043\n",
      "2018-11-26 20:22:01,078 INFO     Weight matrix 4/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:22:07,946 INFO     Weight matrix 4/9 (512,512): Alpha: 4.82421395936145, Alpha Weighted: 2.580725996058724, D: 0.07218284503506112\n",
      "2018-11-26 20:22:07,948 INFO     Weight matrix 4/9 (512,512): Alpha 4.82421395936145 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:22:07,956 INFO     Weight matrix 4/9 (512,512): Lognorm: 0.8413063287734985\n",
      "2018-11-26 20:22:07,959 INFO     Weight matrix 5/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:22:14,821 INFO     Weight matrix 5/9 (512,512): Alpha: 3.6033674955443376, Alpha Weighted: 3.2854983884270927, D: 0.037482328110313046\n",
      "2018-11-26 20:22:14,823 INFO     Weight matrix 5/9 (512,512): Alpha 3.6033674955443376 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:22:14,830 INFO     Weight matrix 5/9 (512,512): Lognorm: 0.8677613735198975\n",
      "2018-11-26 20:22:14,837 INFO     Weight matrix 6/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:22:21,672 INFO     Weight matrix 6/9 (512,512): Alpha: 5.190504455209701, Alpha Weighted: 1.8521137872886826, D: 0.08564677829801604\n",
      "2018-11-26 20:22:21,676 INFO     Weight matrix 6/9 (512,512): Alpha 5.190504455209701 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:22:21,683 INFO     Weight matrix 6/9 (512,512): Lognorm: 0.8360605835914612\n",
      "2018-11-26 20:22:21,687 INFO     Weight matrix 7/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:22:28,575 INFO     Weight matrix 7/9 (512,512): Alpha: 4.825678940957902, Alpha Weighted: 2.029400106243204, D: 0.06085436851210507\n",
      "2018-11-26 20:22:28,578 INFO     Weight matrix 7/9 (512,512): Alpha 4.825678940957902 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:22:28,584 INFO     Weight matrix 7/9 (512,512): Lognorm: 0.851057767868042\n",
      "2018-11-26 20:22:28,586 INFO     Weight matrix 8/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:22:35,477 INFO     Weight matrix 8/9 (512,512): Alpha: 4.114525848662035, Alpha Weighted: 3.20920374314027, D: 0.07444310475403149\n",
      "2018-11-26 20:22:35,480 INFO     Weight matrix 8/9 (512,512): Alpha 4.114525848662035 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:22:35,485 INFO     Weight matrix 8/9 (512,512): Lognorm: 0.8626508116722107\n",
      "2018-11-26 20:22:35,488 INFO     Weight matrix 9/9 (512,512): Analyzing ...\n",
      "2018-11-26 20:22:42,291 INFO     Weight matrix 9/9 (512,512): Alpha: 5.362326013320354, Alpha Weighted: 1.4747897469977636, D: 0.06266417384942347\n",
      "2018-11-26 20:22:42,294 INFO     Weight matrix 9/9 (512,512): Alpha 5.362326013320354 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 20:22:42,299 INFO     Weight matrix 9/9 (512,512): Lognorm: 0.8477775454521179\n",
      "2018-11-26 20:22:42,303 INFO Layer 53: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 20:22:42,305 INFO Layer 53: Skipping (Layer not supported)\n",
      "2018-11-26 20:22:42,307 INFO Layer 54: ReLU(inplace)\n",
      "2018-11-26 20:22:42,310 INFO Layer 54: Skipping (Layer not supported)\n",
      "2018-11-26 20:22:42,312 INFO Layer 55: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 20:22:42,315 INFO Layer 55: Skipping (Layer not supported)\n",
      "2018-11-26 20:22:42,318 INFO Layer 56: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 20:22:42,321 INFO Layer 56: Skipping (Layer not supported)\n",
      "2018-11-26 20:22:42,326 INFO Layer 57: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 20:22:44,748 INFO Layer 57: Analyzing 1 weight matrices...\n",
      "2018-11-26 20:22:44,751 INFO     Weight matrix 1/1 (4096,25088): Analyzing ...\n",
      "2018-11-26 20:33:34,357 INFO     Weight matrix 1/1 (4096,25088): Alpha: 2.0420008609529714, Alpha Weighted: 2.5934827280868418, D: 0.02954189988003486\n",
      "2018-11-26 20:33:34,398 INFO     Weight matrix 1/1 (4096,25088): Lognorm: 1.6614755392074585\n",
      "2018-11-26 20:33:34,493 INFO Layer 58: ReLU(inplace)\n",
      "2018-11-26 20:33:34,586 INFO Layer 58: Skipping (Layer not supported)\n",
      "2018-11-26 20:33:34,589 INFO Layer 59: Dropout(p=0.5)\n",
      "2018-11-26 20:33:34,592 INFO Layer 59: Skipping (Layer not supported)\n",
      "2018-11-26 20:33:34,594 INFO Layer 60: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 20:33:34,706 INFO Layer 60: Analyzing 1 weight matrices...\n",
      "2018-11-26 20:33:34,709 INFO     Weight matrix 1/1 (4096,4096): Analyzing ...\n",
      "2018-11-26 20:38:53,375 INFO     Weight matrix 1/1 (4096,4096): Alpha: 1.9815781973741693, Alpha Weighted: 3.1431793344071712, D: 0.03727465829758128\n",
      "2018-11-26 20:38:53,384 INFO     Weight matrix 1/1 (4096,4096): Lognorm: 1.5861371755599976\n",
      "2018-11-26 20:38:53,416 INFO Layer 61: ReLU(inplace)\n",
      "2018-11-26 20:38:53,440 INFO Layer 61: Skipping (Layer not supported)\n",
      "2018-11-26 20:38:53,443 INFO Layer 62: Dropout(p=0.5)\n",
      "2018-11-26 20:38:53,445 INFO Layer 62: Skipping (Layer not supported)\n",
      "2018-11-26 20:38:53,447 INFO Layer 63: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 20:38:53,482 INFO Layer 63: Analyzing 1 weight matrices...\n",
      "2018-11-26 20:38:53,485 INFO     Weight matrix 1/1 (1000,4096): Analyzing ...\n",
      "2018-11-26 20:39:18,046 INFO     Weight matrix 1/1 (1000,4096): Alpha: 3.0311830282694294, Alpha Weighted: 5.183233480367706, D: 0.03495312895111535\n",
      "2018-11-26 20:39:18,053 INFO     Weight matrix 1/1 (1000,4096): Lognorm: 1.5874838829040527\n",
      "2018-11-26 20:39:18,081 INFO ### Printing results ###\n",
      "2018-11-26 20:39:18,083 DEBUG Layer 5: Lognorm compound: 0.2935509764485889\n",
      "2018-11-26 20:39:18,087 DEBUG Layer 9: Lognorm compound: 0.4870385163360172\n",
      "2018-11-26 20:39:18,090 DEBUG Layer 12: Lognorm compound: 0.513779083887736\n",
      "2018-11-26 20:39:18,093 DEBUG Layer 16: Lognorm compound: 0.5970640116267734\n",
      "2018-11-26 20:39:18,097 DEBUG Layer 19: Lognorm compound: 0.6368463238080343\n",
      "2018-11-26 20:39:18,100 DEBUG Layer 22: Lognorm compound: 0.646138244205051\n",
      "2018-11-26 20:39:18,102 DEBUG Layer 25: Lognorm compound: 0.6836991177664863\n",
      "2018-11-26 20:39:18,105 DEBUG Layer 29: Lognorm compound: 0.7800202502144707\n",
      "2018-11-26 20:39:18,109 DEBUG Layer 32: Lognorm compound: 0.8429031040933397\n",
      "2018-11-26 20:39:18,113 DEBUG Layer 35: Lognorm compound: 0.8533215588993497\n",
      "2018-11-26 20:39:18,116 DEBUG Layer 38: Lognorm compound: 0.8683022922939725\n",
      "2018-11-26 20:39:18,119 DEBUG Layer 42: Lognorm compound: 0.9050774176915487\n",
      "2018-11-26 20:39:18,122 DEBUG Layer 45: Lognorm compound: 0.9086650477515327\n",
      "2018-11-26 20:39:18,125 DEBUG Layer 48: Lognorm compound: 0.8874824047088623\n",
      "2018-11-26 20:39:18,128 DEBUG Layer 51: Lognorm compound: 0.8517882426579794\n",
      "2018-11-26 20:39:18,133 DEBUG Layer 56: Lognorm: 1.6614755392074585\n",
      "2018-11-26 20:39:18,136 DEBUG Layer 59: Lognorm: 1.5861371755599976\n",
      "2018-11-26 20:39:18,139 DEBUG Layer 62: Lognorm: 1.5874838829040527\n",
      "2018-11-26 20:39:18,142 INFO LogNorm: min: 0.21745115518569946, max: 1.6614755392074585, avg: 0.7364940643310547\n",
      "2018-11-26 20:39:18,146 INFO LogNorm compound: min: 0.2935509764485889, max: 1.6614755392074585, avg: 0.8661540661145141\n",
      "2018-11-26 20:39:18,148 DEBUG Layer 5: Alpha compound: 2.416313084602516\n",
      "2018-11-26 20:39:18,152 DEBUG Layer 9: Alpha compound: 1.66471757925084\n",
      "2018-11-26 20:39:18,154 DEBUG Layer 12: Alpha compound: 2.608574718154921\n",
      "2018-11-26 20:39:18,158 DEBUG Layer 16: Alpha compound: 3.1504758197960125\n",
      "2018-11-26 20:39:18,161 DEBUG Layer 19: Alpha compound: 2.1749015497439395\n",
      "2018-11-26 20:39:18,164 DEBUG Layer 22: Alpha compound: 2.6129726700096967\n",
      "2018-11-26 20:39:18,167 DEBUG Layer 25: Alpha compound: 2.612993027965553\n",
      "2018-11-26 20:39:18,170 DEBUG Layer 29: Alpha compound: 2.695914198673737\n",
      "2018-11-26 20:39:18,174 DEBUG Layer 32: Alpha compound: 3.422972804173435\n",
      "2018-11-26 20:39:18,180 DEBUG Layer 35: Alpha compound: 3.1361136444618376\n",
      "2018-11-26 20:39:18,183 DEBUG Layer 38: Alpha compound: 3.4311158434102484\n",
      "2018-11-26 20:39:18,186 DEBUG Layer 42: Alpha compound: 3.8164792940830017\n",
      "2018-11-26 20:39:18,189 DEBUG Layer 45: Alpha compound: 3.9921595531974368\n",
      "2018-11-26 20:39:18,192 DEBUG Layer 48: Alpha compound: 3.9013438080720095\n",
      "2018-11-26 20:39:18,197 DEBUG Layer 51: Alpha compound: 4.799351943384637\n",
      "2018-11-26 20:39:18,200 DEBUG Layer 56: Alpha: 2.0420008609529714\n",
      "2018-11-26 20:39:18,206 DEBUG Layer 59: Alpha: 1.9815781973741693\n",
      "2018-11-26 20:39:18,208 DEBUG Layer 62: Alpha: 3.0311830282694294\n",
      "2018-11-26 20:39:18,211 INFO Alpha: min: 1.5105249374631677, max: 5.644501871946448, avg: 3.079582303894311\n",
      "2018-11-26 20:39:18,215 INFO Alpha compound: min: 1.66471757925084, max: 4.799351943384637, avg: 2.9717312014209107\n",
      "2018-11-26 20:39:18,218 DEBUG Layer 5: Alpha Weighted compound: 0.22033101644991737\n",
      "2018-11-26 20:39:18,221 DEBUG Layer 9: Alpha Weighted compound: 0.6182375971211452\n",
      "2018-11-26 20:39:18,225 DEBUG Layer 12: Alpha Weighted compound: 0.10531188162764259\n",
      "2018-11-26 20:39:18,229 DEBUG Layer 16: Alpha Weighted compound: 0.14312027033758193\n",
      "2018-11-26 20:39:18,232 DEBUG Layer 19: Alpha Weighted compound: -0.014551412952410997\n",
      "2018-11-26 20:39:18,235 DEBUG Layer 22: Alpha Weighted compound: -0.04370743871061911\n",
      "2018-11-26 20:39:18,239 DEBUG Layer 25: Alpha Weighted compound: 0.06923371497159206\n",
      "2018-11-26 20:39:18,242 DEBUG Layer 29: Alpha Weighted compound: 0.4083037886919466\n",
      "2018-11-26 20:39:18,245 DEBUG Layer 32: Alpha Weighted compound: 0.7227422154831694\n",
      "2018-11-26 20:39:18,249 DEBUG Layer 35: Alpha Weighted compound: 0.8280649398470589\n",
      "2018-11-26 20:39:18,252 DEBUG Layer 38: Alpha Weighted compound: 1.5179417646477753\n",
      "2018-11-26 20:39:18,255 DEBUG Layer 42: Alpha Weighted compound: 0.7991880044305177\n",
      "2018-11-26 20:39:18,259 DEBUG Layer 45: Alpha Weighted compound: 1.1339195813971936\n",
      "2018-11-26 20:39:18,262 DEBUG Layer 48: Alpha Weighted compound: 2.3506306664128553\n",
      "2018-11-26 20:39:18,265 DEBUG Layer 51: Alpha Weighted compound: 2.3641355781797224\n",
      "2018-11-26 20:39:18,267 DEBUG Layer 56: Alpha Weigthed: 2.5934827280868418\n",
      "2018-11-26 20:39:18,270 DEBUG Layer 59: Alpha Weigthed: 3.1431793344071712\n",
      "2018-11-26 20:39:18,273 DEBUG Layer 62: Alpha Weigthed: 5.183233480367706\n",
      "2018-11-26 20:39:18,278 INFO Alpha Weighted: min: -0.37484469026724104, max: 5.183233480367706, avg: 0.8110580801034603\n",
      "2018-11-26 20:39:18,285 INFO Alpha Weighted compound: min: -0.04370743871061911, max: 5.183233480367706, avg: 1.2301554283776004\n"
     ]
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.vgg19_bn(pretrained=True)\n",
    "\n",
    "watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "results = watcher.analyze(compute_alphas=True)\n",
    "\n",
    "data.append({\"name\": \"vgg19bntorch\", \"summary\": watcher.get_summary()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T04:39:18.616822Z",
     "start_time": "2018-11-27T04:39:18.587515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'vgg16',\n",
       "  'summary': {'lognorm': 0.5674789,\n",
       "   'lognorm_compound': 0.6947275543654406,\n",
       "   'alpha': 2.718964556284843,\n",
       "   'alpha_compound': 2.661003960009366,\n",
       "   'alpha_weighted': -0.17649111629108588,\n",
       "   'alpha_weighted_compound': 0.23297559243666768}},\n",
       " {'name': 'vgg16torch',\n",
       "  'summary': {'lognorm': 0.838187,\n",
       "   'lognorm_compound': 0.979278251418361,\n",
       "   'alpha': 2.8923375901877724,\n",
       "   'alpha_compound': 2.767717464924071,\n",
       "   'alpha_weighted': 1.4050728280368543,\n",
       "   'alpha_weighted_compound': 1.7930747927063362}},\n",
       " {'name': 'vgg16bntorch',\n",
       "  'summary': {'lognorm': 0.77009755,\n",
       "   'lognorm_compound': 0.9220763058574111,\n",
       "   'alpha': 3.0990856450288917,\n",
       "   'alpha_compound': 2.966024169749659,\n",
       "   'alpha_weighted': 1.0820402892002745,\n",
       "   'alpha_weighted_compound': 1.5490581034866533}},\n",
       " {'name': 'vgg11torch',\n",
       "  'summary': {'lognorm': 0.94749826,\n",
       "   'lognorm_compound': 1.138647382789188,\n",
       "   'alpha': 2.5724934167583515,\n",
       "   'alpha_compound': 2.537004695290022,\n",
       "   'alpha_weighted': 1.8439952060594749,\n",
       "   'alpha_weighted_compound': 2.4581931164960986}},\n",
       " {'name': 'vgg11bntorch',\n",
       "  'summary': {'lognorm': 0.8902592,\n",
       "   'lognorm_compound': 1.0959334148301019,\n",
       "   'alpha': 2.7469664709465444,\n",
       "   'alpha_compound': 2.6381040036787806,\n",
       "   'alpha_weighted': 1.5976471314894973,\n",
       "   'alpha_weighted_compound': 2.201920250597592}},\n",
       " {'name': 'vgg13torch',\n",
       "  'summary': {'lognorm': 0.8640468,\n",
       "   'lognorm_compound': 1.040889948606491,\n",
       "   'alpha': 2.6896964437283257,\n",
       "   'alpha_compound': 2.6287548926265223,\n",
       "   'alpha_weighted': 1.6453830440660253,\n",
       "   'alpha_weighted_compound': 2.192307526206597}},\n",
       " {'name': 'vgg13bntorch',\n",
       "  'summary': {'lognorm': 0.79376173,\n",
       "   'lognorm_compound': 0.9850752019771822,\n",
       "   'alpha': 2.9530774797029045,\n",
       "   'alpha_compound': 2.8166476044253024,\n",
       "   'alpha_weighted': 1.355124493045953,\n",
       "   'alpha_weighted_compound': 1.9049099340709919}},\n",
       " {'name': 'vgg19torch',\n",
       "  'summary': {'lognorm': 0.81850576,\n",
       "   'lognorm_compound': 0.9365272010550088,\n",
       "   'alpha': 2.9646726379493287,\n",
       "   'alpha_compound': 2.847975521455623,\n",
       "   'alpha_weighted': 1.1588882728052485,\n",
       "   'alpha_weighted_compound': 1.5002343912892515}},\n",
       " {'name': 'vgg19bntorch',\n",
       "  'summary': {'lognorm': 0.73649406,\n",
       "   'lognorm_compound': 0.8661540661145141,\n",
       "   'alpha': 3.079582303894311,\n",
       "   'alpha_compound': 2.9717312014209107,\n",
       "   'alpha_weighted': 0.8110580801034603,\n",
       "   'alpha_weighted_compound': 1.2301554283776004}}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T04:39:18.636939Z",
     "start_time": "2018-11-27T04:39:18.624214Z"
    }
   },
   "outputs": [],
   "source": [
    "# pytorch Model accuracies \n",
    "# https://github.com/Cadene/pretrained-models.pytorch\n",
    "\n",
    "accuracies = {\n",
    "    \"vgg11torch\": 68.970,\n",
    "    \"vgg11bntorch\": 70.452,\n",
    "    \"vgg13torch\": 69.662,\n",
    "    \"vgg13bntorch\": 71.508,\n",
    "    \"vgg16torch\": 71.636,\n",
    "    \"vgg16bntorch\": 73.518,\n",
    "    \"vgg19torch\": 72.080,\n",
    "    \"vgg19bntorch\": 74.266,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T04:39:18.660331Z",
     "start_time": "2018-11-27T04:39:18.646396Z"
    }
   },
   "outputs": [],
   "source": [
    "# pytorch Model accuracies \n",
    "# https://github.com/Cadene/pretrained-models.pytorch\n",
    "\n",
    "accuracies5 = {\n",
    "    \"vgg11torch\": 88.746,\n",
    "    \"vgg11bntorch\": 89.818,\n",
    "    \"vgg13torch\": 89.264,\n",
    "    \"vgg13bntorch\": 90.494,\n",
    "    \"vgg16torch\": 90.354,\n",
    "    \"vgg16bntorch\": 91.608,\n",
    "    \"vgg19torch\": 90.822,\n",
    "    \"vgg19bntorch\": 92.066,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Log Norm of Weight Matrices vs Accuracies of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following graph demonstrates the linear relationship between the average Log Norm of Weight matrices and the test accuracies of the models (notice we didnt't need the test data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T04:39:20.603005Z",
     "start_time": "2018-11-27T04:39:18.670368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "\n",
    "for modelname, accuracy in accuracies5.items():\n",
    "    x = accuracy\n",
    "    summary = [d[\"summary\"] for d in data if d[\"name\"] == modelname]\n",
    "    y = summary[0][\"lognorm\"]\n",
    "    label = modelname\n",
    "    plt.scatter(x,y,label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Test Accuracy vs Average Log Norm $\\langle\\log\\Vert W\\Vert\\rangle$\"+\"\\nPretrained VGG and VGG_BN Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\langle\\log\\Vert W\\Vert\\rangle$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the average Log Norm with the average Log Norm compound:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T19:52:28.047510Z",
     "start_time": "2018-11-28T19:52:26.970507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "\n",
    "x = []\n",
    "y1, y2 = [], []\n",
    "for modelname, accuracy in accuracies5.items():\n",
    "    x.append(accuracy)\n",
    "    summary = [d[\"summary\"] for d in data if d[\"name\"] == modelname]\n",
    "    y1.append(summary[0][\"lognorm\"])\n",
    "    y2.append(summary[0][\"lognorm_compound\"])\n",
    "    label = modelname\n",
    "plt.scatter(x,y1,label=\"Log Norm\", color='r')\n",
    "plt.scatter(x,y2,label=\"Log Norm Compound\", color='b')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Test Accuracy vs (Average Log Norm $\\langle\\log\\Vert W\\Vert\\rangle$ and Log Norm Compound)\"+\"\\nPretrained VGG and VGG_BN Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\langle\\log\\Vert W\\Vert\\rangle$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Power law fitting (Alpha) of Weight Matrices vs Accuracies of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear relationship between the Power law fitting (Alpha) of the weight matrices and the accuracies of the models is demonstrated in the following graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T19:44:15.758764Z",
     "start_time": "2018-11-28T19:44:14.579117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "\n",
    "for modelname, accuracy in accuracies5.items():\n",
    "    x = accuracy\n",
    "    summary = [d[\"summary\"] for d in data if d[\"name\"] == modelname]\n",
    "    y = summary[0][\"alpha_weighted\"]\n",
    "    label = modelname\n",
    "    plt.scatter(x,y,label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Test Accuracy vs Weighted Alpha\"+\"\\nPretrained VGG and VGG_BN Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"Weighted Alpha\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more accurate the model, the lower the exponent of the power law fit of the weight matrices is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T19:50:30.368057Z",
     "start_time": "2018-11-28T19:50:29.317946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "\n",
    "x = []\n",
    "y1, y2 = [], []\n",
    "for modelname, accuracy in accuracies5.items():\n",
    "    x.append(accuracy)\n",
    "    summary = [d[\"summary\"] for d in data if d[\"name\"] == modelname]\n",
    "    y1.append(summary[0][\"alpha_weighted\"])\n",
    "    y2.append(summary[0][\"alpha_weighted_compound\"])\n",
    "plt.scatter(x,y1,label=\"Weighted Alpha\", color='r')\n",
    "plt.scatter(x,y2,label=\"Weighted Alpha Compound\", color='b')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Test Accuracy vs (Weighted Alpha and Weighted Alpha compound)\"+\"\\nPretrained VGG and VGG_BN Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"Weighted Alpha\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WeightWatcher helps you choose the best pretrained model for your needs.\n",
    "\n",
    "You can use WeightWatcher to compare several pretrained models and choose the one with the lowest Log Norm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
