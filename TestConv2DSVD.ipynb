{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of Conv2D SVD method from Google Brain\n",
    "\n",
    "https://www.mis.mpg.de/fileadmin/pdf/slides_lroa2019_4125.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "layer = 8\n",
    "for im, m in enumerate(alexnet.modules()):\n",
    "    if im ==8:\n",
    "        print(im,m)\n",
    "        T = np.array(m.weight.data.clone().cpu()) \n",
    "        print(T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import powerlaw\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "class WW:\n",
    "\n",
    "    def __init__(self, model=None, log=True, logger=None):\n",
    "        self.model = self.load_model(model)\n",
    "#        self.alphas = {}\n",
    "        self.results = {}\n",
    "        self.summary = {}\n",
    "        self.logger_set(log=log, logger=logger)\n",
    "\n",
    "        self.info(self.banner())\n",
    "\n",
    "\n",
    "    def logger_set(self, log=True, logger=None):\n",
    "        self.log = log\n",
    "        self.logger = None\n",
    "        if logger:\n",
    "            self.logger = logger\n",
    "        else:\n",
    "            self.logger = logging.getLogger(__name__)\n",
    "            if not self.logger.handlers: # do not register handlers more than once\n",
    "                if log:\n",
    "                    #logging.basicConfig(level=logging.DEBUG)\n",
    "                    log_level = logging.INFO\n",
    "                    self.logger.setLevel(log_level)\n",
    "                    console_handler = logging.StreamHandler()\n",
    "                    console_handler.setLevel(log_level)\n",
    "                    formatter = logging.Formatter(\"%(asctime)s %(levelname)s %(message)s\")\n",
    "                    console_handler.setFormatter(formatter)\n",
    "                    self.logger.addHandler(console_handler)\n",
    "                else:\n",
    "                    self.logger.addHandler(logging.NullHandler())\n",
    "\n",
    "\n",
    "    def header(self):\n",
    "        \"\"\"WeightWatcher v0.1.dev0 by Calculation Consulting\"\"\"\n",
    "#        from weightwatcher import __name__, __version__, __author__, __description__, __url__\n",
    "#        return \"{} v{} by {}\\n{}\\n{}\".format(__name__, __version__, __author__, __description__, __url__)\n",
    "        return \"\"\n",
    "\n",
    "    def banner(self):\n",
    "        versions  = \"\\npython      version {}\".format(sys.version)\n",
    "        versions += \"\\nnumpy       version {}\".format(np.__version__)\n",
    "        versions += \"\\ntensforflow version {}\".format(tf.__version__)\n",
    "        versions += \"\\nkeras       version {}\".format(keras.__version__)\n",
    "        return \"\\n{}{}\".format(self.header(), versions)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        done = bool(self.results)\n",
    "        txt  = \"\\nAnalysis done: {}\".format(done)\n",
    "        return \"{}{}\".format(self.header(), txt)\n",
    "\n",
    "\n",
    "    def debug(self, message):\n",
    "        if self.log:\n",
    "            self.logger.debug(message)\n",
    "\n",
    "\n",
    "    def info(self, message):\n",
    "        if self.log:\n",
    "            self.logger.info(message)\n",
    "\n",
    "\n",
    "    def warn(self, message):\n",
    "        if self.log:\n",
    "            self.logger.warning(message)\n",
    "\n",
    "\n",
    "    def error(self, message):\n",
    "        if self.log:\n",
    "            self.logger.error(message)\n",
    "\n",
    "            \n",
    "    def load_model(self, model):\n",
    "        \"\"\"Load a model from a file if necessary.\n",
    "        \"\"\"\n",
    "        res = model\n",
    "        if isinstance(model, str):\n",
    "            if os.path.isfile(model):\n",
    "                self.info(\"Loading model from file '{}'\".format(model))\n",
    "                res = load_model(model)\n",
    "            else:\n",
    "                self.error(\"Loading model from file '{}': file not found\".format(model))\n",
    "        return res\n",
    "\n",
    "\n",
    "    def model_is_valid(self, model=None):\n",
    "        model = model or self.model\n",
    "        if not model:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "    def get_conv2D_Wmats(self, Wtensor):\n",
    "        \"\"\"Extract W slices from a 4 index conv2D tensor of shape: (N,M,i,j) or (M,N,i,j).  \n",
    "        Return ij (N x M) matrices\n",
    "\n",
    "        \"\"\"\n",
    "        Wmats = []\n",
    "        s = Wtensor.shape\n",
    "        N, M, imax, jmax = s[0],s[1],s[2],s[3]\n",
    "        if N + M >= imax + jmax:\n",
    "            self.debug(\"Pytorch tensor shape detected: {}x{} (NxM), {}x{} (i,j)\".format(N, M, imax, jmax))\n",
    "\n",
    "            for i in range(imax):\n",
    "                for j in range(jmax):\n",
    "                    W = Wtensor[:,:,i,j]\n",
    "                    if N < M:\n",
    "                        W = W.T\n",
    "                    Wmats.append(W)\n",
    "        else:\n",
    "            N, M, imax, jmax = imax, jmax, N, M          \n",
    "            self.debug(\"Keras tensor shape detected: {}x{} (NxM), {}x{} (i,j)\".format(N, M, imax, jmax))\n",
    "\n",
    "            for i in range(imax):\n",
    "                for j in range(jmax):\n",
    "                    W = Wtensor[i,j,:,:]\n",
    "                    if N < M:\n",
    "                        W = W.T\n",
    "                    Wmats.append(W)\n",
    "\n",
    "        return Wmats\n",
    "\n",
    "    def norm_check(self, weight, N, M, receptive_field_size, \n",
    "                   lower = 0.5, upper = 1.5):\n",
    "\n",
    "        kappa = np.sqrt( 2 / ((N + M)*receptive_field_size) )\n",
    "        norm = np.linalg.norm(weight)\n",
    "\n",
    "\n",
    "        check1 = norm / np.sqrt(N*M)\n",
    "        check2 = norm / (kappa*np.sqrt(N*M))\n",
    "        if (check2 > lower) & (check2 < upper):   \n",
    "            #aka, if Glorot normalization\n",
    "            return weight / (kappa * np.sqrt(N))   \n",
    "        elif (check1 > lower) & (check1 < upper): \n",
    "            return weight / np.sqrt(N)      \n",
    "        else:\n",
    "            return weight\n",
    "\n",
    "\n",
    "    def analyze_weight_matrices(self, weights, layer_id, min_size=50, max_size=0,\n",
    "                        alphas=False,  spectralnorms=False, softranks=False,\n",
    "                        normalize=False,  mp_fit=False,\n",
    "                        conv2Dsvd=False,  plot=False):\n",
    "        \"\"\"Analyzes 1 or  weight matrices (assuming all the same shape)\"\"\"\n",
    "\n",
    "\n",
    "        # reset options to be consistent\n",
    "        if (conv2Dsvd or mp_fit):\n",
    "            alphas = True\n",
    "\n",
    "        if (alphas or spectralnorms or softranks):\n",
    "            spectralnorms = True\n",
    "            softranks = True\n",
    "\n",
    "        res = {}\n",
    "        count = len(weights)\n",
    "        if count == 0:\n",
    "            return res\n",
    "\n",
    "        # get an initial W and response\n",
    "        # assumes all weights have the same shape\n",
    "        W = weights[0]\n",
    "        res[0] = {}\n",
    "        \n",
    "        \n",
    "        \n",
    "        # special case for conv2Dsvd \n",
    "        # assumes weights = [conv2D tensor] 1 matrix only\n",
    "        if conv2Dsvd:  # assume W is 4-index tensor\n",
    "            if len(weights)!=1:\n",
    "                msg = \"Only specific conv2Dsvd for 1 tensor: {}\".format(len(weights))\n",
    "                self.warn(msg)\n",
    "                res[0][\"message\"] = msg\n",
    "                return res\n",
    "            if len(W.shape)!=4:\n",
    "                msg = \"Conv2D kernel wrong size: {} {}\".format(W.shape, len(W.shape))\n",
    "                self.warn(msg)\n",
    "                res[0][\"message\"] = msg\n",
    "                return res\n",
    "        else:\n",
    "            if len(W.shape)!=2:\n",
    "                msg = \"Weight matrix wrong size: {}\".format(W.shape)\n",
    "                self.warn(msg)\n",
    "                res[0][\"message\"] = msg\n",
    "                return res\n",
    "\n",
    "        # handle special case now, save for loop later\n",
    "        if conv2Dsvd:\n",
    "            # is pytorch or tensor style \n",
    "            s = W.shape\n",
    "            self.debug(\"    Conv2D SVD ({}): Analyzing ...\".format(s))\n",
    "\n",
    "            N, M, imax, jmax = s[0],s[1],s[2],s[3]\n",
    "            # probably better just to check what col N is in \n",
    "            shape_type = \"pytorch\"\n",
    "            if N + M >= imax + jmax:\n",
    "                self.debug(\"Pytorch tensor shape detected: {}x{} (NxM), {}x{} (i,j)\".format(N, M, imax, jmax))    \n",
    "                fft_axes = [2,3]\n",
    "            else:\n",
    "                N, M, imax, jmax = imax, jmax, N, M          \n",
    "                shape_type = \"keras\"\n",
    "                fft_axes = [0,1]\n",
    "                self.debug(\"Keras tensor shape detected: {}x{} (NxM), {}x{} (i,j)\".format(N, M, imax, jmax))\n",
    "\n",
    "            #  receptive_field / kernel size\n",
    "            rf = np.min([imax, jmax])\n",
    "            # aspect ratio\n",
    "            Q = N/M \n",
    "            # num non-zero eigenvalues\n",
    "            n_comp = rf*N*M\n",
    "\n",
    "            # run FFT on each channel\n",
    "            fft_grid = [32,32]\n",
    "            fft_coefs = np.fft.fft2(W, fft_grid, axes=fft_axes)\n",
    "            # bug in svd, can not compute complex values\n",
    "            #svd = TruncatedSVD(n_components=n_comp, n_iter=7, random_state=10)\n",
    "            #svd.fit(fft_coefs)\n",
    "            #sv = svd.singular_values_\n",
    "            sv = np.linalg.svd(fft_coefs, compute_uv=False).flatten()\n",
    "            sv = np.sort(sv)[-n_comp:]\n",
    "            evals = sv*sv\n",
    "            frobenius_norm = np.sqrt(np.sum(evals))\n",
    "\n",
    "        elif stack_slices:\n",
    "            # this should be part of get_conv2Dmats\n",
    "            # replace weights with W\n",
    "            self.debug(\"stack slices N/A yet\")        \n",
    "            evals = None\n",
    "        elif merge_slices:\n",
    "            # compute all evals, merge\n",
    "            # really only for conv2D\n",
    "            # replace weights with W\n",
    "            self.debug(\"merge slices N/A yet\")\n",
    "            evals = None\n",
    "        else:\n",
    "            s = W.shape\n",
    "            N, M = np.max(s), np.min(s)\n",
    "            # aspect ratio\n",
    "            Q = N/M \n",
    "            evals = None\n",
    "\n",
    "            if M < min_size:\n",
    "                summary = \"Weight matrices too small {}  Skipping: (<{})\".format(W.shape, min_size)\n",
    "                res[0][\"summary\"] = summary \n",
    "                self.info(\"    {}\".format(summary))\n",
    "                return res\n",
    "\n",
    "            if max_size > 0 and M > max_size:\n",
    "                summary = \"Weight matrices too large {}  Skipping:  (>{})\".format(W.shape, max_size)\n",
    "                res[0][\"summary\"] = summary \n",
    "                self.info(\"    {}\".format(summary))\n",
    "                return res\n",
    "\n",
    "        # loop over all slices\n",
    "        for i, W in enumerate(weights):\n",
    "            res[i] = {}\n",
    "            res[i][\"N\"] = N\n",
    "            res[i][\"M\"] = M\n",
    "            res[i][\"Q\"] = Q\n",
    "\n",
    "            summary = []\n",
    "            self.debug(\"    Weight matrix {} {}/{} ({},{}): Analyzing ...\".format(layer_id, i+1, count, M, N))\n",
    "\n",
    "            if alphas:\n",
    "                if evals is None: \n",
    "                    sv = np.linalg.svd(W,  compute_uv=False())\n",
    "                    evals = sv*sv/N\n",
    "                    frobenius_norm = np.linalg.norm(W)\n",
    "\n",
    "                lambda_min, lambda_max = np.min(evals), np.max(evals)\n",
    "                fit = powerlaw.Fit(evals, xmax=lambda_max, verbose=False)\n",
    "                alpha = fit.alpha \n",
    "                D = fit.D\n",
    "\n",
    "                alpha_weighted = alpha * np.log10(lambda_max)\n",
    "                log_pnorm = np.log10(np.sum([ev**alpha for ev in evals]))\n",
    "\n",
    "                res[i][\"alpha\"] = alpha\n",
    "                res[i][\"D\"] = D\n",
    "                res[i][\"alpha_weighted\"] = alpha_weighted\n",
    "\n",
    "\n",
    "            if spectralnorms:  # always set if alphas set\n",
    "                if evals is None:\n",
    "                    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=10)\n",
    "                    svd.fit(fft_coefs)\n",
    "                    evals = sv*sv/N\n",
    "                    frobenius_norm = np.linalg.norm(W)    \n",
    "                    # check evals / norm\n",
    "\n",
    "                lambda_min, lambda_max = np.min(evals), np.max(evals)\n",
    "                spectral_norm = np.max(evals)\n",
    "\n",
    "                res[i][\"lambda_max\"] = lambda_max\n",
    "                res[i][\"lambda_min\"] = lambda_min\n",
    "                res[i][\"spectral_norm\"] = spectral_norm\n",
    "                res[i][\"spectral_normlog\"] = np.log10(spectral_norm)\n",
    "\n",
    "\n",
    "                # soft rank =  stable rank\n",
    "                softrank = (frobenius_norm**2) / spectral_norm\n",
    "                softranklog = np.log10(softrank)\n",
    "                softranklogratio = 2*np.log10(frobenius_norm) / np.log10(spectral_norm)\n",
    "\n",
    "                res[i][\"softrank\"] = softrank\n",
    "                res[i][\"softranklog\"] = softranklog\n",
    "                res[i][\"softranklogratio\"] = softranklogratio\n",
    "\n",
    "\n",
    "            # computations for all W\n",
    "            res[i][\"norm\"] = frobenius_norm\n",
    "            res[i][\"lognorm\"] = np.log10(frobenius_norm)\n",
    "\n",
    "            tolerance = lambda_max * M * np.finfo(np.max(sv)).eps\n",
    "            res[i][\"rank_loss\"] = np.count_nonzero(sv > tolerance, axis=-1)\n",
    "\n",
    "\n",
    "            if plot:\n",
    "                a = \"{:2f}\".format(alpha)\n",
    "                plt.hist(np.log10(evals),bins=100, label=a);\n",
    "                plt.title(\"AlexNet Layer {} W Log10 Eigenvales \\n Conv2D-SVD FFT approach\".format(layer_id))\n",
    "               \n",
    "                plt.xlabel(r\"$\\rho(\\log_{10}\\lambda)$\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "            #        if mp_fit:\n",
    "            #            do_mp_fit(N,M,Q,evals,sv)\n",
    "\n",
    "            # reset computations\n",
    "            evals = None\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = WW()\n",
    "\n",
    "for im, m in enumerate(alexnet.modules()):\n",
    "    if  im > 1 and \"Conv2d\" in str(m):\n",
    "        print(im,m)\n",
    "        W = np.array(m.weight.data.clone().cpu()) \n",
    "        results = ww.analyze_weight_matrices([W], layer_id=im, conv2Dsvd=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
